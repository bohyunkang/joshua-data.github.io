<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2024-08-24T15:53:45+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Joshua Kim</title><subtitle>Analytics Engineer | Data Analyst</subtitle><entry><title type="html">Data-driven VOC Analysis and Automated Dashboard Development: Reducing Cost and Maximizing Efficiency</title><link href="http://localhost:4000/voc-dashboard-en/" rel="alternate" type="text/html" title="Data-driven VOC Analysis and Automated Dashboard Development: Reducing Cost and Maximizing Efficiency" /><published>2024-07-20T00:00:00+09:00</published><updated>2024-07-20T00:00:00+09:00</updated><id>http://localhost:4000/voc-dashboard-en</id><content type="html" xml:base="http://localhost:4000/voc-dashboard-en/"><![CDATA[<blockquote>
  <p>“I learned that internal team members were facing difficulties in following up on Zendesk customer inquiries, so I developed a Redash VOC dashboard to address this issue. The system automatically collected and preprocessed Zendesk data, then used the OpenAI API to categorize and summarize customer inquiries by topic. Additionally, a Slack notification was set up to alert the team each Monday about the topics with the highest increase in inquiries, helping identify and respond to customer issues more efficiently. As a result, we were able to eliminate about $275 in opportunity costs each month and reduce the time spent by team members on VOC follow-ups.”</p>
</blockquote>

<hr />

<h1 id="table-of-contents">Table of Contents</h1>
<ol>
  <li>STAR Summary</li>
  <li>Situation</li>
  <li>Tasks</li>
  <li>Actions</li>
  <li>Results</li>
</ol>

<hr />

<h1 id="1-star-summary">1. STAR Summary</h1>

<h3 id="situation">Situation</h3>
<ul>
  <li>Internal team members were struggling to efficiently track and follow up on Zendesk customer inquiries. Reading through all the inquiries required <strong>an excessive amount of time and effort</strong>, and implementing an external VOC analysis service posed <strong>a cost burden</strong>.</li>
</ul>

<h3 id="tasks">Tasks</h3>
<ol>
  <li>I decided to <strong>categorize and summarize</strong> customer inquiries and create a Redash VOC <strong>dashboard</strong>.</li>
  <li>I also decided to build <strong>a Slack notification bot</strong> to alert the team about the most urgent customer inquiry topics.</li>
</ol>

<h3 id="actions">Actions</h3>
<ol>
  <li>
    <p><strong>Data Pipeline</strong></p>

    <p>1.1. Data Collection and Preprocessing <code class="language-plaintext highlighter-rouge">(Zendesk Tickets → Google Sheets → BigQuery)</code></p>

    <p>1.2. Topic Categorization <code class="language-plaintext highlighter-rouge">(OpenAI API)</code></p>

    <p>1.3. Summarization <code class="language-plaintext highlighter-rouge">(OpenAI API)</code></p>
  </li>
  <li>
    <p><strong>Dashboard and Notification Bot</strong></p>

    <p>2.1. Creating the Dashboard <code class="language-plaintext highlighter-rouge">(BigQuery → Redash)</code></p>

    <p>2.2. Building the Notification Bot <code class="language-plaintext highlighter-rouge">(BigQuery → Slack API)</code></p>
  </li>
</ol>

<h3 id="results">Results</h3>
<ol>
  <li><strong>Cost Savings</strong>
    <ul>
      <li>We solved the problem internally at a cost of $25 per month, avoiding the need for an external service that would have cost $300 per month.</li>
    </ul>
  </li>
  <li><strong>Time Savings</strong>
    <ul>
      <li>The time required for internal team members to follow up on VOC, identify issues, and respond was significantly reduced.</li>
    </ul>
  </li>
</ol>

<hr />

<h1 id="2-situation">2. Situation</h1>

<blockquote>
  <p>Internal team members were struggling to efficiently track and follow up on Zendesk customer inquiries. Reading through all the inquiries required <strong>an excessive amount of time and effort</strong>, and implementing an external VOC analysis service posed <strong>a cost burden</strong>.</p>
</blockquote>

<h3 id="specific-situation">Specific Situation</h3>
<ul>
  <li>It was taking too much time to follow up on dozens to hundreds of customer inquiries each week.</li>
  <li>It was challenging to identify which topics were negatively impacting the customer experience.</li>
</ul>

<h3 id="feedback-from-internal-team-members">Feedback from Internal Team Members</h3>
<ul>
  <li><strong>C-level 1</strong>: “I’m trying to stay on top of customer sentiment by regularly reading the inquiries, but there are just too many, and it’s very time-consuming.”</li>
  <li><strong>C-level 2</strong>: “I’d like to introduce an external service for VOC analysis, but the cost is too high, so we’re hesitant.”</li>
  <li><strong>CX Manager</strong>: “I want to share more VOC insights with colleagues and improve the speed of issue resolution.”</li>
</ul>

<hr />

<h1 id="3-tasks">3. Tasks</h1>

<blockquote>
  <ol>
    <li>I decided to <strong>categorize and summarize</strong> customer inquiries and create a Redash VOC <strong>dashboard</strong>.</li>
    <li>I also decided to build <strong>a Slack notification bot</strong> to alert the team about the most urgent customer inquiry topics.</li>
  </ol>
</blockquote>

<p><img src="/assets/2024-07-20-voc-dashboard/1.png" alt="" /></p>

<hr />

<h1 id="4-actions">4. Actions</h1>

<blockquote>
  <ol>
    <li>
      <p><strong>Data Pipeline</strong></p>

      <p>1.1. Data Collection and Preprocessing <code class="language-plaintext highlighter-rouge">(Zendesk Tickets → Google Sheets → BigQuery)</code></p>

      <p>1.2. Topic Categorization <code class="language-plaintext highlighter-rouge">(OpenAI API)</code></p>

      <p>1.3. Summarization <code class="language-plaintext highlighter-rouge">(OpenAI API)</code></p>
    </li>
    <li>
      <p><strong>Dashboard and Notification Bot</strong></p>

      <p>2.1. Creating the Dashboard <code class="language-plaintext highlighter-rouge">(BigQuery → Redash)</code></p>

      <p>2.2. Building the Notification Bot <code class="language-plaintext highlighter-rouge">(BigQuery → Slack API)</code></p>
    </li>
  </ol>
</blockquote>

<h3 id="1-data-pipeline">1. <strong>Data Pipeline</strong></h3>

<p><img src="/assets/2024-07-20-voc-dashboard/2-en.png" alt="" /></p>

<h5 id="11-data-collection-and-preprocessing-zendesk-tickets--google-sheets--bigquery">1.1. Data Collection and Preprocessing <code class="language-plaintext highlighter-rouge">(Zendesk Tickets → Google Sheets → BigQuery)</code></h5>

<p><img src="/assets/2024-07-20-voc-dashboard/3-en.png" alt="" /></p>

<p>1) First, I used the <strong>Zendesk Connector</strong> available from Google Workspace Marketplace to automatically store completed Zendesk ticket data in a private Google Sheet.</p>

<p><img src="/assets/2024-07-20-voc-dashboard/4.png" alt="" /></p>

<p>2) I then loaded the Google Sheets data into Python.</p>

<details>
<summary>View Code</summary>
<div>
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   <span class="c1"># Load Raw Data from Google Sheets (to `df`)
</span>   <span class="n">gc</span> <span class="o">=</span> <span class="n">gspread</span><span class="p">.</span><span class="nf">service_account</span><span class="p">(</span><span class="n">google_sheets_credentials_fpath</span><span class="p">)</span>
   <span class="n">spreadsheet</span> <span class="o">=</span> <span class="n">gc</span><span class="p">.</span><span class="nf">open_by_url</span><span class="p">(</span><span class="n">google_sheets_url</span><span class="p">)</span>
   <span class="n">sheet</span> <span class="o">=</span> <span class="n">spreadsheet</span><span class="p">.</span><span class="nf">worksheet</span><span class="p">(</span><span class="n">google_sheets_worksheet_name</span><span class="p">)</span>
   <span class="n">sheet_data</span> <span class="o">=</span> <span class="n">sheet</span><span class="p">.</span><span class="nf">get_all_records</span><span class="p">()</span>
   <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">sheet_data</span><span class="p">)</span>
</code></pre></div>    </div>
  </div>
</details>

<p>3) After that, I proceeded with data preprocessing.</p>

<details>
<summary>Filter Only Necessary Columns</summary>
<div>
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   <span class="c1"># Rename Columns
</span>   <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">rename</span><span class="p">(</span>
      <span class="n">columns</span><span class="o">=</span><span class="p">{</span>
         <span class="sh">'</span><span class="s">created_at</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">created_datetime</span><span class="sh">'</span><span class="p">,</span>
         <span class="sh">'</span><span class="s">raw_subject</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">subject</span><span class="sh">'</span><span class="p">,</span>
         <span class="sh">'</span><span class="s">tags.0</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">zendesk_topic</span><span class="sh">'</span><span class="p">,</span>
         <span class="sh">'</span><span class="s">updated_at</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">updated_datetime</span><span class="sh">'</span>
      <span class="p">}</span>
   <span class="p">)</span>
   <span class="c1"># Extract Only Necessary Columns
</span>   <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span>
      <span class="sh">'</span><span class="s">id</span><span class="sh">'</span><span class="p">,</span>
      <span class="sh">'</span><span class="s">created_datetime</span><span class="sh">'</span><span class="p">,</span>
      <span class="sh">'</span><span class="s">zendesk_topic</span><span class="sh">'</span><span class="p">,</span>
      <span class="sh">'</span><span class="s">subject</span><span class="sh">'</span><span class="p">,</span>
      <span class="sh">'</span><span class="s">description</span><span class="sh">'</span>
   <span class="p">]]</span>
</code></pre></div>    </div>
  </div>
</details>

<details>
<summary>Change Timezone (UTC → KST)</summary>
<div>
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   <span class="c1"># Convert Existing Timestamps: UTC to KST
</span>   <span class="n">kst</span> <span class="o">=</span> <span class="n">pytz</span><span class="p">.</span><span class="nf">timezone</span><span class="p">(</span><span class="sh">'</span><span class="s">Asia/Seoul</span><span class="sh">'</span><span class="p">)</span>
   <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">created_datetime</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">created_datetime</span><span class="sh">'</span><span class="p">],</span> <span class="n">utc</span><span class="o">=</span><span class="bp">True</span><span class="p">).</span><span class="n">dt</span><span class="p">.</span><span class="nf">tz_convert</span><span class="p">(</span><span class="n">kst</span><span class="p">).</span><span class="n">dt</span><span class="p">.</span><span class="nf">tz_localize</span><span class="p">(</span><span class="bp">None</span><span class="p">)</span>
   <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">astype</span><span class="p">(</span><span class="sh">'</span><span class="s">str</span><span class="sh">'</span><span class="p">)</span> <span class="c1"># To load into BigQuery, all columns must be cast as strings.
</span></code></pre></div>    </div>
  </div>
</details>

<details>
<summary>Filter Only New Entries</summary>
<div>
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   <span class="c1"># Remove Rows Already in Target Table (Prevent Duplicates)
</span>   <span class="n">query</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">'</span><span class="s">SELECT DISTINCT id FROM `</span><span class="si">{</span><span class="n">bigquery_tickets_table_id</span><span class="si">}</span><span class="s">`</span><span class="sh">'</span>
   <span class="k">try</span><span class="p">:</span>
      <span class="n">existing_ids</span> <span class="o">=</span> <span class="n">client</span><span class="p">.</span><span class="nf">query</span><span class="p">(</span><span class="n">query</span><span class="p">).</span><span class="nf">to_dataframe</span><span class="p">()</span>
      <span class="n">existing_ids</span> <span class="o">=</span> <span class="nf">set</span><span class="p">(</span><span class="n">existing_ids</span><span class="p">[</span><span class="sh">'</span><span class="s">id</span><span class="sh">'</span><span class="p">])</span>
      <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span>
         <span class="o">~</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">id</span><span class="sh">'</span><span class="p">].</span><span class="nf">isin</span><span class="p">(</span><span class="n">existing_ids</span><span class="p">)</span>
      <span class="p">].</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
   <span class="k">except</span><span class="p">:</span>
      <span class="n">df</span> <span class="o">=</span> <span class="n">df</span>
</code></pre></div>    </div>
  </div>
</details>

<p>4) Finally, I loaded the data into the BigQuery table.</p>

<details>
<summary>View Code</summary>
<div>
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   <span class="c1"># Load Data into BigQuery Table
</span>   <span class="n">table</span> <span class="o">=</span> <span class="n">client</span><span class="p">.</span><span class="nf">get_table</span><span class="p">(</span><span class="n">bigquery_tickets_table_id</span><span class="p">)</span>
   <span class="n">client</span><span class="p">.</span><span class="nf">load_table_from_dataframe</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">table</span><span class="p">)</span>
</code></pre></div>    </div>
  </div>
</details>

<h5 id="12-topic-categorization-openai-api">1.2. Topic Categorization <code class="language-plaintext highlighter-rouge">(OpenAI API)</code></h5>

<p><img src="/assets/2024-07-20-voc-dashboard/5-en.png" alt="" /></p>

<p>1) To predefine the list of topics to be categorized, I discussed and established a classification system with a CX manager and a UX/UI designer.</p>

<ul>
  <li><strong>Topic</strong>: Broad subject categories</li>
  <li><strong>Keyword</strong>: Specific subtopics</li>
</ul>

<p><img src="/assets/2024-07-20-voc-dashboard/6.png" alt="" /></p>

<p>2) I loaded the data from the BigQuery table into Python.</p>

<details>
<summary>View Code</summary>
<div>
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   <span class="c1"># Load BigQuery `tickets` Table (to `df`)
</span>   <span class="n">query</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">'</span><span class="s">SELECT * FROM </span><span class="si">{</span><span class="n">bigquery_tickets_table_id</span><span class="si">}</span><span class="sh">'</span>
   <span class="n">df</span> <span class="o">=</span> <span class="n">bigquery_client</span><span class="p">.</span><span class="nf">query</span><span class="p">(</span><span class="n">query</span><span class="p">).</span><span class="nf">to_dataframe</span><span class="p">()</span>
</code></pre></div>    </div>
  </div>
</details>

<p>3) I then filtered out only new entries.</p>

<details>
<summary>View Code</summary>
<div>
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   <span class="c1"># Remove Rows Already in Target Table (Prevent Duplicates)
</span>   <span class="n">query</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">'</span><span class="s">SELECT DISTINCT id FROM `</span><span class="si">{</span><span class="n">bigquery_tickets_topics_table_id</span><span class="si">}</span><span class="s">`</span><span class="sh">'</span>
   <span class="k">try</span><span class="p">:</span>
      <span class="n">existing_ids</span> <span class="o">=</span> <span class="n">bigquery_client</span><span class="p">.</span><span class="nf">query</span><span class="p">(</span><span class="n">query</span><span class="p">).</span><span class="nf">to_dataframe</span><span class="p">()</span>
      <span class="n">existing_ids</span> <span class="o">=</span> <span class="nf">set</span><span class="p">(</span><span class="n">existing_ids</span><span class="p">[</span><span class="sh">'</span><span class="s">id</span><span class="sh">'</span><span class="p">])</span>
      <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span>
         <span class="o">~</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">id</span><span class="sh">'</span><span class="p">].</span><span class="nf">isin</span><span class="p">(</span><span class="n">existing_ids</span><span class="p">)</span>
      <span class="p">].</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
   <span class="k">except</span><span class="p">:</span>
      <span class="n">df</span> <span class="o">=</span> <span class="n">df</span>
</code></pre></div>    </div>
  </div>
</details>

<p>4) I created the prompt to be sent to OpenAI.</p>

<details>
<summary>System Prompt</summary>
<div>
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   Your task is to classify a single key keyword from the customer inquiry details. You must respond by selecting only from the provided list of topics. Below is the list of topics you can choose from:
      {Keyword List}
   Do not create or select any other topics.
</code></pre></div>    </div>
  </div>
</details>

<details>
<summary>User Prompt</summary>
<div>
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   Below is the customer inquiry details.
   Extract a single key topic from this text.

   Customer Inquiry Details:
      {Actual Text}

   Extraction Format: Topic
   Restrictions:
   1. Respond with only the topic.
   2. Choose only from the provided list of topics. Do not create or select any other topics.
   3. Make sure to select one from the list below:
   {Keyword List}
   
   Extraction Result:
</code></pre></div>    </div>
  </div>
</details>

<p>5) I then obtained the main topic by calling the OpenAI API.</p>

<details>
<summary>View Code</summary>
<div>
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   <span class="c1"># Define the system prompt for OpenAI
</span>   <span class="n">prompt_system</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">'''</span><span class="s">
   Your task is to classify a single key keyword from the customer inquiry details. You must respond by selecting only from the provided list of topics. Below is the list of topics you can choose from:
   </span><span class="si">{</span><span class="sh">'</span><span class="s">, </span><span class="sh">'</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="n">topics2_list</span><span class="p">)</span><span class="si">}</span><span class="s">
   Do not create or select any other topics.
   </span><span class="sh">'''</span>

   <span class="c1"># Start the OpenAI API Request for each row
</span>   <span class="n">topic2_results_list</span> <span class="o">=</span> <span class="p">[]</span>

   <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">df</span><span class="p">)):</span>

      <span class="c1"># Subject + Description
</span>      <span class="n">text</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="sh">'</span><span class="s">subject</span><span class="sh">'</span><span class="p">]</span> <span class="o">+</span> <span class="sh">'</span><span class="s"> </span><span class="sh">'</span> <span class="o">+</span> <span class="n">df</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="sh">'</span><span class="s">description</span><span class="sh">'</span><span class="p">]</span>
      <span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="p">[:</span><span class="mi">2000</span><span class="p">]</span> <span class="c1"># Limit length to 2,000 characters (to save costs)
</span>
      <span class="c1"># Define the individual prompt for API Request
</span>      <span class="n">prompt_individual</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">'''</span><span class="s">
      Below is the customer inquiry details.
      Extract a single key topic from this text.

      Customer Inquiry Details:
      </span><span class="si">{</span><span class="n">text</span><span class="si">}</span><span class="s">

      Extraction Format: Topic
      Restrictions:
      1. Respond with only the topic.
      2. Choose only from the provided list of topics. Do not create or select any other topics.
      3. Make sure to select one from the list below:
      </span><span class="si">{</span><span class="sh">'</span><span class="s">, </span><span class="sh">'</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="n">topics2_list</span><span class="p">)</span><span class="si">}</span><span class="s"> 
      
      Extraction Result:
      </span><span class="sh">'''</span>

      <span class="c1"># Start the API Request
</span>      <span class="n">result</span> <span class="o">=</span> <span class="n">openai_client</span><span class="p">.</span><span class="n">chat</span><span class="p">.</span><span class="n">completions</span><span class="p">.</span><span class="nf">create</span><span class="p">(</span>
            <span class="n">model</span> <span class="o">=</span> <span class="sh">'</span><span class="s">gpt-4</span><span class="sh">'</span><span class="p">,</span>
            <span class="n">max_tokens</span> <span class="o">=</span> <span class="mi">500</span><span class="p">,</span>
            <span class="n">n</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
            <span class="n">temperature</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
            <span class="n">stop</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span>
            <span class="n">messages</span> <span class="o">=</span> <span class="p">[</span>
               <span class="p">{</span><span class="sh">"</span><span class="s">role</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">system</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">content</span><span class="sh">"</span><span class="p">:</span> <span class="n">prompt_system</span><span class="p">},</span>
               <span class="p">{</span><span class="sh">"</span><span class="s">role</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">user</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">content</span><span class="sh">"</span><span class="p">:</span> <span class="n">prompt_individual</span><span class="p">}</span>
            <span class="p">]</span>
      <span class="p">)</span>

      <span class="c1"># Record the topic results into Empty Lists
</span>      <span class="n">topic2_result</span> <span class="o">=</span> <span class="n">result</span><span class="p">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">message</span><span class="p">.</span><span class="n">content</span><span class="p">.</span><span class="nf">replace</span><span class="p">(</span><span class="sh">'</span><span class="se">\'</span><span class="sh">'</span><span class="p">,</span> <span class="sh">''</span><span class="p">).</span><span class="nf">replace</span><span class="p">(</span><span class="sh">'</span><span class="se">\"</span><span class="sh">'</span><span class="p">,</span> <span class="sh">''</span><span class="p">).</span><span class="nf">replace</span><span class="p">(</span><span class="sh">'</span><span class="s">[</span><span class="sh">'</span><span class="p">,</span> <span class="sh">''</span><span class="p">).</span><span class="nf">replace</span><span class="p">(</span><span class="sh">'</span><span class="s">]</span><span class="sh">'</span><span class="p">,</span> <span class="sh">''</span><span class="p">).</span><span class="nf">strip</span><span class="p">()</span>
      <span class="n">topic2_results_list</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">topic2_result</span><span class="p">)</span>

   <span class="c1"># Record the 'Topic 1' results using 'Topic 2' results
</span>   <span class="n">topic1_results_list</span> <span class="o">=</span> <span class="p">[]</span>
   <span class="k">for</span> <span class="n">topic2</span> <span class="ow">in</span> <span class="n">topic2_results_list</span><span class="p">:</span>
      <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">topics_list</span><span class="p">)):</span>
            <span class="k">if</span> <span class="n">topics_list</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">topic2</span><span class="p">:</span>
               <span class="n">topic1_results_list</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">topics_list</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
               <span class="k">break</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="nf">len</span><span class="p">(</span><span class="n">topics_list</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
               <span class="n">topic1_results_list</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="sh">'</span><span class="s">Others</span><span class="sh">'</span><span class="p">)</span>
      
   <span class="c1"># Add 'Topic 1' and 'Topic 2' columns to the dataframe and select only the necessary columns
</span>   <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">openai_topic_1</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">topic1_results_list</span>
   <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">openai_topic_2</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">topic2_results_list</span>
   <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span>
      <span class="sh">'</span><span class="s">id</span><span class="sh">'</span><span class="p">,</span>
      <span class="sh">'</span><span class="s">created_datetime</span><span class="sh">'</span><span class="p">,</span>
      <span class="sh">'</span><span class="s">openai_topic_1</span><span class="sh">'</span><span class="p">,</span>
      <span class="sh">'</span><span class="s">openai_topic_2</span><span class="sh">'</span>
   <span class="p">]]</span>
</code></pre></div>    </div>
  </div>
</details>

<p>6) Finally, the topic categorization results were loaded into a BigQuery table.</p>

<details>
<summary>View Code</summary>
<div>
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   <span class="c1"># Load Data into BigQuery Table
</span>   <span class="n">table</span> <span class="o">=</span> <span class="n">bigquery_client</span><span class="p">.</span><span class="nf">get_table</span><span class="p">(</span><span class="n">bigquery_tickets_topics_table_id</span><span class="p">)</span>
   <span class="n">bigquery_client</span><span class="p">.</span><span class="nf">load_table_from_dataframe</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">table</span><span class="p">)</span>
</code></pre></div>    </div>
  </div>
</details>

<h5 id="13-summarization-openai-api">1.3. Summarization <code class="language-plaintext highlighter-rouge">(OpenAI API)</code></h5>

<p><img src="/assets/2024-07-20-voc-dashboard/7-en.png" alt="" /></p>

<p>1) I loaded the data from the BigQuery table into Python.</p>

<details>
<summary>View Code</summary>
<div>
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   <span class="c1"># Load BigQuery `tickets` Table (to `df`)
</span>   <span class="n">query</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">'</span><span class="s">SELECT * FROM </span><span class="si">{</span><span class="n">bigquery_tickets_table_id</span><span class="si">}</span><span class="sh">'</span>
   <span class="n">df</span> <span class="o">=</span> <span class="n">bigquery_client</span><span class="p">.</span><span class="nf">query</span><span class="p">(</span><span class="n">query</span><span class="p">).</span><span class="nf">to_dataframe</span><span class="p">()</span>
</code></pre></div>    </div>
  </div>
</details>

<p>2) I then filtered out only new entries.</p>

<details>
<summary>View Code</summary>
<div>
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   <span class="c1"># Remove Rows Already in Target Table (Prevent Duplicates)
</span>   <span class="n">query</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">'</span><span class="s">SELECT DISTINCT id FROM `</span><span class="si">{</span><span class="n">bigquery_tickets_summary_table_id</span><span class="si">}</span><span class="s">`</span><span class="sh">'</span>
   <span class="k">try</span><span class="p">:</span>
      <span class="n">existing_ids</span> <span class="o">=</span> <span class="n">bigquery_client</span><span class="p">.</span><span class="nf">query</span><span class="p">(</span><span class="n">query</span><span class="p">).</span><span class="nf">to_dataframe</span><span class="p">()</span>
      <span class="n">existing_ids</span> <span class="o">=</span> <span class="nf">set</span><span class="p">(</span><span class="n">existing_ids</span><span class="p">[</span><span class="sh">'</span><span class="s">id</span><span class="sh">'</span><span class="p">])</span>
      <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span>
         <span class="o">~</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">id</span><span class="sh">'</span><span class="p">].</span><span class="nf">isin</span><span class="p">(</span><span class="n">existing_ids</span><span class="p">)</span>
      <span class="p">].</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
   <span class="k">except</span><span class="p">:</span>
      <span class="n">df</span> <span class="o">=</span> <span class="n">df</span>
</code></pre></div>    </div>
  </div>
</details>

<p>3) I created the prompt to be sent to OpenAI.</p>

<details>
<summary>System Prompt</summary>
<div>
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   our task is to summarize customer inquiry details into a single sentence in Korean.
   Keep in mind that the customer is from a blockchain hardware and app wallet service company.
   The summary must be provided in a single sentence in Korean, and sensitive personal information or links must be removed.
</code></pre></div>    </div>
  </div>
</details>

<details>
<summary>User Prompt</summary>
<div>
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>      Below is a customer inquiry.
      Summarize this text into a single sentence in Korean.

      Customer inquiry:
      {text}

      Format of extraction: One sentence in Korean
      Constraints:

      1. Remember that the customer is from a blockchain hardware and app wallet service company.
      2. Summarize in Korean only. (However, proper nouns that cannot be translated may remain in English.)
      3. Respond in only one sentence.
      4. Ensure that sensitive personal information is removed. (e.g., personal details, wallet addresses, contact information, passwords, private keys, mnemonic phrases, email addresses, IP addresses, URLs, social media accounts, etc.)

      Extraction result:
</code></pre></div>    </div>
  </div>
</details>

<p>4) I performed the OpenAI summarization task by iterating over each ticket.</p>

<details>
<summary>View Code</summary>
<div>
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   <span class="c1"># Define the system prompt for OpenAI
</span>   <span class="n">prompt_system</span> <span class="o">=</span> <span class="sh">'''</span><span class="s">
   our task is to summarize customer inquiry details into a single sentence in Korean.
   Keep in mind that the customer is from a blockchain hardware and app wallet service company.
   The summary must be provided in a single sentence in Korean, and sensitive personal information or links must be removed.
   </span><span class="sh">'''</span>

   <span class="c1"># Start the OpenAI API Request for each row
</span>   <span class="n">summaries_list</span> <span class="o">=</span> <span class="p">[]</span>

   <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">df</span><span class="p">)):</span>

      <span class="c1"># Subject + Description
</span>      <span class="n">text</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="sh">'</span><span class="s">subject</span><span class="sh">'</span><span class="p">]</span> <span class="o">+</span> <span class="sh">'</span><span class="s"> </span><span class="sh">'</span> <span class="o">+</span> <span class="n">df</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="sh">'</span><span class="s">description</span><span class="sh">'</span><span class="p">]</span>
      <span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="p">[:</span><span class="mi">2000</span><span class="p">]</span> <span class="c1"># Limit length to 2,000 characters (to save costs)
</span>
      <span class="c1"># Define the individual prompt for API Request
</span>      <span class="n">prompt_individual</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">'''</span><span class="s">
      Below is a customer inquiry.
      Summarize this text into a single sentence in Korean.

      Customer inquiry:
      </span><span class="si">{</span><span class="n">text</span><span class="si">}</span><span class="s">

      Format of extraction: One sentence in Korean
      Constraints:

      1. Remember that the customer is from a blockchain hardware and app wallet service company.
      2. Summarize in Korean only. (However, proper nouns that cannot be translated may remain in English.)
      3. Respond in only one sentence.
      4. Ensure that sensitive personal information is removed. (e.g., personal details, wallet addresses, contact information, passwords, private keys, mnemonic phrases, email addresses, IP addresses, URLs, social media accounts, etc.)

      Extraction result:
      </span><span class="sh">'''</span>

      <span class="c1"># Start the API Request
</span>      <span class="n">result</span> <span class="o">=</span> <span class="n">openai_client</span><span class="p">.</span><span class="n">chat</span><span class="p">.</span><span class="n">completions</span><span class="p">.</span><span class="nf">create</span><span class="p">(</span>
            <span class="n">model</span> <span class="o">=</span> <span class="sh">'</span><span class="s">gpt-4</span><span class="sh">'</span><span class="p">,</span>
            <span class="n">max_tokens</span> <span class="o">=</span> <span class="mi">200</span><span class="p">,</span>
            <span class="n">n</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
            <span class="n">temperature</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
            <span class="n">stop</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span>
            <span class="n">messages</span> <span class="o">=</span> <span class="p">[</span>
               <span class="p">{</span><span class="sh">"</span><span class="s">role</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">system</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">content</span><span class="sh">"</span><span class="p">:</span> <span class="n">prompt_system</span><span class="p">},</span>
               <span class="p">{</span><span class="sh">"</span><span class="s">role</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">user</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">content</span><span class="sh">"</span><span class="p">:</span> <span class="n">prompt_individual</span><span class="p">}</span>
            <span class="p">]</span>
      <span class="p">)</span>

      <span class="c1"># Record the topic results into empty lists
</span>      <span class="n">summary_result</span> <span class="o">=</span> <span class="n">result</span><span class="p">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">message</span><span class="p">.</span><span class="n">content</span><span class="p">.</span><span class="nf">replace</span><span class="p">(</span><span class="sh">'</span><span class="se">\'</span><span class="sh">'</span><span class="p">,</span> <span class="sh">''</span><span class="p">).</span><span class="nf">replace</span><span class="p">(</span><span class="sh">'</span><span class="se">\"</span><span class="sh">'</span><span class="p">,</span> <span class="sh">''</span><span class="p">).</span><span class="nf">replace</span><span class="p">(</span><span class="sh">'</span><span class="s">[</span><span class="sh">'</span><span class="p">,</span> <span class="sh">''</span><span class="p">).</span><span class="nf">replace</span><span class="p">(</span><span class="sh">'</span><span class="s">]</span><span class="sh">'</span><span class="p">,</span> <span class="sh">''</span><span class="p">).</span><span class="nf">strip</span><span class="p">()</span>
      <span class="n">summaries_list</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">summary_result</span><span class="p">)</span>

   <span class="c1"># Add the summary column to the dataframe and select only the required columns
</span>   <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">openai_summary</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">summaries_list</span>
   <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span>
      <span class="sh">'</span><span class="s">id</span><span class="sh">'</span><span class="p">,</span>
      <span class="sh">'</span><span class="s">created_datetime</span><span class="sh">'</span><span class="p">,</span>
      <span class="sh">'</span><span class="s">openai_summary</span><span class="sh">'</span>
   <span class="p">]]</span>
</code></pre></div>    </div>
  </div>
</details>

<p>5) Finally, the summarized results were loaded into a BigQuery table.</p>

<details>
<summary>View Code</summary>
<div>
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   <span class="c1"># Load Data into BigQuery Table
</span>   <span class="n">table</span> <span class="o">=</span> <span class="n">bigquery_client</span><span class="p">.</span><span class="nf">get_table</span><span class="p">(</span><span class="n">bigquery_tickets_summary_table_id</span><span class="p">)</span>
   <span class="n">bigquery_client</span><span class="p">.</span><span class="nf">load_table_from_dataframe</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">table</span><span class="p">)</span>
</code></pre></div>    </div>
  </div>
</details>

<h3 id="2-dashboard-and-notification-bot">2. <strong>Dashboard and Notification Bot</strong></h3>

<h5 id="21-creating-the-dashboard-bigquery--redash">2.1. Creating the Dashboard <code class="language-plaintext highlighter-rouge">(BigQuery → Redash)</code></h5>

<p>1) I created a Redash dashboard with the following contents.</p>

<p><img src="/assets/2024-07-20-voc-dashboard/11.png" alt="" /></p>

<details>
<summary>Proportion by Topic</summary>
<div>
    <p><img src="/assets/2024-07-20-voc-dashboard/12.png" alt="" /></p>
  </div>
</details>

<details>
<summary>Trends by Topic</summary>
<div>
    <p><img src="/assets/2024-07-20-voc-dashboard/13.png" alt="" /></p>
  </div>
</details>

<details>
<summary>Trends by Keyword</summary>
<div>
    <p><img src="/assets/2024-07-20-voc-dashboard/14.png" alt="" /></p>
  </div>
</details>

<details>
<summary>Summary of Inquiries by Keyword</summary>
<div>
    <p><img src="/assets/2024-07-20-voc-dashboard/15.png" alt="" /></p>
  </div>
</details>

<details>
<summary>All Datasets</summary>
<div>
    <p><img src="/assets/2024-07-20-voc-dashboard/16.png" alt="" /></p>
  </div>
</details>

<h5 id="22-building-the-notification-bot-bigquery--slack-api">2.2. Building the Notification Bot <code class="language-plaintext highlighter-rouge">(BigQuery → Slack API)</code></h5>

<p>1) First, I wrote a BigQuery query.</p>

<details>
<summary>Extracting the detailed topics (Keywords) with the most significant increase in customer inquiries from the previous week (compared to the week before)</summary>
<div>
    <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   <span class="k">WITH</span>
   <span class="n">CTE_1w_ago_raw</span> <span class="k">AS</span> <span class="p">(</span>
      <span class="k">SELECT</span>
         <span class="n">openai_topic_2</span><span class="p">,</span>
         <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="n">id</span><span class="p">)</span> <span class="k">AS</span> <span class="n">tickets_cnt</span>
      <span class="k">FROM</span>
         <span class="nv">`bigquery_tickets_topics_table_id`</span>
      <span class="k">WHERE</span>
         <span class="n">DATE_TRUNC</span><span class="p">(</span><span class="n">DATE_ADD</span><span class="p">(</span><span class="k">CURRENT_DATE</span><span class="p">(),</span> <span class="n">INTERVAL</span> <span class="o">-</span><span class="mi">1</span> <span class="n">WEEK</span><span class="p">),</span> <span class="n">WEEK</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="nb">DATE</span><span class="p">(</span><span class="n">created_datetime</span><span class="p">)</span>
         <span class="k">AND</span> <span class="nb">DATE</span><span class="p">(</span><span class="n">created_datetime</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">DATE_TRUNC</span><span class="p">(</span><span class="k">CURRENT_DATE</span><span class="p">(),</span> <span class="n">WEEK</span><span class="p">)</span>
         <span class="k">AND</span> <span class="n">openai_topic_1</span> <span class="o">!=</span> <span class="s1">'Others'</span>
      <span class="k">GROUP</span> <span class="k">BY</span>
         <span class="mi">1</span>
   <span class="p">),</span>
   <span class="n">CTE_2w_ago_raw</span> <span class="k">AS</span> <span class="p">(</span>
      <span class="k">SELECT</span>
         <span class="n">openai_topic_2</span><span class="p">,</span>
         <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="n">id</span><span class="p">)</span> <span class="k">AS</span> <span class="n">tickets_cnt</span>
      <span class="k">FROM</span>
         <span class="nv">`bigquery_tickets_topics_table_id`</span>
      <span class="k">WHERE</span>
         <span class="n">DATE_TRUNC</span><span class="p">(</span><span class="n">DATE_ADD</span><span class="p">(</span><span class="k">CURRENT_DATE</span><span class="p">(),</span> <span class="n">INTERVAL</span> <span class="o">-</span><span class="mi">2</span> <span class="n">WEEK</span><span class="p">),</span> <span class="n">WEEK</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="nb">DATE</span><span class="p">(</span><span class="n">created_datetime</span><span class="p">)</span>
         <span class="k">AND</span> <span class="nb">DATE</span><span class="p">(</span><span class="n">created_datetime</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">DATE_TRUNC</span><span class="p">(</span><span class="n">DATE_ADD</span><span class="p">(</span><span class="k">CURRENT_DATE</span><span class="p">(),</span> <span class="n">INTERVAL</span> <span class="o">-</span><span class="mi">1</span> <span class="n">WEEK</span><span class="p">),</span> <span class="n">WEEK</span><span class="p">)</span>
         <span class="k">AND</span> <span class="n">openai_topic_1</span> <span class="o">!=</span> <span class="s1">'Others'</span>
      <span class="k">GROUP</span> <span class="k">BY</span>
         <span class="mi">1</span>
   <span class="p">),</span>
   <span class="n">CTE_diff</span> <span class="k">AS</span> <span class="p">(</span>
      <span class="k">SELECT</span>
         <span class="n">COALESCE</span><span class="p">(</span><span class="n">MAIN</span><span class="p">.</span><span class="n">openai_topic_2</span><span class="p">,</span> <span class="n">COMP</span><span class="p">.</span><span class="n">openai_topic_2</span><span class="p">)</span> <span class="k">AS</span> <span class="n">openai_topic_2</span><span class="p">,</span>
         <span class="n">MAIN</span><span class="p">.</span><span class="n">tickets_cnt</span> <span class="k">AS</span> <span class="n">tickets_cnt_1w_ago</span><span class="p">,</span>
         <span class="n">COALESCE</span><span class="p">(</span><span class="n">COMP</span><span class="p">.</span><span class="n">tickets_cnt</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="k">AS</span> <span class="n">tickets_cnt_2w_ago</span><span class="p">,</span>
         <span class="n">COALESCE</span><span class="p">(</span><span class="n">MAIN</span><span class="p">.</span><span class="n">tickets_cnt</span> <span class="o">-</span> <span class="n">COMP</span><span class="p">.</span><span class="n">tickets_cnt</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="k">AS</span> <span class="n">tickets_cnt_diff</span>
      <span class="k">FROM</span>
         <span class="n">CTE_1w_ago_raw</span> <span class="n">MAIN</span>
      <span class="k">LEFT</span> <span class="k">JOIN</span>
         <span class="n">CTE_2w_ago_raw</span> <span class="n">COMP</span>
         <span class="k">ON</span> <span class="n">MAIN</span><span class="p">.</span><span class="n">openai_topic_2</span> <span class="o">=</span> <span class="n">COMP</span><span class="p">.</span><span class="n">openai_topic_2</span>
   <span class="p">)</span>
   <span class="k">SELECT</span>
      <span class="n">openai_topic_2</span><span class="p">,</span>
      <span class="n">tickets_cnt_1w_ago</span><span class="p">,</span>
      <span class="n">tickets_cnt_2w_ago</span><span class="p">,</span>
      <span class="n">tickets_cnt_diff</span>
   <span class="k">FROM</span>
      <span class="n">CTE_diff</span>
   <span class="k">WHERE</span>
      <span class="n">tickets_cnt_diff</span> <span class="o">=</span> <span class="p">(</span><span class="k">SELECT</span> <span class="k">MAX</span><span class="p">(</span><span class="n">tickets_cnt_diff</span><span class="p">)</span> <span class="k">FROM</span> <span class="n">CTE_diff</span><span class="p">)</span>
      <span class="k">AND</span> <span class="n">tickets_cnt_diff</span> <span class="o">&gt;</span> <span class="mi">0</span>
   <span class="k">ORDER</span> <span class="k">BY</span>
      <span class="mi">1</span>
</code></pre></div>    </div>
  </div>
</details>

<p>2) I created a Slack message object.</p>

<details>
<summary>View Code</summary>
<div>
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   <span class="n">df</span> <span class="o">=</span> <span class="n">bigquery_client</span><span class="p">.</span><span class="nf">query</span><span class="p">(</span><span class="n">query</span><span class="p">).</span><span class="nf">to_dataframe</span><span class="p">()</span>

   <span class="c1"># Slack Message Title
</span>   <span class="n">message</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">'</span><span class="s">:phone: *Weekly Zendesk Summary* </span><span class="se">\n\n</span><span class="sh">'</span>
   <span class="n">message</span> <span class="o">+=</span> <span class="sa">f</span><span class="sh">'</span><span class="s">*Here are the customer inquiry topics that increased the most in the past week.* </span><span class="se">\n</span><span class="sh">'</span>

   <span class="c1"># If data exists
</span>   <span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
      <span class="n">topics</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">openai_topic_2</span><span class="sh">'</span><span class="p">].</span><span class="nf">tolist</span><span class="p">()</span>
      <span class="n">tickets_cnt_1w_agos</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">tickets_cnt_1w_ago</span><span class="sh">'</span><span class="p">].</span><span class="nf">tolist</span><span class="p">()</span>
      <span class="n">tickets_cnt_diffs</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">tickets_cnt_diff</span><span class="sh">'</span><span class="p">].</span><span class="nf">tolist</span><span class="p">()</span>
      <span class="c1"># Create Slack message
</span>      <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">topic</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">topics</span><span class="p">):</span>
         <span class="n">message</span> <span class="o">+=</span> <span class="sa">f</span><span class="sh">'</span><span class="s">- *</span><span class="si">{</span><span class="n">topic</span><span class="si">}</span><span class="s">*: Total </span><span class="si">{</span><span class="n">tickets_cnt_1w_agos</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s"> cases (Compared to the previous week +</span><span class="si">{</span><span class="n">tickets_cnt_diffs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s">) </span><span class="se">\n</span><span class="sh">'</span>

   <span class="c1"># If no data exists
</span>   <span class="k">else</span><span class="p">:</span>
      <span class="n">message</span> <span class="o">+=</span> <span class="sa">f</span><span class="sh">'</span><span class="s">- *There are no topics that increased.*:smile: </span><span class="se">\n\n</span><span class="sh">'</span>
</code></pre></div>    </div>
  </div>
</details>

<p>3) Every Monday at 9:00 AM, the following Slack notification was sent.</p>

<p><img src="/assets/2024-07-20-voc-dashboard/10-en.png" alt="" /></p>

<hr />

<h1 id="5-results">5. Results</h1>

<blockquote>
  <ol>
    <li><strong>Cost Savings</strong>
      <ul>
        <li>We solved the problem internally at a cost of $25 per month, avoiding the need for an external service that would have cost $300 per month.</li>
      </ul>
    </li>
    <li><strong>Time Savings</strong>
      <ul>
        <li>The time required for internal team members to follow up on VOC, identify issues, and respond was significantly reduced.</li>
      </ul>
    </li>
  </ol>
</blockquote>

<h3 id="1-cost-savings">1. <strong>Cost Savings</strong></h3>

<p>Conclusion)  By developing internally, we were able to eliminate approximately $275 in opportunity costs each month.</p>

<table>
  <tbody>
    <tr>
      <td> </td>
      <td><strong>External VOC Analysis Service</strong></td>
      <td><strong>Internal Development</strong></td>
    </tr>
    <tr>
      <td>Monthly Cost</td>
      <td><code class="language-plaintext highlighter-rouge">$300</code></td>
      <td><code class="language-plaintext highlighter-rouge">$25</code></td>
    </tr>
  </tbody>
</table>

<p>1) External VOC Analysis Service</p>
<ul>
  <li>The <a href="https://www.syncly.kr/">syncly</a> service we considered adopting required a minimum monthly cost of $299.</li>
</ul>

<p><img src="/assets/2024-07-20-voc-dashboard/8.png" alt="" /></p>

<p>2) Internal Development</p>
<ul>
  <li>However, internal development required the following costs:</li>
</ul>

<table>
  <tbody>
    <tr>
      <td><strong>Resource</strong></td>
      <td><strong>Monthly Cost</strong></td>
    </tr>
    <tr>
      <td>1. OpenAI API</td>
      <td><code class="language-plaintext highlighter-rouge">$25</code></td>
    </tr>
    <tr>
      <td>2. BigQuery Storage</td>
      <td>Minimal</td>
    </tr>
    <tr>
      <td>3. BigQuery Query Usage</td>
      <td>Negligible</td>
    </tr>
    <tr>
      <td>4. VM Instance Operation</td>
      <td>Minimal, as we used existing instances</td>
    </tr>
    <tr>
      <td><strong>TOTAL</strong></td>
      <td><code class="language-plaintext highlighter-rouge">$25</code> + e</td>
    </tr>
  </tbody>
</table>

<p><img src="/assets/2024-07-20-voc-dashboard/9.png" alt="ㅇㅇㅇ" /></p>
<blockquote>
  <p>Daily OpenAI API Costs</p>
</blockquote>

<h3 id="2-time-savings">2. <strong>Time Savings</strong></h3>

<p>1) Redash VOC Dashboard (Topic Categorization)</p>
<ul>
  <li>Improved <u>the ease of identifying</u> VOC issues for internal team members.</li>
</ul>

<p>2) Redash VOC Dashboard (Summarization)</p>
<ul>
  <li>Enhanced <u>the follow-up speed</u> on VOC and improved <u>accessibility</u> for internal team members.</li>
</ul>

<p>3) Slack Notification Bot</p>
<ul>
  <li>Improved issue <u>identification</u> and <u>response speed</u> by sharing the topics with the highest increase in inquiries with internal team members each week, contributing to <u>a shared understanding of the context</u>.</li>
</ul>

<hr />

<h2 id="published-by-joshua-kim"><em>Published by</em> Joshua Kim</h2>
<p><img src="/assets/profile/joshua-profile.png" alt="Joshua Kim" /></p>]]></content><author><name></name></author><category term="English" /><category term="Python" /><category term="BigQuery" /><category term="Redash" /><category term="Data Visualization" /><category term="LLM" /><summary type="html"><![CDATA[“I learned that internal team members were facing difficulties in following up on Zendesk customer inquiries, so I developed a Redash VOC dashboard to address this issue. The system automatically collected and preprocessed Zendesk data, then used the OpenAI API to categorize and summarize customer inquiries by topic. Additionally, a Slack notification was set up to alert the team each Monday about the topics with the highest increase in inquiries, helping identify and respond to customer issues more efficiently. As a result, we were able to eliminate about $275 in opportunity costs each month and reduce the time spent by team members on VOC follow-ups.”]]></summary></entry><entry><title type="html">데이터 기반 VOC 분석 및 자동화 대시보드 구축: 비용 절감과 효율성 극대화</title><link href="http://localhost:4000/voc-dashboard-ko/" rel="alternate" type="text/html" title="데이터 기반 VOC 분석 및 자동화 대시보드 구축: 비용 절감과 효율성 극대화" /><published>2024-07-20T00:00:00+09:00</published><updated>2024-07-20T00:00:00+09:00</updated><id>http://localhost:4000/voc-dashboard-ko</id><content type="html" xml:base="http://localhost:4000/voc-dashboard-ko/"><![CDATA[<blockquote>
  <p>“사내 구성원 분들이 젠데스크 고객 문의 내역 팔로업에 어려움을 겪고 있다는 사실을 공유 받아, 이를 해결하기 위해 Redash VOC 대시보드를 구축했습니다. 젠데스크 데이터를 자동으로 수집하고 전처리한 후, OpenAI API를 활용해 고객 문의 내역을 주제별로 분류하고 요약했습니다. 추가적으로, 매주 월요일마다 가장 많이 증가한 문의 주제를 슬랙으로 알림을 보내어, 고객 이슈를 효율적으로 식별하고 대응할 수 있도록 기여했습니다. 결과적으로 매월 약 $275 기회 비용을 제거할 수 있었으며, 사내 구성원 분들의 VOC 팔로업 시간을 감소시키는 성과를 얻었습니다.”</p>
</blockquote>

<hr />

<h1 id="목차">목차</h1>
<ol>
  <li>STAR Summary</li>
  <li>Situation</li>
  <li>Tasks</li>
  <li>Actions</li>
  <li>Results</li>
</ol>

<hr />

<h1 id="1-star-summary">1. STAR Summary</h1>

<h3 id="situation">Situation</h3>
<ul>
  <li>사내 구성원 분들이 젠데스크 고객 문의 내역을 효율적으로 추적하고 팔로업하는 데 어려움을 겪고 있었습니다. 모든 내역을 읽는 것은 지나치게 <strong>많은 시간과 노력</strong>을 요구했으며, 외부 VOC 분석 서비스를 도입하기에는 <strong>비용의 부담</strong>이 있었습니다.</li>
</ul>

<h3 id="tasks">Tasks</h3>
<ol>
  <li>고객 문의 내역의 <strong>주제를 분류하고 요약</strong>하여, Redash VOC <strong>대시보드</strong>를 만들기로 결정했습니다.</li>
  <li>가장 긴급한 고객 문의 주제를 알려주는 <strong>슬랙 알림 봇</strong>을 구축하기로 결정했습니다.</li>
</ol>

<h3 id="actions">Actions</h3>
<ol>
  <li>
    <p><strong>데이터 파이프라인</strong></p>

    <p>1.1. 데이터 수집 및 전처리 <code class="language-plaintext highlighter-rouge">(Zendesk Tickets → Google Sheets → BigQuery)</code></p>

    <p>1.2. 주제 분류 <code class="language-plaintext highlighter-rouge">(OpenAI API)</code></p>

    <p>1.3. 요약하기 <code class="language-plaintext highlighter-rouge">(OpenAI API)</code></p>
  </li>
  <li>
    <p><strong>대시보드와 알림 봇</strong></p>

    <p>2.1. 대시보드 만들기 <code class="language-plaintext highlighter-rouge">(BigQuery → Redash)</code></p>

    <p>2.2. 알림 봇 구축하기 <code class="language-plaintext highlighter-rouge">(BigQuery → Slack API)</code></p>
  </li>
</ol>

<h3 id="results">Results</h3>
<ol>
  <li><strong>비용 절약</strong>
    <ul>
      <li>월 $300 비용의 외부 서비스를 도입하지 않고도, 내부 개발을 통해 월 $25 비용 만으로 문제를 해소했습니다.</li>
    </ul>
  </li>
  <li><strong>시간 절감</strong>
    <ul>
      <li>사내 구성원 분들의 VOC 팔로업, 이슈 식별과 대응 속도를 향상시켰습니다.</li>
    </ul>
  </li>
</ol>

<hr />

<h1 id="2-situation">2. Situation</h1>

<blockquote>
  <p>사내 구성원 분들이 젠데스크 고객 문의 내역을 효율적으로 추적하고 팔로업하는 데 어려움을 겪고 있었습니다. 모든 내역을 읽는 것은 지나치게 <strong>많은 시간과 노력</strong>을 요구했으며, 외부 VOC 분석 서비스를 도입하기에는 <strong>비용의 부담</strong>이 있었습니다.</p>
</blockquote>

<h3 id="구체적인-상황">구체적인 상황</h3>
<ul>
  <li>매주 수십-수백개의 고객 문의 내역을 일일이 팔로업하는 과정에서 너무 많은 시간이 소모되고 있었습니다.</li>
  <li>정확히 어떤 항목이 CX에 악영향을 끼치고 있는지 흐름을 파악하기 어려웠습니다.</li>
</ul>

<h3 id="사내-구성원-분들의-말말말">사내 구성원 분들의 말말말</h3>
<ul>
  <li><strong>임원 1</strong>: “주기적으로 문의 내역을 읽으며 고객의 감을 잡아가고 있는데, 양이 너무 많아 시간 소모가 커요.”</li>
  <li><strong>임원 2</strong>: “VOC 분석을 위한 외부 서비스를 도입하고 싶지만 가격이 너무 비싸서 고민하고 있어요.”</li>
  <li><strong>CX 담당자</strong>: “CX 및 VOC 현황을 좀 더 많은 동료들에게 공유하고, 이슈 대응 속도를 개선하고 싶어요.”</li>
</ul>

<hr />

<h1 id="3-tasks">3. Tasks</h1>

<blockquote>
  <ol>
    <li>고객 문의 내역의 <strong>주제를 분류하고 요약</strong>하여, Redash VOC <strong>대시보드</strong>를 만들기로 결정했습니다.</li>
    <li>가장 긴급한 고객 문의 주제를 알려주는 <strong>슬랙 알림 봇</strong>을 구축하기로 결정했습니다.</li>
  </ol>
</blockquote>

<p><img src="/assets/2024-07-20-voc-dashboard/1.png" alt="" /></p>

<hr />

<h1 id="4-actions">4. Actions</h1>

<blockquote>
  <ol>
    <li>
      <p><strong>데이터 파이프라인</strong></p>

      <p>1.1. 데이터 수집 및 전처리 <code class="language-plaintext highlighter-rouge">(Zendesk Tickets → Google Sheets → BigQuery)</code></p>

      <p>1.2. 주제 분류 <code class="language-plaintext highlighter-rouge">(OpenAI API)</code></p>

      <p>1.3. 요약하기 <code class="language-plaintext highlighter-rouge">(OpenAI API)</code></p>
    </li>
    <li>
      <p><strong>대시보드와 알림 봇</strong></p>

      <p>2.1. 대시보드 만들기 <code class="language-plaintext highlighter-rouge">(BigQuery → Redash)</code></p>

      <p>2.2. 알림 봇 구축하기 <code class="language-plaintext highlighter-rouge">(BigQuery → Slack API)</code></p>
    </li>
  </ol>
</blockquote>

<h3 id="1-데이터-파이프라인">1. <strong>데이터 파이프라인</strong></h3>

<p><img src="/assets/2024-07-20-voc-dashboard/2-ko.png" alt="" /></p>

<h5 id="11-데이터-수집-및-전처리-zendesk-tickets--google-sheets--bigquery">1.1. 데이터 수집 및 전처리 <code class="language-plaintext highlighter-rouge">(Zendesk Tickets → Google Sheets → BigQuery)</code></h5>

<p><img src="/assets/2024-07-20-voc-dashboard/3-ko.png" alt="" /></p>

<p>1) 먼저 Google Workspace Marketplace에서 제공하는 <strong>Zendesk Connector</strong>를 통해 답변이 완료된 젠데스크 티켓 데이터를 사내 비공개 구글 시트에 자동으로 저장될 수 있도록 설정했습니다.</p>

<p><img src="/assets/2024-07-20-voc-dashboard/4.png" alt="" /></p>

<p>2) Python에서 구글 시트 데이터를 로드했습니다.</p>

<details>
<summary>코드 확인하기</summary>
<div>
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   <span class="c1"># 구글 시트 Raw Data 불러오기 (to `df`)
</span>   <span class="n">gc</span> <span class="o">=</span> <span class="n">gspread</span><span class="p">.</span><span class="nf">service_account</span><span class="p">(</span><span class="n">google_sheets_credentials_fpath</span><span class="p">)</span>
   <span class="n">spreadsheet</span> <span class="o">=</span> <span class="n">gc</span><span class="p">.</span><span class="nf">open_by_url</span><span class="p">(</span><span class="n">google_sheets_url</span><span class="p">)</span>
   <span class="n">sheet</span> <span class="o">=</span> <span class="n">spreadsheet</span><span class="p">.</span><span class="nf">worksheet</span><span class="p">(</span><span class="n">google_sheets_worksheet_name</span><span class="p">)</span>
   <span class="n">sheet_data</span> <span class="o">=</span> <span class="n">sheet</span><span class="p">.</span><span class="nf">get_all_records</span><span class="p">()</span>
   <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">sheet_data</span><span class="p">)</span>
</code></pre></div>    </div>
  </div>
</details>

<p>3) 그런 후, 데이터 전처리를 진행했습니다.</p>

<details>
<summary>필요한 칼럼만 필터링</summary>
<div>
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   <span class="c1"># 칼럼 이름 재정의하기
</span>   <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">rename</span><span class="p">(</span>
      <span class="n">columns</span><span class="o">=</span><span class="p">{</span>
         <span class="sh">'</span><span class="s">created_at</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">created_datetime</span><span class="sh">'</span><span class="p">,</span>
         <span class="sh">'</span><span class="s">raw_subject</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">subject</span><span class="sh">'</span><span class="p">,</span>
         <span class="sh">'</span><span class="s">tags.0</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">zendesk_topic</span><span class="sh">'</span><span class="p">,</span>
         <span class="sh">'</span><span class="s">updated_at</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">updated_datetime</span><span class="sh">'</span>
      <span class="p">}</span>
   <span class="p">)</span>
   <span class="c1"># 필요한 칼럼만 뽑아내기
</span>   <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span>
      <span class="sh">'</span><span class="s">id</span><span class="sh">'</span><span class="p">,</span>
      <span class="sh">'</span><span class="s">created_datetime</span><span class="sh">'</span><span class="p">,</span>
      <span class="sh">'</span><span class="s">zendesk_topic</span><span class="sh">'</span><span class="p">,</span>
      <span class="sh">'</span><span class="s">subject</span><span class="sh">'</span><span class="p">,</span>
      <span class="sh">'</span><span class="s">description</span><span class="sh">'</span>
   <span class="p">]]</span>
</code></pre></div>    </div>
  </div>
</details>

<details>
<summary>시간대 변경 (UTC → KST)</summary>
<div>
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   <span class="c1"># 기존 타임스탬프: UTC to KST 변환해주기
</span>   <span class="n">kst</span> <span class="o">=</span> <span class="n">pytz</span><span class="p">.</span><span class="nf">timezone</span><span class="p">(</span><span class="sh">'</span><span class="s">Asia/Seoul</span><span class="sh">'</span><span class="p">)</span>
   <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">created_datetime</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">created_datetime</span><span class="sh">'</span><span class="p">],</span> <span class="n">utc</span><span class="o">=</span><span class="bp">True</span><span class="p">).</span><span class="n">dt</span><span class="p">.</span><span class="nf">tz_convert</span><span class="p">(</span><span class="n">kst</span><span class="p">).</span><span class="n">dt</span><span class="p">.</span><span class="nf">tz_localize</span><span class="p">(</span><span class="bp">None</span><span class="p">)</span>
   <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">astype</span><span class="p">(</span><span class="sh">'</span><span class="s">str</span><span class="sh">'</span><span class="p">)</span> <span class="c1"># BigQuery에 Load할 때, 기본적으로 모두 String 타입이 되어야 하므로, 어쩔 수 없이 모두 String으로 Casting한다.
</span></code></pre></div>    </div>
  </div>
</details>

<details>
<summary>신규 항목들만 필터링</summary>
<div>
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   <span class="c1"># 이미 타겟 테이블에 존재하는 행을 제거해주기 (중복 방지)
</span>   <span class="n">query</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">'</span><span class="s">SELECT DISTINCT id FROM `</span><span class="si">{</span><span class="n">bigquery_tickets_table_id</span><span class="si">}</span><span class="s">`</span><span class="sh">'</span>
   <span class="k">try</span><span class="p">:</span>
      <span class="n">existing_ids</span> <span class="o">=</span> <span class="n">client</span><span class="p">.</span><span class="nf">query</span><span class="p">(</span><span class="n">query</span><span class="p">).</span><span class="nf">to_dataframe</span><span class="p">()</span>
      <span class="n">existing_ids</span> <span class="o">=</span> <span class="nf">set</span><span class="p">(</span><span class="n">existing_ids</span><span class="p">[</span><span class="sh">'</span><span class="s">id</span><span class="sh">'</span><span class="p">])</span>
      <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span>
         <span class="o">~</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">id</span><span class="sh">'</span><span class="p">].</span><span class="nf">isin</span><span class="p">(</span><span class="n">existing_ids</span><span class="p">)</span>
      <span class="p">].</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
   <span class="k">except</span><span class="p">:</span>
      <span class="n">df</span> <span class="o">=</span> <span class="n">df</span>
</code></pre></div>    </div>
  </div>
</details>

<p>4) 마지막으로 BigQuery 테이블에 적재했습니다.</p>

<details>
<summary>코드 확인하기</summary>
<div>
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   <span class="c1"># 빅쿼리 테이블에 적재하기
</span>   <span class="n">table</span> <span class="o">=</span> <span class="n">client</span><span class="p">.</span><span class="nf">get_table</span><span class="p">(</span><span class="n">bigquery_tickets_table_id</span><span class="p">)</span>
   <span class="n">client</span><span class="p">.</span><span class="nf">load_table_from_dataframe</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">table</span><span class="p">)</span>
</code></pre></div>    </div>
  </div>
</details>

<h5 id="12-주제-분류-openai-api">1.2. 주제 분류 <code class="language-plaintext highlighter-rouge">(OpenAI API)</code></h5>

<p><img src="/assets/2024-07-20-voc-dashboard/5-ko.png" alt="" /></p>

<p>1) 분류할 주제 목록을 사전에 정의하기 위해, CX 담당자 및 UX/UI 디자이너 분과 함께 논의 후 분류 체계를 세웠습니다.</p>
<ul>
  <li><strong>Topic</strong>: 넓은 범주의 주제</li>
  <li><strong>Keyword</strong>: 구체적인 세부 주제</li>
</ul>

<p><img src="/assets/2024-07-20-voc-dashboard/6.png" alt="" /></p>

<p>2) Python에서 BigQuery 테이블의 데이터를 로드했습니다.</p>

<details>
<summary>코드 확인하기</summary>
<div>
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   <span class="c1"># BigQuery `tickets` 테이블 불러오기 (to `df`)
</span>   <span class="n">query</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">'</span><span class="s">SELECT * FROM </span><span class="si">{</span><span class="n">bigquery_tickets_table_id</span><span class="si">}</span><span class="sh">'</span>
   <span class="n">df</span> <span class="o">=</span> <span class="n">bigquery_client</span><span class="p">.</span><span class="nf">query</span><span class="p">(</span><span class="n">query</span><span class="p">).</span><span class="nf">to_dataframe</span><span class="p">()</span>
</code></pre></div>    </div>
  </div>
</details>

<p>3) 그 중, 신규 항목들만 필터링했습니다.</p>

<details>
<summary>코드 확인하기</summary>
<div>
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   <span class="c1"># 이미 타겟 테이블에 존재하는 행을 제거해주기 (중복 제거)
</span>   <span class="n">query</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">'</span><span class="s">SELECT DISTINCT id FROM `</span><span class="si">{</span><span class="n">bigquery_tickets_topics_table_id</span><span class="si">}</span><span class="s">`</span><span class="sh">'</span>
   <span class="k">try</span><span class="p">:</span>
      <span class="n">existing_ids</span> <span class="o">=</span> <span class="n">bigquery_client</span><span class="p">.</span><span class="nf">query</span><span class="p">(</span><span class="n">query</span><span class="p">).</span><span class="nf">to_dataframe</span><span class="p">()</span>
      <span class="n">existing_ids</span> <span class="o">=</span> <span class="nf">set</span><span class="p">(</span><span class="n">existing_ids</span><span class="p">[</span><span class="sh">'</span><span class="s">id</span><span class="sh">'</span><span class="p">])</span>
      <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span>
         <span class="o">~</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">id</span><span class="sh">'</span><span class="p">].</span><span class="nf">isin</span><span class="p">(</span><span class="n">existing_ids</span><span class="p">)</span>
      <span class="p">].</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
   <span class="k">except</span><span class="p">:</span>
      <span class="n">df</span> <span class="o">=</span> <span class="n">df</span>
</code></pre></div>    </div>
  </div>
</details>

<p>4) OpenAI에 요청할 프롬프트를 작성했습니다.</p>

<details>
<summary>System Prompt</summary>
<div>
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   당신의 작업은 고객 문의 내역에서 하나의 핵심 키워드를 분류하는 것입니다.
   오로지 주어진 토픽 목록에서만 선택하여 응답해야 합니다.
   아래는 당신이 선택할 수 있는 토픽 목록입니다:
      {키워드 리스트}
   다른 토픽을 생성하거나 선택하지 마세요.
</code></pre></div>    </div>
  </div>
</details>

<details>
<summary>User Prompt</summary>
<div>
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   아래는 고객 문의 내역입니다.
   이 텍스트에서 하나의 핵심 토픽을 추출하세요.

   고객 문의 내역:
         {실제 텍스트}

   추출 형식: 토픽
   제한 사항: 
   1. 오로지 토픽으로만 응답하세요.
   2. 주어진 토픽 목록에서만 선택하세요. 다른 토픽을 생성하거나 선택하지 마세요.
   3. 반드시 아래 목록에서 하나를 선택하세요:
   {키워드 리스트} 

   추출 결과: 
</code></pre></div>    </div>
  </div>
</details>

<p>5) 각 티켓을 순회하며 OpenAI 주제 분류 작업을 진행했습니다.</p>

<details>
<summary>코드 확인하기</summary>
<div>
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   <span class="c1"># OpenAI에 요청할 시스템 프롬프트 정의하기
</span>   <span class="n">prompt_system</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">'''</span><span class="s">
   당신의 작업은 고객 문의 내역에서 하나의 핵심 키워드를 분류하는 것입니다.
   오로지 주어진 토픽 목록에서만 선택하여 응답해야 합니다.
   아래는 당신이 선택할 수 있는 토픽 목록입니다:
   </span><span class="si">{</span><span class="sh">'</span><span class="s">, </span><span class="sh">'</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="n">topics2_list</span><span class="p">)</span><span class="si">}</span><span class="s">
   다른 토픽을 생성하거나 선택하지 마세요.
   </span><span class="sh">'''</span>

   <span class="c1"># 각 행을 돌아가면서 OpenAI API Request 시작하기
</span>   <span class="n">topic2_results_list</span> <span class="o">=</span> <span class="p">[]</span>

   <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">df</span><span class="p">)):</span>

      <span class="c1"># 주제 + 본문
</span>      <span class="n">text</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="sh">'</span><span class="s">subject</span><span class="sh">'</span><span class="p">]</span> <span class="o">+</span> <span class="sh">'</span><span class="s"> </span><span class="sh">'</span> <span class="o">+</span> <span class="n">df</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="sh">'</span><span class="s">description</span><span class="sh">'</span><span class="p">]</span>
      <span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="p">[:</span><span class="mi">2000</span><span class="p">]</span> <span class="c1"># 2,000개 길이로 제한 (비용 절약)
</span>
      <span class="c1"># 개별적으로 요청할 프롬프트 정의
</span>      <span class="n">prompt_individual</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">'''</span><span class="s">
      아래는 고객 문의 내역입니다.
      이 텍스트에서 하나의 핵심 토픽을 추출하세요.

      고객 문의 내역:
      </span><span class="si">{</span><span class="n">text</span><span class="si">}</span><span class="s">

      추출 형식: 토픽
      제한 사항: 
      1. 오로지 토픽으로만 응답하세요.
      2. 주어진 토픽 목록에서만 선택하세요. 다른 토픽을 생성하거나 선택하지 마세요.
      3. 반드시 아래 목록에서 하나를 선택하세요:
      </span><span class="si">{</span><span class="sh">'</span><span class="s">, </span><span class="sh">'</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="n">topics2_list</span><span class="p">)</span><span class="si">}</span><span class="s"> 

      추출 결과: 
      </span><span class="sh">'''</span>

      <span class="c1"># API Request 시작
</span>      <span class="n">result</span> <span class="o">=</span> <span class="n">openai_client</span><span class="p">.</span><span class="n">chat</span><span class="p">.</span><span class="n">completions</span><span class="p">.</span><span class="nf">create</span><span class="p">(</span>
            <span class="n">model</span> <span class="o">=</span> <span class="sh">'</span><span class="s">gpt-4</span><span class="sh">'</span><span class="p">,</span>
            <span class="n">max_tokens</span> <span class="o">=</span> <span class="mi">500</span><span class="p">,</span>
            <span class="n">n</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
            <span class="n">temperature</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
            <span class="n">stop</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span>
            <span class="n">messages</span> <span class="o">=</span> <span class="p">[</span>
               <span class="p">{</span><span class="sh">"</span><span class="s">role</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">system</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">content</span><span class="sh">"</span><span class="p">:</span> <span class="n">prompt_system</span><span class="p">},</span>
               <span class="p">{</span><span class="sh">"</span><span class="s">role</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">user</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">content</span><span class="sh">"</span><span class="p">:</span> <span class="n">prompt_individual</span><span class="p">}</span>
            <span class="p">]</span>
      <span class="p">)</span>

      <span class="c1"># 토픽 결과를 Empty Lists에 기록하기
</span>      <span class="n">topic2_result</span> <span class="o">=</span> <span class="n">result</span><span class="p">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">message</span><span class="p">.</span><span class="n">content</span><span class="p">.</span><span class="nf">replace</span><span class="p">(</span><span class="sh">'</span><span class="se">\'</span><span class="sh">'</span><span class="p">,</span> <span class="sh">''</span><span class="p">).</span><span class="nf">replace</span><span class="p">(</span><span class="sh">'</span><span class="se">\"</span><span class="sh">'</span><span class="p">,</span> <span class="sh">''</span><span class="p">).</span><span class="nf">replace</span><span class="p">(</span><span class="sh">'</span><span class="s">[</span><span class="sh">'</span><span class="p">,</span> <span class="sh">''</span><span class="p">).</span><span class="nf">replace</span><span class="p">(</span><span class="sh">'</span><span class="s">]</span><span class="sh">'</span><span class="p">,</span> <span class="sh">''</span><span class="p">).</span><span class="nf">strip</span><span class="p">()</span>
      <span class="n">topic2_results_list</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">topic2_result</span><span class="p">)</span>

   <span class="c1"># 토픽 2 결과를 통해 토픽 1 결과도 기록하기
</span>   <span class="n">topic1_results_list</span> <span class="o">=</span> <span class="p">[]</span>
   <span class="k">for</span> <span class="n">topic2</span> <span class="ow">in</span> <span class="n">topic2_results_list</span><span class="p">:</span>
      <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">topics_list</span><span class="p">)):</span>
            <span class="k">if</span> <span class="n">topics_list</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">topic2</span><span class="p">:</span>
               <span class="n">topic1_results_list</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">topics_list</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
               <span class="k">break</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="nf">len</span><span class="p">(</span><span class="n">topics_list</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
               <span class="n">topic1_results_list</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="sh">'</span><span class="s">Others</span><span class="sh">'</span><span class="p">)</span>
      
   <span class="c1"># df에 토픽 1, 토픽 2 칼럼을 추가하고, 필요한 칼럼만 뽑아내기
</span>   <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">openai_topic_1</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">topic1_results_list</span>
   <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">openai_topic_2</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">topic2_results_list</span>
   <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span>
      <span class="sh">'</span><span class="s">id</span><span class="sh">'</span><span class="p">,</span>
      <span class="sh">'</span><span class="s">created_datetime</span><span class="sh">'</span><span class="p">,</span>
      <span class="sh">'</span><span class="s">openai_topic_1</span><span class="sh">'</span><span class="p">,</span>
      <span class="sh">'</span><span class="s">openai_topic_2</span><span class="sh">'</span>
   <span class="p">]]</span>
</code></pre></div>    </div>
  </div>
</details>

<p>6) 마지막으로, 주제 분류 결과를 BigQuery 테이블에 적재했습니다.</p>

<details>
<summary>코드 확인하기</summary>
<div>
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   <span class="c1"># 빅쿼리 테이블에 적재하기
</span>   <span class="n">table</span> <span class="o">=</span> <span class="n">bigquery_client</span><span class="p">.</span><span class="nf">get_table</span><span class="p">(</span><span class="n">bigquery_tickets_topics_table_id</span><span class="p">)</span>
   <span class="n">bigquery_client</span><span class="p">.</span><span class="nf">load_table_from_dataframe</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">table</span><span class="p">)</span>
</code></pre></div>    </div>
  </div>
</details>

<h5 id="13-요약하기-openai-api">1.3. 요약하기 <code class="language-plaintext highlighter-rouge">(OpenAI API)</code></h5>

<p><img src="/assets/2024-07-20-voc-dashboard/7-ko.png" alt="" /></p>

<p>1) Python에서 BigQuery 테이블의 데이터를 로드했습니다.</p>

<details>
<summary>코드 확인하기</summary>
<div>
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   <span class="c1"># BigQuery `tickets` 테이블 불러오기 (to `df`)
</span>   <span class="n">query</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">'</span><span class="s">SELECT * FROM </span><span class="si">{</span><span class="n">bigquery_tickets_table_id</span><span class="si">}</span><span class="sh">'</span>
   <span class="n">df</span> <span class="o">=</span> <span class="n">bigquery_client</span><span class="p">.</span><span class="nf">query</span><span class="p">(</span><span class="n">query</span><span class="p">).</span><span class="nf">to_dataframe</span><span class="p">()</span>
</code></pre></div>    </div>
  </div>
</details>

<p>2) 그 중, 신규 항목들만 필터링했습니다.</p>

<details>
<summary>코드 확인하기</summary>
<div>
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   <span class="c1"># 이미 타겟 테이블에 존재하는 행을 제거해주기 (중복 제거)
</span>   <span class="n">query</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">'</span><span class="s">SELECT DISTINCT id FROM `</span><span class="si">{</span><span class="n">bigquery_tickets_summary_table_id</span><span class="si">}</span><span class="s">`</span><span class="sh">'</span>
   <span class="k">try</span><span class="p">:</span>
      <span class="n">existing_ids</span> <span class="o">=</span> <span class="n">bigquery_client</span><span class="p">.</span><span class="nf">query</span><span class="p">(</span><span class="n">query</span><span class="p">).</span><span class="nf">to_dataframe</span><span class="p">()</span>
      <span class="n">existing_ids</span> <span class="o">=</span> <span class="nf">set</span><span class="p">(</span><span class="n">existing_ids</span><span class="p">[</span><span class="sh">'</span><span class="s">id</span><span class="sh">'</span><span class="p">])</span>
      <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span>
         <span class="o">~</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">id</span><span class="sh">'</span><span class="p">].</span><span class="nf">isin</span><span class="p">(</span><span class="n">existing_ids</span><span class="p">)</span>
      <span class="p">].</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
   <span class="k">except</span><span class="p">:</span>
      <span class="n">df</span> <span class="o">=</span> <span class="n">df</span>
</code></pre></div>    </div>
  </div>
</details>

<p>3) OpenAI에 요청할 프롬프트를 작성했습니다.</p>

<details>
<summary>System Prompt</summary>
<div>
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   당신의 작업은 고객 문의 내역을 한국어 한 문장으로 요약하는 것입니다.
   블록체인 하드웨어 및 앱 지갑 서비스 기업의 고객임을 기억하세요.
   요약은 반드시 한국어 한 문장으로 제공되어야 하며, 민감한 개인정보나 링크는 반드시 제거되어야 합니다.
</code></pre></div>    </div>
  </div>
</details>

<details>
<summary>User Prompt</summary>
<div>
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   아래는 고객 문의 내역입니다.
   이 텍스트를 한국어 하나의 문장으로 요약하세요.

   고객 문의 내역:
   {실제 텍스트}

   추출 형식: 한국어 한 문장
   제한 사항:
   1. 블록체인 하드웨어 및 앱 지갑 서비스 기업의 고객임을 기억하세요.
   2. 반드시 한국어로 요약하세요. (단, 번역이 불가능한 고유 단어는 영어 가능)
   3. 오로지 한 문장으로만 응답하세요.
   4. 민감한 개인정보는 반드시 제거하세요.
   
   추출 결과:  
</code></pre></div>    </div>
  </div>
</details>

<p>4) 각 티켓을 순회하며 OpenAI 요약 작업을 진행했습니다.</p>

<details>
<summary>코드 확인하기</summary>
<div>
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   <span class="c1"># OpenAI에 요청할 시스템 프롬프트 정의하기
</span>   <span class="n">prompt_system</span> <span class="o">=</span> <span class="sh">'''</span><span class="s">
   당신의 작업은 고객 문의 내역을 한국어 한 문장으로 요약하는 것입니다.
   블록체인 하드웨어 및 앱 지갑 서비스 기업의 고객임을 기억하세요.
   요약은 반드시 한국어 한 문장으로 제공되어야 하며, 민감한 개인정보나 링크는 반드시 제거되어야 합니다.
   </span><span class="sh">'''</span>

   <span class="c1"># 각 행을 돌아가면서 OpenAI API Request 시작하기
</span>   <span class="n">summaries_list</span> <span class="o">=</span> <span class="p">[]</span>

   <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">df</span><span class="p">)):</span>

      <span class="c1"># 주제 + 본문
</span>      <span class="n">text</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="sh">'</span><span class="s">subject</span><span class="sh">'</span><span class="p">]</span> <span class="o">+</span> <span class="sh">'</span><span class="s"> </span><span class="sh">'</span> <span class="o">+</span> <span class="n">df</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="sh">'</span><span class="s">description</span><span class="sh">'</span><span class="p">]</span>
      <span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="p">[:</span><span class="mi">2000</span><span class="p">]</span> <span class="c1"># 2,000개 길이로 제한 (비용 절약)
</span>
      <span class="c1"># 개별적으로 요청할 프롬프트 정의
</span>      <span class="n">prompt_individual</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">'''</span><span class="s">
      아래는 고객 문의 내역입니다.
      이 텍스트를 한국어 하나의 문장으로 요약하세요.

      고객 문의 내역:
      </span><span class="si">{</span><span class="n">text</span><span class="si">}</span><span class="s">

      추출 형식: 한국어 한 문장
      제한 사항:
      1. 블록체인 하드웨어 및 앱 지갑 서비스 기업의 고객임을 기억하세요.
      2. 반드시 한국어로 요약하세요. (단, 번역이 불가능한 고유 단어는 영어 가능)
      3. 오로지 한 문장으로만 응답하세요.
      4. 민감한 개인정보는 반드시 제거하세요. (예: 인적사항, 지갑주소, 연락처, 비밀번호, 개인키, 니모닉, 이메일 주소, IP 주소, URL, 소셜 미디어 계정 등)
      
      추출 결과: 
      </span><span class="sh">'''</span>

      <span class="c1"># API Request 시작
</span>      <span class="n">result</span> <span class="o">=</span> <span class="n">openai_client</span><span class="p">.</span><span class="n">chat</span><span class="p">.</span><span class="n">completions</span><span class="p">.</span><span class="nf">create</span><span class="p">(</span>
            <span class="n">model</span> <span class="o">=</span> <span class="sh">'</span><span class="s">gpt-4</span><span class="sh">'</span><span class="p">,</span>
            <span class="n">max_tokens</span> <span class="o">=</span> <span class="mi">200</span><span class="p">,</span>
            <span class="n">n</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
            <span class="n">temperature</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
            <span class="n">stop</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span>
            <span class="n">messages</span> <span class="o">=</span> <span class="p">[</span>
               <span class="p">{</span><span class="sh">"</span><span class="s">role</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">system</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">content</span><span class="sh">"</span><span class="p">:</span> <span class="n">prompt_system</span><span class="p">},</span>
               <span class="p">{</span><span class="sh">"</span><span class="s">role</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">user</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">content</span><span class="sh">"</span><span class="p">:</span> <span class="n">prompt_individual</span><span class="p">}</span>
            <span class="p">]</span>
      <span class="p">)</span>

      <span class="c1"># 토픽 결과를 Empty Lists에 기록하기
</span>      <span class="n">summary_result</span> <span class="o">=</span> <span class="n">result</span><span class="p">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">message</span><span class="p">.</span><span class="n">content</span><span class="p">.</span><span class="nf">replace</span><span class="p">(</span><span class="sh">'</span><span class="se">\'</span><span class="sh">'</span><span class="p">,</span> <span class="sh">''</span><span class="p">).</span><span class="nf">replace</span><span class="p">(</span><span class="sh">'</span><span class="se">\"</span><span class="sh">'</span><span class="p">,</span> <span class="sh">''</span><span class="p">).</span><span class="nf">replace</span><span class="p">(</span><span class="sh">'</span><span class="s">[</span><span class="sh">'</span><span class="p">,</span> <span class="sh">''</span><span class="p">).</span><span class="nf">replace</span><span class="p">(</span><span class="sh">'</span><span class="s">]</span><span class="sh">'</span><span class="p">,</span> <span class="sh">''</span><span class="p">).</span><span class="nf">strip</span><span class="p">()</span>
      <span class="n">summaries_list</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">summary_result</span><span class="p">)</span>

   <span class="c1"># df에 요약 칼럼을 추가하고, 필요한 칼럼만 뽑아내기
</span>   <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">openai_summary</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">summaries_list</span>
   <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span>
      <span class="sh">'</span><span class="s">id</span><span class="sh">'</span><span class="p">,</span>
      <span class="sh">'</span><span class="s">created_datetime</span><span class="sh">'</span><span class="p">,</span>
      <span class="sh">'</span><span class="s">openai_summary</span><span class="sh">'</span>
   <span class="p">]]</span>
</code></pre></div>    </div>
  </div>
</details>

<p>5) 마지막으로, 요약 결과를 BigQuery 테이블에 적재했습니다.</p>

<details>
<summary>코드 확인하기</summary>
<div>
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   <span class="c1"># 빅쿼리 테이블에 적재하기
</span>   <span class="n">table</span> <span class="o">=</span> <span class="n">bigquery_client</span><span class="p">.</span><span class="nf">get_table</span><span class="p">(</span><span class="n">bigquery_tickets_summary_table_id</span><span class="p">)</span>
   <span class="n">bigquery_client</span><span class="p">.</span><span class="nf">load_table_from_dataframe</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">table</span><span class="p">)</span>
</code></pre></div>    </div>
  </div>
</details>

<h3 id="2-대시보드와-알림-봇">2. <strong>대시보드와 알림 봇</strong></h3>

<h5 id="21-대시보드-만들기-bigquery--redash">2.1. 대시보드 만들기 <code class="language-plaintext highlighter-rouge">(BigQuery → Redash)</code></h5>

<p>1) 다음 내용을 지닌 Redash 대시보드를 생성했습니다.</p>

<p><img src="/assets/2024-07-20-voc-dashboard/11.png" alt="" /></p>

<details>
<summary>Topic별 비율</summary>
<div>
    <p><img src="/assets/2024-07-20-voc-dashboard/12.png" alt="" /></p>
  </div>
</details>

<details>
<summary>Topic별 트렌드</summary>
<div>
    <p><img src="/assets/2024-07-20-voc-dashboard/13.png" alt="" /></p>
  </div>
</details>

<details>
<summary>Keyword별 트렌드</summary>
<div>
    <p><img src="/assets/2024-07-20-voc-dashboard/14.png" alt="" /></p>
  </div>
</details>

<details>
<summary>Keyword별 문의 요약</summary>
<div>
    <p><img src="/assets/2024-07-20-voc-dashboard/15.png" alt="" /></p>
  </div>
</details>

<details>
<summary>전체 데이터</summary>
<div>
    <p><img src="/assets/2024-07-20-voc-dashboard/16.png" alt="" /></p>
  </div>
</details>

<h5 id="22-알림-봇-구축하기-bigquery--slack-api">2.2. 알림 봇 구축하기 <code class="language-plaintext highlighter-rouge">(BigQuery → Slack API)</code></h5>

<p>1) 우선, BigQuery 쿼리문을 작성했습니다.</p>

<details>
<summary>전주에 고객 문의 수가 가장 많이 증가한 세부 주제(Keyword)를 추출 (전전주 대비)</summary>
<div>
    <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   <span class="k">WITH</span>
   <span class="n">CTE_1w_ago_raw</span> <span class="k">AS</span> <span class="p">(</span>
      <span class="k">SELECT</span>
         <span class="n">openai_topic_2</span><span class="p">,</span>
         <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="n">id</span><span class="p">)</span> <span class="k">AS</span> <span class="n">tickets_cnt</span>
      <span class="k">FROM</span>
         <span class="nv">`bigquery_tickets_topics_table_id`</span>
      <span class="k">WHERE</span>
         <span class="n">DATE_TRUNC</span><span class="p">(</span><span class="n">DATE_ADD</span><span class="p">(</span><span class="k">CURRENT_DATE</span><span class="p">(),</span> <span class="n">INTERVAL</span> <span class="o">-</span><span class="mi">1</span> <span class="n">WEEK</span><span class="p">),</span> <span class="n">WEEK</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="nb">DATE</span><span class="p">(</span><span class="n">created_datetime</span><span class="p">)</span>
         <span class="k">AND</span> <span class="nb">DATE</span><span class="p">(</span><span class="n">created_datetime</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">DATE_TRUNC</span><span class="p">(</span><span class="k">CURRENT_DATE</span><span class="p">(),</span> <span class="n">WEEK</span><span class="p">)</span>
         <span class="k">AND</span> <span class="n">openai_topic_1</span> <span class="o">!=</span> <span class="s1">'Others'</span>
      <span class="k">GROUP</span> <span class="k">BY</span>
         <span class="mi">1</span>
   <span class="p">),</span>
   <span class="n">CTE_2w_ago_raw</span> <span class="k">AS</span> <span class="p">(</span>
      <span class="k">SELECT</span>
         <span class="n">openai_topic_2</span><span class="p">,</span>
         <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="n">id</span><span class="p">)</span> <span class="k">AS</span> <span class="n">tickets_cnt</span>
      <span class="k">FROM</span>
         <span class="nv">`bigquery_tickets_topics_table_id`</span>
      <span class="k">WHERE</span>
         <span class="n">DATE_TRUNC</span><span class="p">(</span><span class="n">DATE_ADD</span><span class="p">(</span><span class="k">CURRENT_DATE</span><span class="p">(),</span> <span class="n">INTERVAL</span> <span class="o">-</span><span class="mi">2</span> <span class="n">WEEK</span><span class="p">),</span> <span class="n">WEEK</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="nb">DATE</span><span class="p">(</span><span class="n">created_datetime</span><span class="p">)</span>
         <span class="k">AND</span> <span class="nb">DATE</span><span class="p">(</span><span class="n">created_datetime</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">DATE_TRUNC</span><span class="p">(</span><span class="n">DATE_ADD</span><span class="p">(</span><span class="k">CURRENT_DATE</span><span class="p">(),</span> <span class="n">INTERVAL</span> <span class="o">-</span><span class="mi">1</span> <span class="n">WEEK</span><span class="p">),</span> <span class="n">WEEK</span><span class="p">)</span>
         <span class="k">AND</span> <span class="n">openai_topic_1</span> <span class="o">!=</span> <span class="s1">'Others'</span>
      <span class="k">GROUP</span> <span class="k">BY</span>
         <span class="mi">1</span>
   <span class="p">),</span>
   <span class="n">CTE_diff</span> <span class="k">AS</span> <span class="p">(</span>
      <span class="k">SELECT</span>
         <span class="n">COALESCE</span><span class="p">(</span><span class="n">MAIN</span><span class="p">.</span><span class="n">openai_topic_2</span><span class="p">,</span> <span class="n">COMP</span><span class="p">.</span><span class="n">openai_topic_2</span><span class="p">)</span> <span class="k">AS</span> <span class="n">openai_topic_2</span><span class="p">,</span>
         <span class="n">MAIN</span><span class="p">.</span><span class="n">tickets_cnt</span> <span class="k">AS</span> <span class="n">tickets_cnt_1w_ago</span><span class="p">,</span>
         <span class="n">COALESCE</span><span class="p">(</span><span class="n">COMP</span><span class="p">.</span><span class="n">tickets_cnt</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="k">AS</span> <span class="n">tickets_cnt_2w_ago</span><span class="p">,</span>
         <span class="n">COALESCE</span><span class="p">(</span><span class="n">MAIN</span><span class="p">.</span><span class="n">tickets_cnt</span> <span class="o">-</span> <span class="n">COMP</span><span class="p">.</span><span class="n">tickets_cnt</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="k">AS</span> <span class="n">tickets_cnt_diff</span>
      <span class="k">FROM</span>
         <span class="n">CTE_1w_ago_raw</span> <span class="n">MAIN</span>
      <span class="k">LEFT</span> <span class="k">JOIN</span>
         <span class="n">CTE_2w_ago_raw</span> <span class="n">COMP</span>
         <span class="k">ON</span> <span class="n">MAIN</span><span class="p">.</span><span class="n">openai_topic_2</span> <span class="o">=</span> <span class="n">COMP</span><span class="p">.</span><span class="n">openai_topic_2</span>
   <span class="p">)</span>
   <span class="k">SELECT</span>
      <span class="n">openai_topic_2</span><span class="p">,</span>
      <span class="n">tickets_cnt_1w_ago</span><span class="p">,</span>
      <span class="n">tickets_cnt_2w_ago</span><span class="p">,</span>
      <span class="n">tickets_cnt_diff</span>
   <span class="k">FROM</span>
      <span class="n">CTE_diff</span>
   <span class="k">WHERE</span>
      <span class="n">tickets_cnt_diff</span> <span class="o">=</span> <span class="p">(</span><span class="k">SELECT</span> <span class="k">MAX</span><span class="p">(</span><span class="n">tickets_cnt_diff</span><span class="p">)</span> <span class="k">FROM</span> <span class="n">CTE_diff</span><span class="p">)</span>
      <span class="k">AND</span> <span class="n">tickets_cnt_diff</span> <span class="o">&gt;</span> <span class="mi">0</span>
   <span class="k">ORDER</span> <span class="k">BY</span>
      <span class="mi">1</span>
</code></pre></div>    </div>
  </div>
</details>

<p>2) 슬랙 메시지 객체를 작성했습니다.</p>

<details>
<summary>코드 확인하기</summary>
<div>
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   <span class="n">df</span> <span class="o">=</span> <span class="n">bigquery_client</span><span class="p">.</span><span class="nf">query</span><span class="p">(</span><span class="n">query</span><span class="p">).</span><span class="nf">to_dataframe</span><span class="p">()</span>

   <span class="c1"># Slack 메시지 제목 만들기
</span>   <span class="n">message</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">'</span><span class="s">:phone: *Weekly Zendesk 요약* </span><span class="se">\n\n</span><span class="sh">'</span>
   <span class="n">message</span> <span class="o">+=</span> <span class="sa">f</span><span class="sh">'</span><span class="s">*지난 1주 가장 많이 증가한 고객 문의 주제들입니다.* </span><span class="se">\n</span><span class="sh">'</span>

   <span class="c1"># 만약 데이터가 존재하는 경우
</span>   <span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
      <span class="n">topics</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">openai_topic_2</span><span class="sh">'</span><span class="p">].</span><span class="nf">tolist</span><span class="p">()</span>
      <span class="n">tickets_cnt_1w_agos</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">tickets_cnt_1w_ago</span><span class="sh">'</span><span class="p">].</span><span class="nf">tolist</span><span class="p">()</span>
      <span class="n">tickets_cnt_diffs</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">tickets_cnt_diff</span><span class="sh">'</span><span class="p">].</span><span class="nf">tolist</span><span class="p">()</span>
      <span class="c1"># Slack 메시지 만들기
</span>      <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">topic</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">topics</span><span class="p">):</span>
         <span class="n">message</span> <span class="o">+=</span> <span class="sa">f</span><span class="sh">'</span><span class="s">- *</span><span class="si">{</span><span class="n">topic</span><span class="si">}</span><span class="s">*: 총 </span><span class="si">{</span><span class="n">tickets_cnt_1w_agos</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s">건 (전주 대비 +</span><span class="si">{</span><span class="n">tickets_cnt_diffs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s">) </span><span class="se">\n</span><span class="sh">'</span>

   <span class="c1"># 만약 데이터가 존재하지 않는 경우
</span>   <span class="k">else</span><span class="p">:</span>
      <span class="n">message</span> <span class="o">+=</span> <span class="sa">f</span><span class="sh">'</span><span class="s">- *증가한 주제가 하나도 없어요.*:smile: </span><span class="se">\n\n</span><span class="sh">'</span>
</code></pre></div>    </div>
  </div>
</details>

<p>3) 매주 월요일 9:00 AM KST에 다음과 같은 슬랙 알림이 발송되었습니다.</p>

<p><img src="/assets/2024-07-20-voc-dashboard/10-ko.png" alt="" /></p>

<hr />

<h1 id="5-results">5. Results</h1>

<blockquote>
  <ol>
    <li><strong>비용 절약</strong>
      <ul>
        <li>월 $300 비용의 외부 서비스를 도입하지 않고도, 내부 개발을 통해 월 $25 비용 만으로 문제를 해소했습니다.</li>
      </ul>
    </li>
    <li><strong>시간 절감</strong>
      <ul>
        <li>사내 구성원 분들의 VOC 팔로업, 이슈 식별과 대응 속도를 향상시켰습니다.</li>
      </ul>
    </li>
  </ol>
</blockquote>

<h3 id="1-비용-절약">1. <strong>비용 절약</strong></h3>

<p>결론) 내부 개발을 통해 매월 약 $275 기회 비용을 제거할 수 있었습니다.</p>

<table>
  <tbody>
    <tr>
      <td> </td>
      <td><strong>외부 VOC 분석 서비스</strong></td>
      <td><strong>내부 개발</strong></td>
    </tr>
    <tr>
      <td>월간 비용</td>
      <td><code class="language-plaintext highlighter-rouge">$300</code></td>
      <td><code class="language-plaintext highlighter-rouge">$25</code></td>
    </tr>
  </tbody>
</table>

<p>1) 외부 VOC 서비스</p>
<ul>
  <li>도입을 고려 중이었던 <a href="https://www.syncly.kr/">syncly</a>의 경우, 최소 월 $299의 비용이 요구되었습니다.</li>
</ul>

<p><img src="/assets/2024-07-20-voc-dashboard/8.png" alt="" /></p>

<p>2) 내부 개발</p>
<ul>
  <li>그러나 직접 내부 개발은 다음과 같은 비용이 요구되었습니다.</li>
</ul>

<table>
  <tbody>
    <tr>
      <td><strong>리소스</strong></td>
      <td><strong>월간 비용</strong></td>
    </tr>
    <tr>
      <td>1. OpenAI API</td>
      <td><code class="language-plaintext highlighter-rouge">$25</code></td>
    </tr>
    <tr>
      <td>2. BigQuery 스토리지</td>
      <td>거의 없음</td>
    </tr>
    <tr>
      <td>3. BigQuery 쿼리 사용</td>
      <td>미미함</td>
    </tr>
    <tr>
      <td>4. VM Instance 운영</td>
      <td>기존 인스턴스를 사용하므로 한계비용 적음</td>
    </tr>
    <tr>
      <td><strong>TOTAL</strong></td>
      <td><code class="language-plaintext highlighter-rouge">$25</code> + e</td>
    </tr>
  </tbody>
</table>

<p><img src="/assets/2024-07-20-voc-dashboard/9.png" alt="ㅇㅇㅇ" /></p>
<blockquote>
  <p>일별 OpenAI API 비용</p>
</blockquote>

<h3 id="2-시간-절감">2. <strong>시간 절감</strong></h3>

<p>1) Redash VOC 대시보드 (주제 분류)</p>
<ul>
  <li>사내 구성원 분들의 VOC 이슈 <u>식별 편의성</u>을 향상시켰습니다.</li>
</ul>

<p>2) Redash VOC 대시보드 (요약)</p>
<ul>
  <li>사내 구성원 분들의 VOC <u>팔로업 속도</u>를 향상시키고 VOC에 대한 <u>접근성</u>을 개선했습니다.</li>
</ul>

<p>3) 슬랙 알림 봇</p>
<ul>
  <li>매주 문의 수가 가장 많이 늘어난 주제를 사내 구성원 분들에게 공유함으로써, 이슈 <u>식별과 대응 속도</u>를 향상시키고 동일한 <u>맥락을 공유</u>하는 데 기여했습니다.</li>
</ul>

<hr />

<h2 id="published-by-joshua-kim"><em>Published by</em> Joshua Kim</h2>
<p><img src="/assets/profile/joshua-profile.png" alt="Joshua Kim" /></p>]]></content><author><name></name></author><category term="Korean" /><category term="Python" /><category term="BigQuery" /><category term="Redash" /><category term="Data Visualization" /><category term="LLM" /><summary type="html"><![CDATA[“사내 구성원 분들이 젠데스크 고객 문의 내역 팔로업에 어려움을 겪고 있다는 사실을 공유 받아, 이를 해결하기 위해 Redash VOC 대시보드를 구축했습니다. 젠데스크 데이터를 자동으로 수집하고 전처리한 후, OpenAI API를 활용해 고객 문의 내역을 주제별로 분류하고 요약했습니다. 추가적으로, 매주 월요일마다 가장 많이 증가한 문의 주제를 슬랙으로 알림을 보내어, 고객 이슈를 효율적으로 식별하고 대응할 수 있도록 기여했습니다. 결과적으로 매월 약 $275 기회 비용을 제거할 수 있었으며, 사내 구성원 분들의 VOC 팔로업 시간을 감소시키는 성과를 얻었습니다.”]]></summary></entry><entry><title type="html">Rolling MAU 쿼리 최적화</title><link href="http://localhost:4000/rolling-mau-ko/" rel="alternate" type="text/html" title="Rolling MAU 쿼리 최적화" /><published>2024-06-30T00:00:00+09:00</published><updated>2024-06-30T00:00:00+09:00</updated><id>http://localhost:4000/rolling-mau-ko</id><content type="html" xml:base="http://localhost:4000/rolling-mau-ko/"><![CDATA[<blockquote>
  <p>“Rolling MAU와 같은 복잡한 Rolling Metrics를 계산하는 데는 대규모 데이터셋에서 막대한 시간과 비용이 소요될 수 있습니다. 기존 쿼리로 6시간 이상 걸리던 작업을 쿼리 최적화와 B-tree Index를 통해 6초로 단축했습니다. 이 과정에서 불필요한 메모리 사용을 줄이고 쿼리 성능을 극대화하여 데이터 처리 효율성을 크게 향상시켰습니다. 이를 통해 기업이 Rolling MAU 지표를 효율적으로 관리하고 인프라 비용을 절감하는 데 기여할 수 있었습니다.”</p>
</blockquote>

<hr />

<h1 id="목차">목차</h1>
<ol>
  <li>STAR Summary</li>
  <li>Situation</li>
  <li>Tasks</li>
  <li>Actions</li>
  <li>Results</li>
</ol>

<hr />

<h1 id="1-star-summary">1. STAR Summary</h1>

<h3 id="situation">Situation</h3>
<ul>
  <li>회사는 Rolling MAU와 같은 복잡한 Rolling Metrics를 계산하고 관리하는 데 <strong>막대한 비용과 시간을 소모</strong>하고 있었습니다. 특히, 사용자가 많아질수록 이 지표를 효율적으로 추출하는 것이 더욱 어려워질 것으로 예상되었으며, 실제로 기존 쿼리로는 Rolling MAU를 계산하는 데 <strong>6시간</strong> 이상 소요되었습니다. Incremental Strategy를 적용하더라도 <strong>2시간</strong>이 걸리는 상황이었습니다.</li>
</ul>

<h3 id="tasks">Tasks</h3>
<ul>
  <li>저는 Rolling MAU 지표를 효율적으로 계산할 수 있는 쿼리를 설계하여 실행 시간을 획기적으로 줄이고 인프라 비용을 절감하는 것을 목표로 삼았습니다. 이를 위해 <strong>쿼리 최적화를 통해 연산 비용을 낮추고 성능을 향상시키는 것</strong>이 필요했습니다.</li>
</ul>

<h3 id="actions">Actions</h3>

<ol>
  <li><strong>B-tree Index 생성</strong>
    <ul>
      <li>Rolling MAU를 계산할 때 가장 많은 시간이 소요되는 <code class="language-plaintext highlighter-rouge">date</code> 칼럼에 B-tree Index를 생성하여 스캔 속도를 향상시키고자 했습니다. 이를 통해 아래 조건에서 <strong>비교 연산의 부담을 줄이고자 한 것</strong>입니다.
        <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">SUB</span><span class="p">.</span><span class="nb">date</span> <span class="k">BETWEEN</span> <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span> <span class="o">-</span> <span class="n">INTERVAL</span> <span class="s1">'29 DAYS'</span> <span class="k">AND</span> <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span>
</code></pre></div>        </div>
      </li>
    </ul>
  </li>
  <li><strong>쿼리 최적화</strong>
    <ul>
      <li>B-tree Index 생성 이후에도 성능 개선이 충분하지 않았습니다. 이에 따라 메모리 사용량을 줄이기 위해 쿼리에서 필요한 컬럼만 불러오는 방식으로 변경했습니다. MAIN 테이블에서 모든 행을 불러오는 대신, 아래와 같이 <strong>필요한 칼럼만 불러와 SELF JOIN 과정에서 기하급수적인 메모리 사용량을 대폭 줄였습니다.</strong>
        <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">SELECT</span> <span class="k">DISTINCT</span> <span class="nb">date</span> <span class="k">FROM</span> <span class="n">daily_activated_users</span>
</code></pre></div>        </div>
      </li>
    </ul>
  </li>
</ol>

<h3 id="results">Results</h3>
<ul>
  <li>이 최적화 전략 덕분에 Rolling MAU 계산 <strong>쿼리의 실행 시간이 6시간에서 6초로 대폭 단축</strong>되었습니다. 이로 인해 데이터 처리 효율성이 극적으로 향상되었고, 쿼리 실행 시간과 인프라 비용 측면에서도 큰 절감 효과를 얻을 수 있었습니다. 이러한 성과는 기업이 Rolling Metrics와 같은 복잡한 지표를 보다 효율적으로 관리할 수 있도록 도왔습니다.</li>
</ul>

<hr />

<h1 id="2-situation">2. Situation</h1>

<blockquote>
  <ul>
    <li>회사는 Rolling MAU와 같은 복잡한 Rolling Metrics를 계산하고 관리하는 데 <strong>막대한 비용과 시간을 소모</strong>하고 있었습니다. 특히, 사용자가 많아질수록 이 지표를 효율적으로 추출하는 것이 더욱 어려워질 것으로 예상되었으며, 실제로 기존 쿼리로는 Rolling MAU를 계산하는 데 <strong>6시간</strong> 이상 소요되었습니다. Incremental Strategy를 적용하더라도 <strong>2시간</strong>이 걸리는 상황이었습니다.</li>
  </ul>
</blockquote>

<h3 id="구체적인-문제-상황">구체적인 문제 상황</h3>
<ul>
  <li>회사가 운영하는 프로덕트는 시간이 지남에 따라 사용자 수가 급증하고 있었으며, 데이터 웨어하우스 관점에서 최적화가 중요한 이슈로 떠오르고 있었습니다. 특히, Rolling MAU는 프로덕트 요금제의 기준으로 필수적인 지표 역할을 했습니다. 그러나 Rolling MAU의 계산 과정은 매우 복잡하고 연산 비용이 높아 큰 고민이 되었습니다.</li>
</ul>

<h3 id="기존-쿼리-분석-및-병목-지점-파악">기존 쿼리 분석 및 병목 지점 파악</h3>

<h5 id="1-기존-쿼리">(1) 기존 쿼리</h5>
<ul>
  <li>초기에 작성된 쿼리는 각 날짜별로 최근 30일 동안의 활성 사용자 수를 계산하기 위해 SELF JOIN을 사용했습니다. 이 방식은 모든 날짜에 대해 연관된 데이터를 반복적으로 조회하고 계산하는 과정에서 O(n²)의 연산 복잡도를 가지며, 사용자가 많아질수록 연산 비용이 기하급수적으로 증가하는 문제점을 지니고 있었습니다. 실제로, 이 쿼리를 Full Scan으로 실행할 때 6시간 이상 소요되었으며, Incremental Strategy로 실행해도 2시간 가까이 걸렸습니다.
    <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="k">SELECT</span>
    <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span><span class="p">,</span>
    <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="n">SUB</span><span class="p">.</span><span class="n">user_id</span><span class="p">)</span> <span class="k">AS</span> <span class="n">rolling_mau</span>
 <span class="k">FROM</span>
    <span class="n">daily_activated_users</span> <span class="n">MAIN</span>
 <span class="k">LEFT</span> <span class="k">JOIN</span>
    <span class="n">daily_activated_users</span> <span class="n">SUB</span>
    <span class="k">ON</span> <span class="n">SUB</span><span class="p">.</span><span class="nb">date</span> <span class="k">BETWEEN</span> <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span> <span class="o">-</span> <span class="n">INTERVAL</span> <span class="s1">'29 DAYS'</span> <span class="k">AND</span> <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span>
 <span class="k">GROUP</span> <span class="k">BY</span>
    <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span>
 <span class="k">ORDER</span> <span class="k">BY</span>
    <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span>
</code></pre></div>    </div>
  </li>
</ul>

<h5 id="2-기존-쿼리-분석-rolling-2-day-active-users-사례">(2) 기존 쿼리 분석 (<code class="language-plaintext highlighter-rouge">Rolling 2-day Active Users 사례</code>)</h5>

<ul>
  <li><strong>A</strong>. 먼저, 아래 과정을 통해 <code class="language-plaintext highlighter-rouge">daily_activated_users</code> 테이블의 데이터를 가져옵니다.
    <details>
 <summary>자세히 보기</summary>
 <div>
        <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="k">FROM</span>
       <span class="n">daily_activated_users</span> <span class="n">MAIN</span>
</code></pre></div>        </div>

        <p><img src="/assets/2024-06-30-rolling-mau/1.webp" alt="Joshua Kim" /></p>
      </div>
 </details>
  </li>
  <li><strong>B</strong>. 그런 후, SELF JOIN을 통해 각 일별 Recent 2-day 활성 사용자 목록을 모두 이어 붙입니다.
    <details>
 <summary>자세히 보기</summary>
 <div>
        <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="k">FROM</span>
       <span class="n">daily_activated_users</span> <span class="n">MAIN</span>
    <span class="k">LEFT</span> <span class="k">JOIN</span>
       <span class="n">daily_activated_users</span> <span class="n">SUB</span>
       <span class="k">ON</span> <span class="n">SUB</span><span class="p">.</span><span class="nb">date</span> <span class="k">BETWEEN</span> <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span> <span class="o">-</span> <span class="n">INTERVAL</span> <span class="s1">'1 DAYS'</span> <span class="k">AND</span> <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span>
</code></pre></div>        </div>

        <p><img src="/assets/2024-06-30-rolling-mau/2.webp" alt="Joshua Kim" /></p>
      </div>
 </details>
  </li>
  <li><strong>C</strong>. 이제 <code class="language-plaintext highlighter-rouge">MAIN.date</code>를 기준으로 그룹화하여 순수 사용자 수를 계산합니다.
    <details>
 <summary>자세히 보기</summary>
 <div>
        <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="k">SELECT</span>
       <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span><span class="p">,</span>
       <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="n">SUB</span><span class="p">.</span><span class="n">user_id</span><span class="p">)</span> <span class="k">AS</span> <span class="n">rolling_mau</span>
    <span class="k">FROM</span>
       <span class="n">daily_activated_users</span> <span class="n">MAIN</span>
    <span class="k">LEFT</span> <span class="k">JOIN</span>
       <span class="n">daily_activated_users</span> <span class="n">SUB</span>
       <span class="k">ON</span> <span class="n">SUB</span><span class="p">.</span><span class="nb">date</span> <span class="k">BETWEEN</span> <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span> <span class="o">-</span> <span class="n">INTERVAL</span> <span class="s1">'29 DAYS'</span> <span class="k">AND</span> <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span>
    <span class="k">GROUP</span> <span class="k">BY</span>
       <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span>
</code></pre></div>        </div>

        <p><img src="/assets/2024-06-30-rolling-mau/3.webp" alt="Joshua Kim" /></p>
      </div>
 </details>
  </li>
  <li>정확한 병목 지점 파악
    <ul>
      <li><strong>연산 시간이 가장 많이 소모되는 지점은 단계 B입니다.</strong> 이 단계에서는 각 행마다 Recent 2-day Window에 해당하는 모든 행을 이어 붙이는 과정이 이루어집니다. 예를 들어, 1월 2일의 행 수가 10개이고, Recent 2-day Window에 해당하는 행이 100개라면, 총 1,000개의 행(10*100)을 이어 붙여야 하므로 메모리 사용량이 급격히 증가합니다. 즉, SELF JOIN을 통해 각 일별 Recent 2-day 활성 사용자 목록을 이어 붙이는 과정이 Scan 시간과 메모리 사용량을 상당히 많이 소모하는 원인이었습니다.</li>
      <li>이러한 상황에서, Rolling MAU 지표를 보다 효율적으로 개선하고 쿼리 실행 시간을 대폭 줄이기 위한 최적화가 시급한 과제로 떠올랐습니다. 또한, 기존 인프라로는 이와 같은 연산 비용을 지속적으로 감당하는 것이 비효율적이었기 때문에, 최적화를 통해 인프라 비용도 절감할 필요가 있었습니다. 즉, 비용과 시간을 절감할 수 있는 솔루션을 찾는 것이 절실한 상황이었습니다.</li>
    </ul>
  </li>
</ul>

<hr />

<h1 id="3-tasks">3. Tasks</h1>
<blockquote>
  <ul>
    <li>저는 Rolling MAU 지표를 효율적으로 계산할 수 있는 쿼리를 설계하여 실행 시간을 획기적으로 줄이고 인프라 비용을 절감하는 것을 목표로 삼았습니다. 이를 위해 <strong>쿼리 최적화를 통해 연산 비용을 낮추고 성능을 향상시키는 것</strong>이 필요했습니다.</li>
  </ul>
</blockquote>

<h3 id="1-쿼리-실행-시간-단축"><strong>1. 쿼리 실행 시간 단축</strong></h3>
<ul>
  <li>Rolling MAU를 계산하는 기존 쿼리는 O(n²)의 연산 복잡도를 가지고 있었기 때문에, 실행 시간이 6시간 이상 걸렸습니다. 이를 크게 단축하여 실시간 분석에 가까운 성능을 구현하는 것이 최우선 과제였습니다. 실행 시간을 초 단위로 줄여야만, 빠르게 변화하는 사용자 활동 데이터를 분석하고 즉각적으로 대응할 수 있는 환경을 마련할 수 있었습니다.</li>
</ul>

<h3 id="2-인프라-비용-절감"><strong>2. 인프라 비용 절감</strong></h3>
<ul>
  <li>쿼리 실행 시 사용되는 메모리와 처리 능력은 비용으로 직결됩니다. 기존 쿼리는 데이터 양이 증가함에 따라 메모리 사용량도 기하급수적으로 늘어나고, 이로 인해 인프라 비용이 급증하는 문제가 있었습니다. 따라서, 메모리 사용량을 줄이고 인프라 자원을 효율적으로 활용할 수 있는 쿼리 구조를 설계하는 것이 필요했습니다.</li>
</ul>

<hr />

<h1 id="4-actions">4. Actions</h1>

<blockquote>
  <ol>
    <li><strong>B-tree Index 생성</strong>
      <ul>
        <li>Rolling MAU를 계산할 때 가장 많은 시간이 소요되는 <code class="language-plaintext highlighter-rouge">date</code> 칼럼에 B-tree Index를 생성하여 스캔 속도를 향상시키고자 했습니다. 이를 통해 아래 조건에서 <strong>비교 연산의 부담을 줄이고자 한 것</strong>입니다.
          <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">SUB</span><span class="p">.</span><span class="nb">date</span> <span class="k">BETWEEN</span> <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span> <span class="o">-</span> <span class="n">INTERVAL</span> <span class="s1">'29 DAYS'</span> <span class="k">AND</span> <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span>
</code></pre></div>          </div>
        </li>
      </ul>
    </li>
    <li><strong>쿼리 최적화</strong>
      <ul>
        <li>B-tree Index 생성 이후에도 성능 개선이 충분하지 않았습니다. 이에 따라 메모리 사용량을 줄이기 위해 쿼리에서 필요한 컬럼만 불러오는 방식으로 변경했습니다. MAIN 테이블에서 모든 행을 불러오는 대신, 아래와 같이 <strong>필요한 칼럼만 불러와 SELF JOIN 과정에서 기하급수적인 메모리 사용량을 대폭 줄였습니다.</strong>
          <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">SELECT</span> <span class="k">DISTINCT</span> <span class="nb">date</span> <span class="k">FROM</span> <span class="n">daily_activated_users</span>
</code></pre></div>          </div>
        </li>
      </ul>
    </li>
  </ol>
</blockquote>

<h3 id="1-b-tree-index-생성"><strong>1. B-tree Index 생성</strong></h3>
<ul>
  <li>병목 지점이었던 <code class="language-plaintext highlighter-rouge">date</code> 칼럼 비교 연산의 성능을 향상시키기 위해, <code class="language-plaintext highlighter-rouge">date</code> 칼럼에 <strong>B-tree Index</strong>를 생성했습니다.
    <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="k">CREATE</span> <span class="k">INDEX</span> <span class="n">idx_dates</span> <span class="k">ON</span> <span class="n">daily_activated_users</span> <span class="k">USING</span> <span class="n">btree</span> <span class="p">(</span><span class="nb">date</span><span class="p">);</span>
</code></pre></div>    </div>
  </li>
  <li>이를 통해, 아래의 <code class="language-plaintext highlighter-rouge">date</code> 검색 속도를 개선하여 쿼리 시간이 소폭 개선되었으나, 여전히 메모리 사용량과 실행 시간이 과도하게 많이 소요되고 있었습니다.
    <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="k">FROM</span>
    <span class="n">daily_activated_users</span> <span class="n">MAIN</span>
 <span class="k">LEFT</span> <span class="k">JOIN</span>
    <span class="n">daily_activated_users</span> <span class="n">SUB</span>
    <span class="k">ON</span> <span class="n">SUB</span><span class="p">.</span><span class="nb">date</span> <span class="k">BETWEEN</span> <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span> <span class="o">-</span> <span class="n">INTERVAL</span> <span class="s1">'29 DAYS'</span> <span class="k">AND</span> <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span>
</code></pre></div>    </div>
  </li>
</ul>

<h3 id="2-쿼리-최적화"><strong>2. 쿼리 최적화</strong></h3>
<ul>
  <li>안타깝게도 <code class="language-plaintext highlighter-rouge">date</code> 칼럼을 Index로 생성했음에도 불구하고 쿼리 실행 시간은 여전히 과도하게 많이 소요되고 있었습니다.</li>
  <li><strong>즉, 핵심 문제는 <code class="language-plaintext highlighter-rouge">date</code> 칼럼 비교 연산 과정이라기보다는, SELF JOIN 과정의 기하급수적인 메모리 사용 과정이었던 것입니다.</strong> 따라서 메모리 사용량을 줄이기 위해 반드시 필요한 칼럼만을 불러오는 방법을 고안했습니다.
    <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="k">SELECT</span>
    <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span><span class="p">,</span>
    <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="n">SUB</span><span class="p">.</span><span class="n">user_id</span><span class="p">)</span> <span class="k">AS</span> <span class="n">rolling_mau</span>
 <span class="k">FROM</span>
    <span class="p">(</span><span class="k">SELECT</span> <span class="k">DISTINCT</span> <span class="nb">date</span> <span class="k">FROM</span> <span class="n">daily_activated_users</span><span class="p">)</span> <span class="n">MAIN</span> <span class="c1">-- 변경한 부분</span>
 <span class="k">LEFT</span> <span class="k">JOIN</span>
    <span class="n">daily_activated_users</span> <span class="n">SUB</span>
    <span class="k">ON</span> <span class="n">SUB</span><span class="p">.</span><span class="nb">date</span> <span class="k">BETWEEN</span> <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span> <span class="o">-</span> <span class="n">INTERVAL</span> <span class="s1">'29 DAYS'</span> <span class="k">AND</span> <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span>
 <span class="k">GROUP</span> <span class="k">BY</span>
    <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span>
</code></pre></div>    </div>
  </li>
  <li>이를 통해 SELF JOIN의 데이터 처리량을 드라마틱하게 줄여 메모리 사용량을 대폭 감소시켰습니다.</li>
</ul>

<hr />

<h1 id="5-results">5. Results</h1>
<blockquote>
  <ul>
    <li>이 최적화 전략 덕분에 Rolling MAU 계산 <strong>쿼리의 실행 시간이 6시간에서 6초로 대폭 단축</strong>되었습니다. 이로 인해 데이터 처리 효율성이 극적으로 향상되었고, 쿼리 실행 시간과 인프라 비용 측면에서도 큰 절감 효과를 얻을 수 있었습니다. 이러한 성과는 기업이 Rolling Metrics와 같은 복잡한 지표를 보다 효율적으로 관리할 수 있도록 도왔습니다.</li>
  </ul>
</blockquote>

<h3 id="쿼리-실행-시간의-극적-단축"><strong>쿼리 실행 시간의 극적 단축</strong></h3>
<ul>
  <li>Rolling MAU는 프로덕트의 요금제 기준으로 기획되었기 때문에, 본 문제는 상당히 중요한 이슈였습니다.
    <ul>
      <li><strong>최적화 이전</strong>: Rolling MAU를 계산하는 쿼리가 약 6시간 소요</li>
      <li><strong>최적화 이후</strong>: 동일한 작업이 단 6초 만에 완료</li>
    </ul>
  </li>
  <li>이렇게 단축된 실행 시간 덕분에 더욱 안정적인 프로덕트 운영이 가능해졌으며 요금제 기준의 대체 방법을 고민할 수도 있었던 기업의 기회비용을 절약할 수 있었습니다.</li>
</ul>

<hr />

<h2 id="published-by-joshua-kim"><em>Published by</em> Joshua Kim</h2>
<p><img src="/assets/profile/joshua-profile.png" alt="Joshua Kim" /></p>]]></content><author><name></name></author><category term="Korean" /><category term="PostgreSQL" /><summary type="html"><![CDATA[“Rolling MAU와 같은 복잡한 Rolling Metrics를 계산하는 데는 대규모 데이터셋에서 막대한 시간과 비용이 소요될 수 있습니다. 기존 쿼리로 6시간 이상 걸리던 작업을 쿼리 최적화와 B-tree Index를 통해 6초로 단축했습니다. 이 과정에서 불필요한 메모리 사용을 줄이고 쿼리 성능을 극대화하여 데이터 처리 효율성을 크게 향상시켰습니다. 이를 통해 기업이 Rolling MAU 지표를 효율적으로 관리하고 인프라 비용을 절감하는 데 기여할 수 있었습니다.”]]></summary></entry><entry><title type="html">Rolling MAU Query Optimization</title><link href="http://localhost:4000/rolling-mau-en/" rel="alternate" type="text/html" title="Rolling MAU Query Optimization" /><published>2024-06-30T00:00:00+09:00</published><updated>2024-06-30T00:00:00+09:00</updated><id>http://localhost:4000/rolling-mau-en</id><content type="html" xml:base="http://localhost:4000/rolling-mau-en/"><![CDATA[<blockquote>
  <p>“Calculating complex Rolling Metrics like Rolling MAU can consume significant time and cost on large datasets. A task that previously took over 6 hours with the original query was reduced to 6 seconds through query optimization and the use of a B-tree Index. This process significantly enhanced data processing efficiency by minimizing unnecessary memory usage and maximizing query performance. As a result, the company was able to manage Rolling MAU metrics more efficiently, contributing to infrastructure cost savings.”</p>
</blockquote>

<hr />

<h1 id="table-of-contents">Table of Contents</h1>
<ol>
  <li>STAR Summary</li>
  <li>Situation</li>
  <li>Tasks</li>
  <li>Actions</li>
  <li>Results</li>
</ol>

<hr />

<h1 id="1-star-summary">1. STAR Summary</h1>

<h3 id="situation">Situation</h3>
<ul>
  <li>The company was consuming <strong>significant time and costs</strong> to calculate and manage complex Rolling Metrics like Rolling MAU. As the number of users increased, it was expected to become even more challenging to extract this metric efficiently, and indeed, the original query took more than <strong>6 hours</strong> to calculate Rolling MAU. Even with an Incremental Strategy applied, it still took <strong>2 hours</strong>.</li>
</ul>

<h3 id="tasks">Tasks</h3>
<ul>
  <li>My goal was to design a query that could calculate the Rolling MAU metric efficiently, drastically reduce execution time, and lower infrastructure costs. This required <strong>query optimization to reduce computational costs and improve performance</strong>.</li>
</ul>

<h3 id="actions">Actions</h3>

<ol>
  <li><strong>Creating a B-tree Index</strong>
    <ul>
      <li>To speed up the most time-consuming process of calculating Rolling MAU, I created a B-tree Index on the <code class="language-plaintext highlighter-rouge">date</code> column to enhance scan speed. This was intended to <strong>reduce the burden of comparison operations</strong> under the following condition:
        <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">SUB</span><span class="p">.</span><span class="nb">date</span> <span class="k">BETWEEN</span> <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span> <span class="o">-</span> <span class="n">INTERVAL</span> <span class="s1">'29 DAYS'</span> <span class="k">AND</span> <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span>
</code></pre></div>        </div>
      </li>
    </ul>
  </li>
  <li><strong>Query Optimization</strong>
    <ul>
      <li>Even after creating the B-tree Index, the performance improvement was not sufficient. Therefore, I changed the query to fetch only the necessary columns to reduce memory usage. Instead of fetching all rows from the MAIN table, I fetched only the necessary columns, <strong>significantly reducing the exponential memory usage during the SELF JOIN process.</strong>
        <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">SELECT</span> <span class="k">DISTINCT</span> <span class="nb">date</span> <span class="k">FROM</span> <span class="n">daily_activated_users</span>
</code></pre></div>        </div>
      </li>
    </ul>
  </li>
</ol>

<h3 id="results">Results</h3>
<ul>
  <li>Thanks to this optimization strategy, the execution time for the Rolling MAU calculation query was <strong>reduced from 6 hours to 6 seconds.</strong> This led to a dramatic improvement in data processing efficiency and significant cost savings in query execution time and infrastructure. These results helped the company manage complex metrics like Rolling Metrics more efficiently.</li>
</ul>

<hr />

<h1 id="2-situation">2. Situation</h1>

<blockquote>
  <ul>
    <li>The company was consuming <strong>significant time and costs</strong> to calculate and manage complex Rolling Metrics like Rolling MAU. As the number of users increased, it was expected to become even more challenging to extract this metric efficiently, and indeed, the original query took more than <strong>6 hours</strong> to calculate Rolling MAU. Even with an Incremental Strategy applied, it still took <strong>2 hours</strong>.</li>
  </ul>
</blockquote>

<h3 id="specific-problem-situation">Specific Problem Situation</h3>
<ul>
  <li>The company’s product saw a rapid increase in users over time, making optimization a critical issue from a data warehouse perspective. The Rolling MAU, a key metric for product pricing, played an essential role. However, the calculation process for Rolling MAU was very complex and computationally expensive, which posed a significant challenge.</li>
</ul>

<h3 id="analysis-of-the-existing-query-and-identification-of-bottlenecks">Analysis of the Existing Query and Identification of Bottlenecks</h3>

<h5 id="1-the-existing-query">(1) The Existing Query</h5>
<ul>
  <li>The initial query used a SELF JOIN to calculate the number of active users over the last 30 days for each date. This approach had a computational complexity of O(n²) because it repeatedly retrieved and calculated related data for each date, causing an exponential increase in computation cost as the number of users grew. In practice, this query took more than 6 hours to execute with a Full Scan, and nearly 2 hours even with an Incremental Strategy.
    <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="k">SELECT</span>
    <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span><span class="p">,</span>
    <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="n">SUB</span><span class="p">.</span><span class="n">user_id</span><span class="p">)</span> <span class="k">AS</span> <span class="n">rolling_mau</span>
 <span class="k">FROM</span>
    <span class="n">daily_activated_users</span> <span class="n">MAIN</span>
 <span class="k">LEFT</span> <span class="k">JOIN</span>
    <span class="n">daily_activated_users</span> <span class="n">SUB</span>
    <span class="k">ON</span> <span class="n">SUB</span><span class="p">.</span><span class="nb">date</span> <span class="k">BETWEEN</span> <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span> <span class="o">-</span> <span class="n">INTERVAL</span> <span class="s1">'29 DAYS'</span> <span class="k">AND</span> <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span>
 <span class="k">GROUP</span> <span class="k">BY</span>
    <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span>
 <span class="k">ORDER</span> <span class="k">BY</span>
    <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span>
</code></pre></div>    </div>
  </li>
</ul>

<h5 id="2-analysis-of-the-existing-query-rolling-2-day-active-users-example">(2) Analysis of the Existing Query (<code class="language-plaintext highlighter-rouge">Rolling 2-day Active Users Example</code>)</h5>

<ul>
  <li><strong>A</strong>. First, the <code class="language-plaintext highlighter-rouge">daily_activated_users</code> table data is retrieved through the following process:
    <details>
 <summary>View code</summary>
 <div>
        <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="k">FROM</span>
       <span class="n">daily_activated_users</span> <span class="n">MAIN</span>
</code></pre></div>        </div>

        <p><img src="/assets/2024-06-30-rolling-mau/1.webp" alt="Joshua Kim" /></p>
      </div>
 </details>
  </li>
  <li><strong>B</strong>. Then, a SELF JOIN is performed to concatenate the list of active users for the recent 2-day period for each day.
    <details>
 <summary>View code</summary>
 <div>
        <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="k">FROM</span>
       <span class="n">daily_activated_users</span> <span class="n">MAIN</span>
    <span class="k">LEFT</span> <span class="k">JOIN</span>
       <span class="n">daily_activated_users</span> <span class="n">SUB</span>
       <span class="k">ON</span> <span class="n">SUB</span><span class="p">.</span><span class="nb">date</span> <span class="k">BETWEEN</span> <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span> <span class="o">-</span> <span class="n">INTERVAL</span> <span class="s1">'1 DAYS'</span> <span class="k">AND</span> <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span>
</code></pre></div>        </div>

        <p><img src="/assets/2024-06-30-rolling-mau/2.webp" alt="Joshua Kim" /></p>
      </div>
 </details>
  </li>
  <li><strong>C</strong>. Now, the users are grouped by <code class="language-plaintext highlighter-rouge">MAIN.date</code> to calculate the unique number of users.
    <details>
 <summary>View code</summary>
 <div>
        <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="k">SELECT</span>
       <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span><span class="p">,</span>
       <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="n">SUB</span><span class="p">.</span><span class="n">user_id</span><span class="p">)</span> <span class="k">AS</span> <span class="n">rolling_mau</span>
    <span class="k">FROM</span>
       <span class="n">daily_activated_users</span> <span class="n">MAIN</span>
    <span class="k">LEFT</span> <span class="k">JOIN</span>
       <span class="n">daily_activated_users</span> <span class="n">SUB</span>
       <span class="k">ON</span> <span class="n">SUB</span><span class="p">.</span><span class="nb">date</span> <span class="k">BETWEEN</span> <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span> <span class="o">-</span> <span class="n">INTERVAL</span> <span class="s1">'29 DAYS'</span> <span class="k">AND</span> <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span>
    <span class="k">GROUP</span> <span class="k">BY</span>
       <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span>
</code></pre></div>        </div>

        <p><img src="/assets/2024-06-30-rolling-mau/3.webp" alt="Joshua Kim" /></p>
      </div>
 </details>
  </li>
  <li>Identifying the Exact Bottleneck
    <ul>
      <li><strong>The most time-consuming part is step B.</strong> In this step, all rows corresponding to the Recent 2-day Window are concatenated for each row. For example, if there are 10 rows on January 2nd, and 100 rows corresponding to the Recent 2-day Window, a total of 1,000 rows (10*100) need to be concatenated, resulting in a rapid increase in memory usage. The process of concatenating the list of active users for each day through SELF JOIN was the primary cause of excessive scan time and memory usage.</li>
      <li>Given this situation, it became urgent to optimize the Rolling MAU metric to improve efficiency and significantly reduce query execution time. Additionally, continuing to bear such computational costs with the existing infrastructure was inefficient, necessitating optimization to reduce infrastructure costs. In other words, finding a solution to save both time and costs was crucial.</li>
    </ul>
  </li>
</ul>

<hr />

<h1 id="3-tasks">3. Tasks</h1>
<blockquote>
  <ul>
    <li>My goal was to design a query that could calculate the Rolling MAU metric efficiently, drastically reduce execution time, and lower infrastructure costs. This required <strong>query optimization to reduce computational costs and improve performance</strong>.</li>
  </ul>
</blockquote>

<h3 id="1-reducing-query-execution-time"><strong>1. Reducing Query Execution Time</strong></h3>
<ul>
  <li>The original query for calculating Rolling MAU had a computational complexity of O(n²), resulting in an execution time of over 6 hours. Drastically reducing this time to achieve near real-time performance was the top priority. Reducing execution time to the second level was essential to quickly analyze changing user activity data and respond immediately.</li>
</ul>

<h3 id="2-reducing-infrastructure-costs"><strong>2. Reducing Infrastructure Costs</strong></h3>
<ul>
  <li>Memory and processing power used during query execution directly translate to costs. The original query had an issue where memory usage increased exponentially as the data volume grew, leading to a sharp rise in infrastructure costs. Therefore, it was necessary to design a query structure that minimized memory usage and efficiently utilized infrastructure resources.</li>
</ul>

<hr />

<h1 id="4-actions">4. Actions</h1>

<blockquote>
  <ol>
    <li><strong>Creating a B-tree Index</strong>
      <ul>
        <li>To speed up the most time-consuming process of calculating Rolling MAU, I created a B-tree Index on the <code class="language-plaintext highlighter-rouge">date</code> column to enhance scan speed. This was intended to <strong>reduce the burden of comparison operations</strong> under the following condition:
          <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">SUB</span><span class="p">.</span><span class="nb">date</span> <span class="k">BETWEEN</span> <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span> <span class="o">-</span> <span class="n">INTERVAL</span> <span class="s1">'29 DAYS'</span> <span class="k">AND</span> <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span>
</code></pre></div>          </div>
        </li>
      </ul>
    </li>
    <li><strong>Query Optimization</strong>
      <ul>
        <li>Even after creating the B-tree Index, the performance improvement was not sufficient. Therefore, I changed the query to fetch only the necessary columns to reduce memory usage. Instead of fetching all rows from the MAIN table, I fetched only the necessary columns, <strong>significantly reducing the exponential memory usage during the SELF JOIN process.</strong>
          <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">SELECT</span> <span class="k">DISTINCT</span> <span class="nb">date</span> <span class="k">FROM</span> <span class="n">daily_activated_users</span>
</code></pre></div>          </div>
        </li>
      </ul>
    </li>
  </ol>
</blockquote>

<h3 id="1-creating-a-b-tree-index"><strong>1. Creating a B-tree Index</strong></h3>
<ul>
  <li>To improve the performance of comparison operations on the <code class="language-plaintext highlighter-rouge">date</code> column, which was the bottleneck, I created a <strong>B-tree Index</strong> on the <code class="language-plaintext highlighter-rouge">date</code> column.
    <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="k">CREATE</span> <span class="k">INDEX</span> <span class="n">idx_dates</span> <span class="k">ON</span> <span class="n">daily_activated_users</span> <span class="k">USING</span> <span class="n">btree</span> <span class="p">(</span><span class="nb">date</span><span class="p">);</span>
</code></pre></div>    </div>
  </li>
  <li>This improved the search speed for <code class="language-plaintext highlighter-rouge">date</code> and slightly reduced query time, but the memory usage and execution time were still excessively high.
    <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="k">FROM</span>
    <span class="n">daily_activated_users</span> <span class="n">MAIN</span>
 <span class="k">LEFT</span> <span class="k">JOIN</span>
    <span class="n">daily_activated_users</span> <span class="n">SUB</span>
    <span class="k">ON</span> <span class="n">SUB</span><span class="p">.</span><span class="nb">date</span> <span class="k">BETWEEN</span> <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span> <span class="o">-</span> <span class="n">INTERVAL</span> <span class="s1">'29 DAYS'</span> <span class="k">AND</span> <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span>
</code></pre></div>    </div>
  </li>
</ul>

<h3 id="2-query-optimization"><strong>2. Query Optimization</strong></h3>
<ul>
  <li>Unfortunately, even after creating an index on the <code class="language-plaintext highlighter-rouge">date</code> column, the query execution time was still excessively high.</li>
  <li><strong>The core issue was not the comparison operations on the <code class="language-plaintext highlighter-rouge">date</code> column, but rather the exponential memory usage during the SELF JOIN process.</strong> To reduce memory usage, I devised a method to retrieve only the necessary columns.
    <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="k">SELECT</span>
    <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span><span class="p">,</span>
    <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="n">SUB</span><span class="p">.</span><span class="n">user_id</span><span class="p">)</span> <span class="k">AS</span> <span class="n">rolling_mau</span>
 <span class="k">FROM</span>
    <span class="p">(</span><span class="k">SELECT</span> <span class="k">DISTINCT</span> <span class="nb">date</span> <span class="k">FROM</span> <span class="n">daily_activated_users</span><span class="p">)</span> <span class="n">MAIN</span> <span class="c1">-- The Modified Part</span>
 <span class="k">LEFT</span> <span class="k">JOIN</span>
    <span class="n">daily_activated_users</span> <span class="n">SUB</span>
    <span class="k">ON</span> <span class="n">SUB</span><span class="p">.</span><span class="nb">date</span> <span class="k">BETWEEN</span> <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span> <span class="o">-</span> <span class="n">INTERVAL</span> <span class="s1">'29 DAYS'</span> <span class="k">AND</span> <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span>
 <span class="k">GROUP</span> <span class="k">BY</span>
    <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span>
</code></pre></div>    </div>
  </li>
  <li>This drastically reduced the data processing load during SELF JOIN, significantly decreasing memory usage.</li>
</ul>

<hr />

<h1 id="5-results">5. Results</h1>
<blockquote>
  <ul>
    <li>Thanks to this optimization strategy, the execution time for the Rolling MAU calculation query was <strong>reduced from 6 hours to 6 seconds.</strong> This led to a dramatic improvement in data processing efficiency and significant cost savings in query execution time and infrastructure. These results helped the company manage complex metrics like Rolling Metrics more efficiently.</li>
  </ul>
</blockquote>

<h3 id="dramatic-reduction-in-query-execution-time"><strong>Dramatic Reduction in Query Execution Time</strong></h3>
<ul>
  <li>Since Rolling MAU was a key metric for product pricing, this issue was of significant importance.
    <ul>
      <li><strong>Before Optimization</strong>: The query for calculating Rolling MAU took about 6 hours</li>
      <li><strong>After Optimization</strong>: The same task was completed in just 6 seconds</li>
    </ul>
  </li>
  <li>The reduced execution time enabled more stable product operations and saved the company from considering alternative pricing methods, thereby saving opportunity costs.</li>
</ul>

<hr />

<h2 id="published-by-joshua-kim"><em>Published by</em> Joshua Kim</h2>
<p><img src="/assets/profile/joshua-profile.png" alt="Joshua Kim" /></p>]]></content><author><name></name></author><category term="English" /><category term="PostgreSQL" /><summary type="html"><![CDATA[“Calculating complex Rolling Metrics like Rolling MAU can consume significant time and cost on large datasets. A task that previously took over 6 hours with the original query was reduced to 6 seconds through query optimization and the use of a B-tree Index. This process significantly enhanced data processing efficiency by minimizing unnecessary memory usage and maximizing query performance. As a result, the company was able to manage Rolling MAU metrics more efficiently, contributing to infrastructure cost savings.”]]></summary></entry><entry><title type="html">IP 주소-국가 매핑 쿼리 최적화</title><link href="http://localhost:4000/ip-address-to-country-ko/" rel="alternate" type="text/html" title="IP 주소-국가 매핑 쿼리 최적화" /><published>2024-05-19T00:00:00+09:00</published><updated>2024-05-19T00:00:00+09:00</updated><id>http://localhost:4000/ip-address-to-country-ko</id><content type="html" xml:base="http://localhost:4000/ip-address-to-country-ko/"><![CDATA[<blockquote>
  <p>“데이터 웨어하우스에서 IP 주소를 사용해 사용자의 국가 정보를 매핑하는 작업을 최적화하였습니다. 기존 방식은 연산 시간이 길어 비효율적이었으나, 새로운 접근 방식을 통해 쿼리 실행 시간을 90% 감소시켰습니다.”</p>
</blockquote>

<hr />

<h1 id="목차">목차</h1>
<ol>
  <li>STAR Summary</li>
  <li>Situation</li>
  <li>Tasks</li>
  <li>Actions</li>
  <li>Results</li>
</ol>

<hr />

<h1 id="1-star-summary">1. STAR Summary</h1>

<h3 id="situation">Situation</h3>
<ul>
  <li>글로벌 서비스를 운영하는 환경에서 사용자의 접속 IP 주소를 기반으로 국가 정보를 매핑해야 했습니다. PostgreSQL을 사용하여 이 작업을 수행했으나, 기존 접근 방식으로 인해 성능 저하 문제가 발생했습니다. 기존 쿼리로는 너무 많은 시간이 소요되었으며, 이는 데이터 웨어하우스 운영에 큰 부담을 주고 있었습니다.</li>
</ul>

<h3 id="tasks">Tasks</h3>
<ul>
  <li>기존의 IP 주소 매핑 쿼리를 최적화하여 처리 시간을 대폭 줄이는 것이 목표였습니다. 이 작업을 통해 Transformation 과정의 효율성을 높여, 더 나은 데이터 웨어하우스 성능을 달성해야 했습니다. 구체적으로는 IP 주소 매핑 시 연산 과정을 최적화하고, JOIN 조건의 효율성을 높이는 것이 핵심 과제였습니다.</li>
</ul>

<h3 id="actions">Actions</h3>

<ol>
  <li><strong>기존 접근 방식 분석</strong>
    <ul>
      <li>기존 쿼리에서 <code class="language-plaintext highlighter-rouge">&lt;&lt;=</code> 연산자를 사용하여 CIDR 네트워크에 IP 주소를 매핑하는 방법을 사용했습니다. 이는 성능 저하의 주요 원인으로 파악되었습니다.</li>
    </ul>
  </li>
  <li><strong>새로운 테이블 생성</strong>
    <ul>
      <li>기존 테이블을 가공하여 <code class="language-plaintext highlighter-rouge">dim_ips_countries</code> 테이블을 생성했습니다.
        <ul>
          <li>이 테이블은 <code class="language-plaintext highlighter-rouge">start_ip</code>와 <code class="language-plaintext highlighter-rouge">end_ip</code> 칼럼을 가지고 있습니다.</li>
          <li>비교 연산의 효율성을 위해 IP 주소를 BIGINT 타입으로 변환했습니다.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>Index 생성</strong>
    <ul>
      <li><code class="language-plaintext highlighter-rouge">start_ip</code>와 <code class="language-plaintext highlighter-rouge">end_ip</code> 칼럼을 Index로 생성하여 검색 성능을 극대화했습니다.</li>
    </ul>
  </li>
  <li><strong>쿼리 최적화</strong>
    <ul>
      <li>기존의 <code class="language-plaintext highlighter-rouge">&lt;&lt;=</code> 연산자를 <code class="language-plaintext highlighter-rouge">BETWEEN</code> 연산자로 대체하여, IP 주소 비교 작업을 단순화하고 경량화된 연산을 수행하도록 쿼리를 재구성했습니다.</li>
    </ul>
  </li>
</ol>

<h3 id="results">Results</h3>
<ul>
  <li>최적화된 쿼리를 통해 실행 시간이 90% 대폭 감소하여 데이터 웨어하우스 성능 향상을 가져왔습니다.</li>
</ul>

<hr />

<h1 id="2-situation">2. Situation</h1>

<blockquote>
  <ul>
    <li>글로벌 서비스를 운영하는 환경에서 사용자의 접속 IP 주소를 기반으로 국가 정보를 매핑해야 했습니다. PostgreSQL을 사용하여 이 작업을 수행했으나, 기존 접근 방식으로 인해 성능 저하 문제가 발생했습니다. 기존 쿼리로는 너무 많은 시간이 소요되었으며, 이는 데이터 웨어하우스 운영에 큰 부담을 주고 있었습니다.</li>
  </ul>
</blockquote>

<h3 id="문제-요약">문제 요약</h3>
<ul>
  <li>글로벌 서비스를 운영하는 환경에서 사용자들이 접속할 때마다 수집되는 IP 주소를 지리 정보인 국가로 매핑하는 작업이 필요했습니다. 이를 위해 PostgreSQL의 CIDR 연산자를 사용하여 IP 주소를 국가명과 매핑하는 테이블을 구성했지만, 기존 방식은 매우 비효율적이었습니다.</li>
</ul>

<h3 id="구체적인-문제-상황">구체적인 문제 상황</h3>
<ul>
  <li><code class="language-plaintext highlighter-rouge">src_sessions</code> 테이블의 <code class="language-plaintext highlighter-rouge">session_ip</code> 칼럼을 <code class="language-plaintext highlighter-rouge">src_cidrs_countries</code> 테이블의 <code class="language-plaintext highlighter-rouge">cidr</code> 칼럼에 매핑하여 <code class="language-plaintext highlighter-rouge">fct_sessions</code> 테이블을 생성하는 작업이 핵심 문제였습니다.</li>
  <li>기존 쿼리는 <code class="language-plaintext highlighter-rouge">&lt;&lt;=</code> 연산자를 사용하여 IP 주소가 특정 CIDR 네트워크에 포함되는지를 확인하는 방식으로 이루어졌습니다. 그러나 이 방법은 대규모 데이터 처리 시 성능 문제가 발생하여, 쿼리 실행 시간이 지나치게 많이 소요되었습니다. 이는 데이터 웨어하우스의 성능을 저하시키고, 운영에 심각한 지장을 초래했습니다.</li>
</ul>

<hr />

<h1 id="3-tasks">3. Tasks</h1>
<blockquote>
  <ul>
    <li>기존의 IP 주소 매핑 쿼리를 최적화하여 처리 시간을 대폭 줄이는 것이 목표였습니다. 이 작업을 통해 Transformation 과정의 효율성을 높여, 더 나은 데이터 웨어하우스 성능을 달성해야 했습니다. 구체적으로는 IP 주소 매핑 시 연산 과정을 최적화하고, JOIN 조건의 효율성을 높이는 것이 핵심 과제였습니다.</li>
  </ul>
</blockquote>

<h3 id="주어진-과제"><strong>주어진 과제</strong></h3>
<ul>
  <li>기존의 비효율적인 쿼리 실행 시간을 대폭 줄이는 것이었습니다.</li>
</ul>

<h5 id="1-데이터-처리-속도-향상"><strong>1. 데이터 처리 속도 향상</strong></h5>
<ul>
  <li>실행 시간을 줄여 데이터 처리 효율성을 높이고, 서비스 운영에 방해가 되지 않도록 하는 것</li>
</ul>

<h5 id="2-쿼리-최적화"><strong>2. 쿼리 최적화</strong></h5>
<ul>
  <li>IP 주소와 국가 정보의 매핑 작업을 보다 효율적으로 수행할 수 있는 최적화된 쿼리 구조를 설계하고 구현하는 것</li>
</ul>

<h5 id="3-시스템-성능-개선"><strong>3. 시스템 성능 개선</strong></h5>
<ul>
  <li>데이터 웨어하우스의 전반적인 성능을 개선하여 미래의 데이터 확장 및 증가에도 대응할 수 있는 기반을 마련하는 것</li>
</ul>

<hr />

<h1 id="4-actions">4. Actions</h1>

<blockquote>
  <ol>
    <li><strong>기존 접근 방식 분석</strong>
      <ul>
        <li>기존 쿼리에서 <code class="language-plaintext highlighter-rouge">&lt;&lt;=</code> 연산자를 사용하여 CIDR 네트워크에 IP 주소를 매핑하는 방법을 사용했습니다. 이는 성능 저하의 주요 원인으로 파악되었습니다.</li>
      </ul>
    </li>
    <li><strong>새로운 테이블 생성</strong>
      <ul>
        <li>기존 테이블을 가공하여 <code class="language-plaintext highlighter-rouge">dim_ips_countries</code> 테이블을 생성했습니다.</li>
      </ul>
      <ul>
        <li>이 테이블은 <code class="language-plaintext highlighter-rouge">start_ip</code>와 <code class="language-plaintext highlighter-rouge">end_ip</code> 칼럼을 가지고 있습니다.</li>
        <li>비교 연산의 효율성을 위해 IP 주소를 BIGINT 타입으로 변환했습니다.</li>
      </ul>
    </li>
    <li><strong>Index 생성</strong>
      <ul>
        <li><code class="language-plaintext highlighter-rouge">start_ip</code>와 <code class="language-plaintext highlighter-rouge">end_ip</code> 칼럼을 Index로 생성하여 검색 성능을 극대화했습니다.</li>
      </ul>
    </li>
    <li><strong>쿼리 최적화</strong>
      <ul>
        <li>기존의 <code class="language-plaintext highlighter-rouge">&lt;&lt;=</code> 연산자를 <code class="language-plaintext highlighter-rouge">BETWEEN</code> 연산자로 대체하여, IP 주소 비교 작업을 단순화하고 경량화된 연산을 수행하도록 쿼리를 재구성했습니다.</li>
      </ul>
    </li>
  </ol>
</blockquote>

<h3 id="1-기존-접근-방식-분석">1. 기존 접근 방식 분석</h3>
<p><img src="/assets/2024-05-19-ip-address-to-country/1.webp" alt="" /></p>

<p><strong>(STEP 1)</strong> <code class="language-plaintext highlighter-rouge">src_cidrs_countries</code> 테이블에 Index를 생성합니다.</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">src_sessions</code> 테이블과 JOIN시 <code class="language-plaintext highlighter-rouge">cidr</code> 칼럼을 빈번하게 스캔해야 하므로, 이를 Index로 생성했습니다.
    <details>
<summary>View code</summary>
<div>
        <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="k">CREATE</span> <span class="k">INDEX</span> <span class="n">idx_cidr</span> <span class="k">ON</span> <span class="n">src_cidrs_countries</span> <span class="p">(</span><span class="n">cidr</span><span class="p">);</span>
</code></pre></div>        </div>
      </div>
</details>
  </li>
</ul>

<p><strong>(STEP 2)</strong> <code class="language-plaintext highlighter-rouge">src_cidrs_countries</code> 테이블과 <code class="language-plaintext highlighter-rouge">src_sessions</code> 테이블을 JOIN한 <code class="language-plaintext highlighter-rouge">fct_sessions</code> 테이블을 생성했습니다.</p>
<ul>
  <li>JOIN 과정에서 <code class="language-plaintext highlighter-rouge">&lt;&lt;=</code> 연산자를 사용했습니다.</li>
  <li>그러나 이 연산자는 CIDR 타입 간의 비교를 수행하는 데 연산 비용이 높아, 대규모 데이터 처리 시 성능 저하의 원인이 되었습니다.
    <details>
<summary>View code</summary>
<div>
        <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">fct_sessions</span> <span class="k">AS</span>
    <span class="k">SELECT</span>
      <span class="n">S</span><span class="p">.</span><span class="n">session_id</span><span class="p">,</span>
      <span class="n">S</span><span class="p">.</span><span class="n">user_id</span><span class="p">,</span>
      <span class="k">C</span><span class="p">.</span><span class="n">country</span>
    <span class="k">FROM</span>
      <span class="n">src_sessions</span> <span class="n">S</span>
    <span class="k">LEFT</span> <span class="k">JOIN</span>
      <span class="n">src_cidrs_countries</span> <span class="k">C</span>
      <span class="k">ON</span> <span class="n">S</span><span class="p">.</span><span class="n">session_ip</span><span class="p">::</span><span class="n">INET</span> <span class="o">&lt;&lt;=</span> <span class="k">C</span><span class="p">.</span><span class="n">cidr</span><span class="p">;</span>
</code></pre></div>        </div>
      </div>
</details>
  </li>
</ul>

<h3 id="2-새로운-테이블-생성">2. <strong>새로운 테이블 생성</strong></h3>
<p><img src="/assets/2024-05-19-ip-address-to-country/2.webp" alt="" /></p>

<ul>
  <li>기존의 <code class="language-plaintext highlighter-rouge">src_cidrs_countries</code> 테이블을 가공하여 <code class="language-plaintext highlighter-rouge">dim_ips_countries</code> 테이블을 새롭게 설계했습니다. 이 테이블에 CIDR 연산을 최소화하기 위해 각 CIDR 값에 대해 IP 주소 범위를 나타내는 <code class="language-plaintext highlighter-rouge">start_ip</code>와 <code class="language-plaintext highlighter-rouge">end_ip</code> 칼럼을 추가했습니다.</li>
  <li>IP 주소를 BIGINT 타입으로 변환하여 저장함으로써, 연산 속도를 크게 향상시켰습니다. <code class="language-plaintext highlighter-rouge">start_ip</code>와 <code class="language-plaintext highlighter-rouge">end_ip</code>는 CIDR 범위 내에서 가장 낮은 IP와 가장 높은 IP를 나타내며, 이를 통해 CIDR 네트워크 내 IP 주소 확인 작업을 단순화했습니다.</li>
</ul>

<details>
<summary>View code</summary>
<div>
    <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">dim_ips_countries</span> <span class="k">AS</span>
    <span class="k">SELECT</span>
      <span class="n">cidr</span><span class="p">,</span>
      <span class="p">(</span><span class="s1">'x'</span> <span class="o">||</span> 
      <span class="n">LPAD</span><span class="p">(</span><span class="n">TO_HEX</span><span class="p">((</span><span class="n">SPLIT_PART</span><span class="p">(</span><span class="k">HOST</span><span class="p">(</span><span class="n">cidr</span><span class="p">),</span> <span class="s1">'.'</span><span class="p">,</span> <span class="mi">1</span><span class="p">)::</span><span class="nb">INTEGER</span><span class="p">)),</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">'0'</span><span class="p">)</span> <span class="o">||</span>
      <span class="n">LPAD</span><span class="p">(</span><span class="n">TO_HEX</span><span class="p">((</span><span class="n">SPLIT_PART</span><span class="p">(</span><span class="k">HOST</span><span class="p">(</span><span class="n">cidr</span><span class="p">),</span> <span class="s1">'.'</span><span class="p">,</span> <span class="mi">2</span><span class="p">)::</span><span class="nb">INTEGER</span><span class="p">)),</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">'0'</span><span class="p">)</span> <span class="o">||</span>
      <span class="n">LPAD</span><span class="p">(</span><span class="n">TO_HEX</span><span class="p">((</span><span class="n">SPLIT_PART</span><span class="p">(</span><span class="k">HOST</span><span class="p">(</span><span class="n">cidr</span><span class="p">),</span> <span class="s1">'.'</span><span class="p">,</span> <span class="mi">3</span><span class="p">)::</span><span class="nb">INTEGER</span><span class="p">)),</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">'0'</span><span class="p">)</span> <span class="o">||</span>
      <span class="n">LPAD</span><span class="p">(</span><span class="n">TO_HEX</span><span class="p">((</span><span class="n">SPLIT_PART</span><span class="p">(</span><span class="k">HOST</span><span class="p">(</span><span class="n">cidr</span><span class="p">),</span> <span class="s1">'.'</span><span class="p">,</span> <span class="mi">4</span><span class="p">)::</span><span class="nb">INTEGER</span><span class="p">)),</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">'0'</span><span class="p">)</span>
      <span class="p">)::</span><span class="nb">BIT</span><span class="p">(</span><span class="mi">32</span><span class="p">)::</span><span class="nb">BIGINT</span> <span class="k">AS</span> <span class="n">start_ip</span><span class="p">,</span>
      <span class="p">(</span><span class="s1">'x'</span> <span class="o">||</span>
      <span class="n">LPAD</span><span class="p">(</span><span class="n">TO_HEX</span><span class="p">((</span><span class="n">SPLIT_PART</span><span class="p">(</span><span class="k">HOST</span><span class="p">(</span><span class="n">BROADCAST</span><span class="p">(</span><span class="n">cidr</span><span class="p">)),</span> <span class="s1">'.'</span><span class="p">,</span> <span class="mi">1</span><span class="p">)::</span><span class="nb">INTEGER</span><span class="p">)),</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">'0'</span><span class="p">)</span> <span class="o">||</span>
      <span class="n">LPAD</span><span class="p">(</span><span class="n">TO_HEX</span><span class="p">((</span><span class="n">SPLIT_PART</span><span class="p">(</span><span class="k">HOST</span><span class="p">(</span><span class="n">BROADCAST</span><span class="p">(</span><span class="n">cidr</span><span class="p">)),</span> <span class="s1">'.'</span><span class="p">,</span> <span class="mi">2</span><span class="p">)::</span><span class="nb">INTEGER</span><span class="p">)),</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">'0'</span><span class="p">)</span> <span class="o">||</span>
      <span class="n">LPAD</span><span class="p">(</span><span class="n">TO_HEX</span><span class="p">((</span><span class="n">SPLIT_PART</span><span class="p">(</span><span class="k">HOST</span><span class="p">(</span><span class="n">BROADCAST</span><span class="p">(</span><span class="n">cidr</span><span class="p">)),</span> <span class="s1">'.'</span><span class="p">,</span> <span class="mi">3</span><span class="p">)::</span><span class="nb">INTEGER</span><span class="p">)),</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">'0'</span><span class="p">)</span> <span class="o">||</span>
      <span class="n">LPAD</span><span class="p">(</span><span class="n">TO_HEX</span><span class="p">((</span><span class="n">SPLIT_PART</span><span class="p">(</span><span class="k">HOST</span><span class="p">(</span><span class="n">BROADCAST</span><span class="p">(</span><span class="n">cidr</span><span class="p">)),</span> <span class="s1">'.'</span><span class="p">,</span> <span class="mi">4</span><span class="p">)::</span><span class="nb">INTEGER</span><span class="p">)),</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">'0'</span><span class="p">)</span>
      <span class="p">)::</span><span class="nb">BIT</span><span class="p">(</span><span class="mi">32</span><span class="p">)::</span><span class="nb">BIGINT</span> <span class="k">AS</span> <span class="n">end_ip</span><span class="p">,</span>				
      <span class="n">country</span>
    <span class="k">FROM</span>
      <span class="n">src_cidrs_countries</span><span class="p">;</span>
</code></pre></div>    </div>
  </div>
</details>

<h3 id="3-index-생성">3. <strong>Index 생성</strong></h3>

<ul>
  <li><code class="language-plaintext highlighter-rouge">src_sessions</code> 테이블과 JOIN시 <code class="language-plaintext highlighter-rouge">start_ip</code> 및 <code class="language-plaintext highlighter-rouge">end_ip</code> 칼럼을 빈번하게 스캔해야 하므로, 이 2개 칼럼을 Index로 생성했습니다.</li>
  <li>이 Index는 IP 주소 범위 내에서 효율적으로 값을 찾을 수 있도록 설계되었으며, JOIN 연산 시 빠른 검색이 가능하게 되었습니다.
    <details>
<summary>View code</summary>
<div>
        <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="k">CREATE</span> <span class="k">INDEX</span> <span class="n">idx_ip_range</span> <span class="k">ON</span> <span class="n">dim_ips_countries</span> <span class="p">(</span><span class="n">start_ip</span><span class="p">,</span> <span class="n">end_ip</span><span class="p">);</span>
</code></pre></div>        </div>
      </div>
</details>
  </li>
</ul>

<h3 id="4-쿼리-최적화">4. <strong>쿼리 최적화</strong></h3>

<ul>
  <li>기존의 <code class="language-plaintext highlighter-rouge">&lt;&lt;=</code> 연산자를 <code class="language-plaintext highlighter-rouge">BETWEEN</code> 연산자로 대체하여, IP 주소 비교 작업을 단순화하고 경량화된 연산을 수행하도록 쿼리를 재구성했습니다.</li>
  <li><code class="language-plaintext highlighter-rouge">src_sessions</code> 테이블의 <code class="language-plaintext highlighter-rouge">session_ip</code> 칼럼도 CIDR에서 IP 주소를 추출한 후 BIGINT 타입으로 변환하여 <code class="language-plaintext highlighter-rouge">dim_ips_countries</code> 테이블의 <code class="language-plaintext highlighter-rouge">start_ip</code>와 <code class="language-plaintext highlighter-rouge">end_ip</code> 칼럼과 비교했습니다.
    <details>
<summary>View code</summary>
<div>
        <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">fct_sessions</span> <span class="k">AS</span>
    <span class="k">SELECT</span>
    <span class="n">S</span><span class="p">.</span><span class="n">session_id</span><span class="p">,</span>
    <span class="n">S</span><span class="p">.</span><span class="n">user_id</span><span class="p">,</span>
    <span class="k">C</span><span class="p">.</span><span class="n">country</span>
  <span class="k">FROM</span> <span class="p">(</span>
    <span class="k">SELECT</span>
      <span class="n">session_id</span><span class="p">,</span>
      <span class="n">user_id</span><span class="p">,</span>
      <span class="p">(</span><span class="s1">'x'</span> <span class="o">||</span>
      <span class="n">LPAD</span><span class="p">(</span><span class="n">TO_HEX</span><span class="p">((</span><span class="n">SPLIT_PART</span><span class="p">(</span><span class="k">HOST</span><span class="p">(</span><span class="n">session_ip</span><span class="p">::</span><span class="n">INET</span><span class="p">),</span> <span class="s1">'.'</span><span class="p">,</span> <span class="mi">1</span><span class="p">)::</span><span class="nb">INTEGER</span><span class="p">)),</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">'0'</span><span class="p">)</span> <span class="o">||</span>
      <span class="n">LPAD</span><span class="p">(</span><span class="n">TO_HEX</span><span class="p">((</span><span class="n">SPLIT_PART</span><span class="p">(</span><span class="k">HOST</span><span class="p">(</span><span class="n">session_ip</span><span class="p">::</span><span class="n">INET</span><span class="p">),</span> <span class="s1">'.'</span><span class="p">,</span> <span class="mi">2</span><span class="p">)::</span><span class="nb">INTEGER</span><span class="p">)),</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">'0'</span><span class="p">)</span> <span class="o">||</span>
      <span class="n">LPAD</span><span class="p">(</span><span class="n">TO_HEX</span><span class="p">((</span><span class="n">SPLIT_PART</span><span class="p">(</span><span class="k">HOST</span><span class="p">(</span><span class="n">session_ip</span><span class="p">::</span><span class="n">INET</span><span class="p">),</span> <span class="s1">'.'</span><span class="p">,</span> <span class="mi">3</span><span class="p">)::</span><span class="nb">INTEGER</span><span class="p">)),</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">'0'</span><span class="p">)</span> <span class="o">||</span>
      <span class="n">LPAD</span><span class="p">(</span><span class="n">TO_HEX</span><span class="p">((</span><span class="n">SPLIT_PART</span><span class="p">(</span><span class="k">HOST</span><span class="p">(</span><span class="n">session_ip</span><span class="p">::</span><span class="n">INET</span><span class="p">),</span> <span class="s1">'.'</span><span class="p">,</span> <span class="mi">4</span><span class="p">)::</span><span class="nb">INTEGER</span><span class="p">)),</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">'0'</span><span class="p">)</span>                
      <span class="p">)::</span><span class="nb">BIT</span><span class="p">(</span><span class="mi">32</span><span class="p">)::</span><span class="nb">BIGINT</span> <span class="k">AS</span> <span class="n">session_ip</span>
    <span class="k">FROM</span>
      <span class="n">src_sessions</span>
  <span class="p">)</span> <span class="n">S</span>
  <span class="k">LEFT</span> <span class="k">JOIN</span>
    <span class="n">src_cidrs_countries</span> <span class="k">C</span>
    <span class="k">ON</span> <span class="n">S</span><span class="p">.</span><span class="n">session_ip</span> <span class="k">BETWEEN</span> <span class="k">C</span><span class="p">.</span><span class="n">start_ip</span> <span class="k">AND</span> <span class="k">C</span><span class="p">.</span><span class="n">end_ip</span><span class="p">;</span>
</code></pre></div>        </div>
      </div>
</details>
  </li>
</ul>

<hr />

<h1 id="5-results">5. Results</h1>
<blockquote>
  <ul>
    <li>최적화된 쿼리를 통해 실행 시간이 90% 대폭 감소하여 데이터 웨어하우스 성능 향상을 가져왔습니다.</li>
  </ul>
</blockquote>

<h3 id="1-긍정적인-결과">1. 긍정적인 결과</h3>

<ul>
  <li>최적화된 접근 방식을 통해 쿼리 실행 시간이 기존 100x시간에서 약 10x시간으로 감소하였습니다. 이는 실행 시간의 약 90%를 줄인 결과로, 데이터 처리 속도와 시스템 성능이 크게 개선되었습니다. 특히, 신규 접근 방식은 대규모 데이터 처리 시에도 안정적인 성능을 유지할 수 있도록 하였으며, 향후 데이터 증가에도 유연하게 대응할 수 있는 기반을 마련했습니다.</li>
  <li>이 최적화 작업은 데이터 웨어하우스의 효율성을 극대화하여 운영 비용을 절감하고, 더 나은 데이터 분석과 서비스 제공이 가능하도록 했습니다. 결과적으로, 시스템의 전반적인 성능이 크게 향상되었으며, 이로 인해 회사의 데이터 운영 전략에 중요한 기여를 할 수 있었습니다.</li>
</ul>

<h3 id="2-교훈">2. 교훈</h3>

<ul>
  <li>아래 그림과 같이, SQL의 JOIN은 Nested Loop 탐색 과정이 일어나므로 가장 면밀하게 검토해야 할 부분이었습니다.
<img src="/assets/2024-05-19-ip-address-to-country/3.webp" alt="" /></li>
</ul>

<h5 id="tip-1-join의-조건-역할을-하는-칼럼은-최대한-가벼운-타입을-지녀야-한다">(TIP 1) JOIN의 조건 역할을 하는 칼럼은 최대한 가벼운 타입을 지녀야 한다.</h5>
<ul>
  <li>기존 접근 방식에서는 <code class="language-plaintext highlighter-rouge">cidr</code> 칼럼이 CIDR 타입이었으나, 신규 접근 방식에서는 이를 BIGINT로 Parse하여 타입을 경량화시켰습니다.</li>
</ul>

<h5 id="tip-2-join의-조건-역할을-하는-연산자는-최대한-가벼운-과정이-되어야-한다">(TIP 2) JOIN의 조건 역할을 하는 연산자는 최대한 가벼운 과정이 되어야 한다.</h5>
<ul>
  <li>기존 접근 방식에서는 <code class="language-plaintext highlighter-rouge">&gt;&gt;=</code>라는 다소 무거운 연산자를 사용했으나, 신규 접근 방식에서는 이를 <code class="language-plaintext highlighter-rouge">BETWEEN</code> 연산자를 사용하여 부담을 줄였습니다.</li>
</ul>

<hr />

<h2 id="published-by-joshua-kim"><em>Published by</em> Joshua Kim</h2>
<p><img src="/assets/profile/joshua-profile.png" alt="Joshua Kim" /></p>]]></content><author><name></name></author><category term="Korean" /><category term="PostgreSQL" /><summary type="html"><![CDATA[“데이터 웨어하우스에서 IP 주소를 사용해 사용자의 국가 정보를 매핑하는 작업을 최적화하였습니다. 기존 방식은 연산 시간이 길어 비효율적이었으나, 새로운 접근 방식을 통해 쿼리 실행 시간을 90% 감소시켰습니다.”]]></summary></entry><entry><title type="html">IP Address-Country Mapping Query Optimization</title><link href="http://localhost:4000/ip-address-to-country-en/" rel="alternate" type="text/html" title="IP Address-Country Mapping Query Optimization" /><published>2024-05-19T00:00:00+09:00</published><updated>2024-05-19T00:00:00+09:00</updated><id>http://localhost:4000/ip-address-to-country-en</id><content type="html" xml:base="http://localhost:4000/ip-address-to-country-en/"><![CDATA[<blockquote>
  <p>“Optimized the process of mapping user country information using IP addresses in a data warehouse. The previous method was inefficient due to long processing times, but the new approach reduced query execution time by 90%.”</p>
</blockquote>

<hr />

<h1 id="table-of-contents">Table of Contents</h1>
<ol>
  <li>STAR Summary</li>
  <li>Situation</li>
  <li>Tasks</li>
  <li>Actions</li>
  <li>Results</li>
</ol>

<hr />

<h1 id="1-star-summary">1. STAR Summary</h1>

<h3 id="situation">Situation</h3>
<ul>
  <li>In an environment operating a global service, it was necessary to map user country information based on connection IP addresses. This task was performed using PostgreSQL, but the previous approach resulted in performance degradation. The existing query took too long to execute, placing a significant burden on data warehouse operations.</li>
</ul>

<h3 id="tasks">Tasks</h3>
<ul>
  <li>The goal was to optimize the existing IP address mapping query to drastically reduce processing time. This optimization aimed to improve the efficiency of the transformation process, achieving better data warehouse performance. Specifically, the core task was to optimize the computational process for IP address mapping and enhance the efficiency of the JOIN conditions.</li>
</ul>

<h3 id="actions">Actions</h3>

<ol>
  <li><strong>Analysis of the Existing Approach</strong>
    <ul>
      <li>The existing query used the <code class="language-plaintext highlighter-rouge">&lt;&lt;=</code> operator to map IP addresses to CIDR networks, identified as the main cause of performance degradation.</li>
    </ul>
  </li>
  <li><strong>Creation of a New Table</strong>
    <ul>
      <li>Created a new table, <code class="language-plaintext highlighter-rouge">dim_ips_countries</code>, by processing the existing table.
        <ul>
          <li>This table includes <code class="language-plaintext highlighter-rouge">start_ip</code> and <code class="language-plaintext highlighter-rouge">end_ip</code> columns.</li>
          <li>Converted IP addresses to BIGINT type to improve the efficiency of comparison operations.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>Index Creation</strong>
    <ul>
      <li>Created indexes on the <code class="language-plaintext highlighter-rouge">start_ip</code> and <code class="language-plaintext highlighter-rouge">end_ip</code> columns to maximize search performance.</li>
    </ul>
  </li>
  <li><strong>Query Optimization</strong>
    <ul>
      <li>Replaced the existing <code class="language-plaintext highlighter-rouge">&lt;&lt;=</code> operator with the <code class="language-plaintext highlighter-rouge">BETWEEN</code> operator to simplify IP address comparison and restructure the query for lightweight operations.</li>
    </ul>
  </li>
</ol>

<h3 id="results">Results</h3>
<ul>
  <li>The optimized query reduced execution time by 90%, significantly improving data warehouse performance.</li>
</ul>

<hr />

<h1 id="2-situation">2. Situation</h1>

<blockquote>
  <ul>
    <li>In an environment operating a global service, it was necessary to map user country information based on connection IP addresses. This task was performed using PostgreSQL, but the previous approach resulted in performance degradation. The existing query took too long to execute, placing a significant burden on data warehouse operations.</li>
  </ul>
</blockquote>

<h3 id="problem-summary">Problem Summary</h3>
<ul>
  <li>In an environment operating a global service, it was necessary to map IP addresses collected from user connections to geographical information such as the country. For this, a table mapping IP addresses to country names was created using PostgreSQL’s CIDR operator, but the existing method was highly inefficient.</li>
</ul>

<h3 id="specific-problem-context">Specific Problem Context</h3>
<ul>
  <li>The core task was to map the <code class="language-plaintext highlighter-rouge">session_ip</code> column in the <code class="language-plaintext highlighter-rouge">src_sessions</code> table to the <code class="language-plaintext highlighter-rouge">cidr</code> column in the <code class="language-plaintext highlighter-rouge">src_cidrs_countries</code> table to create the <code class="language-plaintext highlighter-rouge">fct_sessions</code> table.</li>
  <li>The existing query used the <code class="language-plaintext highlighter-rouge">&lt;&lt;=</code> operator to determine whether an IP address was included in a specific CIDR network. However, this method caused performance issues during large-scale data processing, with query execution times being excessively long. This degraded data warehouse performance and caused severe operational disruptions.</li>
</ul>

<hr />

<h1 id="3-tasks">3. Tasks</h1>
<blockquote>
  <ul>
    <li>The goal was to optimize the existing IP address mapping query to drastically reduce processing time. This optimization aimed to improve the efficiency of the transformation process, achieving better data warehouse performance. Specifically, the core task was to optimize the computational process for IP address mapping and enhance the efficiency of the JOIN conditions.</li>
  </ul>
</blockquote>

<h3 id="assigned-tasks"><strong>Assigned Tasks</strong></h3>
<ul>
  <li>The main objective was to significantly reduce the inefficient query execution time.</li>
</ul>

<h3 id="1-improve-data-processing-speed"><strong>1. Improve Data Processing Speed</strong></h3>
<ul>
  <li>Reduce execution time to enhance data processing efficiency and prevent disruption to service operations.</li>
</ul>

<h3 id="2-query-optimization"><strong>2. Query Optimization</strong></h3>
<ul>
  <li>Design and implement an optimized query structure that can perform IP address and country information mapping more efficiently.</li>
</ul>

<h3 id="3-system-performance-improvement"><strong>3. System Performance Improvement</strong></h3>
<ul>
  <li>Improve overall data warehouse performance to establish a foundation that can handle future data expansion and growth.</li>
</ul>

<hr />

<h1 id="4-actions">4. Actions</h1>

<blockquote>
  <ol>
    <li><strong>Analysis of the Existing Approach</strong>
      <ul>
        <li>The existing query used the <code class="language-plaintext highlighter-rouge">&lt;&lt;=</code> operator to map IP addresses to CIDR networks, identified as the main cause of performance degradation.</li>
      </ul>
    </li>
    <li><strong>Creation of a New Table</strong>
      <ul>
        <li>Created a new table, <code class="language-plaintext highlighter-rouge">dim_ips_countries</code>, by processing the existing table.
          <ul>
            <li>This table includes <code class="language-plaintext highlighter-rouge">start_ip</code> and <code class="language-plaintext highlighter-rouge">end_ip</code> columns.</li>
            <li>Converted IP addresses to BIGINT type to improve the efficiency of comparison operations.</li>
          </ul>
        </li>
      </ul>
    </li>
    <li><strong>Index Creation</strong>
      <ul>
        <li>Created indexes on the <code class="language-plaintext highlighter-rouge">start_ip</code> and <code class="language-plaintext highlighter-rouge">end_ip</code> columns to maximize search performance.</li>
      </ul>
    </li>
    <li><strong>Query Optimization</strong>
      <ul>
        <li>Replaced the existing <code class="language-plaintext highlighter-rouge">&lt;&lt;=</code> operator with the <code class="language-plaintext highlighter-rouge">BETWEEN</code> operator to simplify IP address comparison and restructure the query for lightweight operations.</li>
      </ul>
    </li>
  </ol>
</blockquote>

<h3 id="1-analysis-of-the-existing-approach">1. Analysis of the Existing Approach</h3>
<p><img src="/assets/2024-05-19-ip-address-to-country/1.webp" alt="" /></p>

<p><strong>(STEP 1)</strong> Create an index on the <code class="language-plaintext highlighter-rouge">src_cidrs_countries</code> table.</p>
<ul>
  <li>Since the <code class="language-plaintext highlighter-rouge">cidr</code> column needs to be frequently scanned during the JOIN operation with the <code class="language-plaintext highlighter-rouge">src_sessions</code> table, an index was created on this column.
    <details>
<summary>View code</summary>
<div>
        <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="k">CREATE</span> <span class="k">INDEX</span> <span class="n">idx_cidr</span> <span class="k">ON</span> <span class="n">src_cidrs_countries</span> <span class="p">(</span><span class="n">cidr</span><span class="p">);</span>
</code></pre></div>        </div>
      </div>
</details>
  </li>
</ul>

<p><strong>(STEP 2)</strong> Created the <code class="language-plaintext highlighter-rouge">fct_sessions</code> table by joining the <code class="language-plaintext highlighter-rouge">src_cidrs_countries</code> table with the <code class="language-plaintext highlighter-rouge">src_sessions</code> table.</p>
<ul>
  <li>The <code class="language-plaintext highlighter-rouge">&lt;&lt;=</code> operator was used in the JOIN process.</li>
  <li>However, this operator, which compares CIDR types, had a high computational cost, causing performance degradation during large-scale data processing.
    <details>
<summary>View code</summary>
<div>
        <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">fct_sessions</span> <span class="k">AS</span>
    <span class="k">SELECT</span>
      <span class="n">S</span><span class="p">.</span><span class="n">session_id</span><span class="p">,</span>
      <span class="n">S</span><span class="p">.</span><span class="n">user_id</span><span class="p">,</span>
      <span class="k">C</span><span class="p">.</span><span class="n">country</span>
    <span class="k">FROM</span>
      <span class="n">src_sessions</span> <span class="n">S</span>
    <span class="k">LEFT</span> <span class="k">JOIN</span>
      <span class="n">src_cidrs_countries</span> <span class="k">C</span>
      <span class="k">ON</span> <span class="n">S</span><span class="p">.</span><span class="n">session_ip</span><span class="p">::</span><span class="n">INET</span> <span class="o">&lt;&lt;=</span> <span class="k">C</span><span class="p">.</span><span class="n">cidr</span><span class="p">;</span>
</code></pre></div>        </div>
      </div>
</details>
  </li>
</ul>

<h3 id="2-creation-of-a-new-table">2. <strong>Creation of a New Table</strong></h3>
<p><img src="/assets/2024-05-19-ip-address-to-country/2.webp" alt="" /></p>

<ul>
  <li>A new table, <code class="language-plaintext highlighter-rouge">dim_ips_countries</code>, was created by processing the existing <code class="language-plaintext highlighter-rouge">src_cidrs_countries</code> table. This table was newly designed to minimize CIDR operations, adding <code class="language-plaintext highlighter-rouge">start_ip</code> and <code class="language-plaintext highlighter-rouge">end_ip</code> columns representing the IP address range for each CIDR value.</li>
  <li>By converting IP addresses to BIGINT type for storage, computation speed was greatly improved. <code class="language-plaintext highlighter-rouge">start_ip</code> and <code class="language-plaintext highlighter-rouge">end_ip</code> represent the lowest and highest IPs within the CIDR range, simplifying the process of verifying IP addresses within a CIDR network.</li>
</ul>
<details>
<summary>View code</summary>
<div>
    <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">dim_ips_countries</span> <span class="k">AS</span>
    <span class="k">SELECT</span>
      <span class="n">cidr</span><span class="p">,</span>
      <span class="p">(</span><span class="s1">'x'</span> <span class="o">||</span> 
      <span class="n">LPAD</span><span class="p">(</span><span class="n">TO_HEX</span><span class="p">((</span><span class="n">SPLIT_PART</span><span class="p">(</span><span class="k">HOST</span><span class="p">(</span><span class="n">cidr</span><span class="p">),</span> <span class="s1">'.'</span><span class="p">,</span> <span class="mi">1</span><span class="p">)::</span><span class="nb">INTEGER</span><span class="p">)),</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">'0'</span><span class="p">)</span> <span class="o">||</span>
      <span class="n">LPAD</span><span class="p">(</span><span class="n">TO_HEX</span><span class="p">((</span><span class="n">SPLIT_PART</span><span class="p">(</span><span class="k">HOST</span><span class="p">(</span><span class="n">cidr</span><span class="p">),</span> <span class="s1">'.'</span><span class="p">,</span> <span class="mi">2</span><span class="p">)::</span><span class="nb">INTEGER</span><span class="p">)),</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">'0'</span><span class="p">)</span> <span class="o">||</span>
      <span class="n">LPAD</span><span class="p">(</span><span class="n">TO_HEX</span><span class="p">((</span><span class="n">SPLIT_PART</span><span class="p">(</span><span class="k">HOST</span><span class="p">(</span><span class="n">cidr</span><span class="p">),</span> <span class="s1">'.'</span><span class="p">,</span> <span class="mi">3</span><span class="p">)::</span><span class="nb">INTEGER</span><span class="p">)),</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">'0'</span><span class="p">)</span> <span class="o">||</span>
      <span class="n">LPAD</span><span class="p">(</span><span class="n">TO_HEX</span><span class="p">((</span><span class="n">SPLIT_PART</span><span class="p">(</span><span class="k">HOST</span><span class="p">(</span><span class="n">cidr</span><span class="p">),</span> <span class="s1">'.'</span><span class="p">,</span> <span class="mi">4</span><span class="p">)::</span><span class="nb">INTEGER</span><span class="p">)),</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">'0'</span><span class="p">)</span>
      <span class="p">)::</span><span class="nb">BIT</span><span class="p">(</span><span class="mi">32</span><span class="p">)::</span><span class="nb">BIGINT</span> <span class="k">AS</span> <span class="n">start_ip</span><span class="p">,</span>
      <span class="p">(</span><span class="s1">'x'</span> <span class="o">||</span>
      <span class="n">LPAD</span><span class="p">(</span><span class="n">TO_HEX</span><span class="p">((</span><span class="n">SPLIT_PART</span><span class="p">(</span><span class="k">HOST</span><span class="p">(</span><span class="n">BROADCAST</span><span class="p">(</span><span class="n">cidr</span><span class="p">)),</span> <span class="s1">'.'</span><span class="p">,</span> <span class="mi">1</span><span class="p">)::</span><span class="nb">INTEGER</span><span class="p">)),</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">'0'</span><span class="p">)</span> <span class="o">||</span>
      <span class="n">LPAD</span><span class="p">(</span><span class="n">TO_HEX</span><span class="p">((</span><span class="n">SPLIT_PART</span><span class="p">(</span><span class="k">HOST</span><span class="p">(</span><span class="n">BROADCAST</span><span class="p">(</span><span class="n">cidr</span><span class="p">)),</span> <span class="s1">'.'</span><span class="p">,</span> <span class="mi">2</span><span class="p">)::</span><span class="nb">INTEGER</span><span class="p">)),</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">'0'</span><span class="p">)</span> <span class="o">||</span>
      <span class="n">LPAD</span><span class="p">(</span><span class="n">TO_HEX</span><span class="p">((</span><span class="n">SPLIT_PART</span><span class="p">(</span><span class="k">HOST</span><span class="p">(</span><span class="n">BROADCAST</span><span class="p">(</span><span class="n">cidr</span><span class="p">)),</span> <span class="s1">'.'</span><span class="p">,</span> <span class="mi">3</span><span class="p">)::</span><span class="nb">INTEGER</span><span class="p">)),</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">'0'</span><span class="p">)</span> <span class="o">||</span>
      <span class="n">LPAD</span><span class="p">(</span><span class="n">TO_HEX</span><span class="p">((</span><span class="n">SPLIT_PART</span><span class="p">(</span><span class="k">HOST</span><span class="p">(</span><span class="n">BROADCAST</span><span class="p">(</span><span class="n">cidr</span><span class="p">)),</span> <span class="s1">'.'</span><span class="p">,</span> <span class="mi">4</span><span class="p">)::</span><span class="nb">INTEGER</span><span class="p">)),</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">'0'</span><span class="p">)</span>
      <span class="p">)::</span><span class="nb">BIT</span><span class="p">(</span><span class="mi">32</span><span class="p">)::</span><span class="nb">BIGINT</span> <span class="k">AS</span> <span class="n">end_ip</span><span class="p">,</span>				
      <span class="n">country</span>
    <span class="k">FROM</span>
      <span class="n">src_cidrs_countries</span><span class="p">;</span>
</code></pre></div>    </div>
  </div>
</details>

<h3 id="3-index-creation">3. <strong>Index Creation</strong></h3>

<ul>
  <li>Since the <code class="language-plaintext highlighter-rouge">start_ip</code> and <code class="language-plaintext highlighter-rouge">end_ip</code> columns need to be frequently scanned during the JOIN operation with the <code class="language-plaintext highlighter-rouge">src_sessions</code> table, an index was created on these two columns.</li>
  <li>This index was designed to efficiently find values within an IP address range, enabling quick searches during JOIN operations.
    <details>
<summary>View code</summary>
<div>
        <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="k">CREATE</span> <span class="k">INDEX</span> <span class="n">idx_ip_range</span> <span class="k">ON</span> <span class="n">dim_ips_countries</span> <span class="p">(</span><span class="n">start_ip</span><span class="p">,</span> <span class="n">end_ip</span><span class="p">);</span>
</code></pre></div>        </div>
      </div>
</details>
  </li>
</ul>

<h3 id="4-query-optimization">4. <strong>Query Optimization</strong></h3>

<ul>
  <li>The existing <code class="language-plaintext highlighter-rouge">&lt;&lt;=</code> operator was replaced with the <code class="language-plaintext highlighter-rouge">BETWEEN</code> operator to simplify IP address comparison and restructure the query for lightweight operations.</li>
  <li>The <code class="language-plaintext highlighter-rouge">session_ip</code> column in the <code class="language-plaintext highlighter-rouge">src_sessions</code> table was also converted from CIDR to IP address, then to BIGINT type, to be compared with the <code class="language-plaintext highlighter-rouge">start_ip</code> and <code class="language-plaintext highlighter-rouge">end_ip</code> columns in the <code class="language-plaintext highlighter-rouge">dim_ips_countries</code> table.
    <details>
<summary>View code</summary>
<div>
        <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">fct_sessions</span> <span class="k">AS</span>
    <span class="k">SELECT</span>
    <span class="n">S</span><span class="p">.</span><span class="n">session_id</span><span class="p">,</span>
    <span class="n">S</span><span class="p">.</span><span class="n">user_id</span><span class="p">,</span>
    <span class="k">C</span><span class="p">.</span><span class="n">country</span>
  <span class="k">FROM</span> <span class="p">(</span>
    <span class="k">SELECT</span>
      <span class="n">session_id</span><span class="p">,</span>
      <span class="n">user_id</span><span class="p">,</span>
      <span class="p">(</span><span class="s1">'x'</span> <span class="o">||</span>
      <span class="n">LPAD</span><span class="p">(</span><span class="n">TO_HEX</span><span class="p">((</span><span class="n">SPLIT_PART</span><span class="p">(</span><span class="k">HOST</span><span class="p">(</span><span class="n">session_ip</span><span class="p">::</span><span class="n">INET</span><span class="p">),</span> <span class="s1">'.'</span><span class="p">,</span> <span class="mi">1</span><span class="p">)::</span><span class="nb">INTEGER</span><span class="p">)),</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">'0'</span><span class="p">)</span> <span class="o">||</span>
      <span class="n">LPAD</span><span class="p">(</span><span class="n">TO_HEX</span><span class="p">((</span><span class="n">SPLIT_PART</span><span class="p">(</span><span class="k">HOST</span><span class="p">(</span><span class="n">session_ip</span><span class="p">::</span><span class="n">INET</span><span class="p">),</span> <span class="s1">'.'</span><span class="p">,</span> <span class="mi">2</span><span class="p">)::</span><span class="nb">INTEGER</span><span class="p">)),</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">'0'</span><span class="p">)</span> <span class="o">||</span>
      <span class="n">LPAD</span><span class="p">(</span><span class="n">TO_HEX</span><span class="p">((</span><span class="n">SPLIT_PART</span><span class="p">(</span><span class="k">HOST</span><span class="p">(</span><span class="n">session_ip</span><span class="p">::</span><span class="n">INET</span><span class="p">),</span> <span class="s1">'.'</span><span class="p">,</span> <span class="mi">3</span><span class="p">)::</span><span class="nb">INTEGER</span><span class="p">)),</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">'0'</span><span class="p">)</span> <span class="o">||</span>
      <span class="n">LPAD</span><span class="p">(</span><span class="n">TO_HEX</span><span class="p">((</span><span class="n">SPLIT_PART</span><span class="p">(</span><span class="k">HOST</span><span class="p">(</span><span class="n">session_ip</span><span class="p">::</span><span class="n">INET</span><span class="p">),</span> <span class="s1">'.'</span><span class="p">,</span> <span class="mi">4</span><span class="p">)::</span><span class="nb">INTEGER</span><span class="p">)),</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">'0'</span><span class="p">)</span>                
      <span class="p">)::</span><span class="nb">BIT</span><span class="p">(</span><span class="mi">32</span><span class="p">)::</span><span class="nb">BIGINT</span> <span class="k">AS</span> <span class="n">session_ip</span>
    <span class="k">FROM</span>
      <span class="n">src_sessions</span>
  <span class="p">)</span> <span class="n">S</span>
  <span class="k">LEFT</span> <span class="k">JOIN</span>
    <span class="n">src_cidrs_countries</span> <span class="k">C</span>
    <span class="k">ON</span> <span class="n">S</span><span class="p">.</span><span class="n">session_ip</span> <span class="k">BETWEEN</span> <span class="k">C</span><span class="p">.</span><span class="n">start_ip</span> <span class="k">AND</span> <span class="k">C</span><span class="p">.</span><span class="n">end_ip</span><span class="p">;</span>
</code></pre></div>        </div>
      </div>
</details>
  </li>
</ul>

<hr />

<h1 id="5-results">5. Results</h1>
<blockquote>
  <ul>
    <li>The optimized query reduced execution time by 90%, significantly improving data warehouse performance.</li>
  </ul>
</blockquote>

<h3 id="1-positive-results">1. Positive Results</h3>

<ul>
  <li>The optimized approach reduced query execution time from approximately 100x to 10x, effectively cutting execution time by around 90%. This significantly improved data processing speed and system performance. The new approach also maintained stable performance during large-scale data processing and established a foundation that could flexibly respond to future data growth.</li>
  <li>This optimization effort maximized the efficiency of the data warehouse, reducing operational costs and enabling better data analysis and service delivery. As a result, the overall system performance was greatly enhanced, making a significant contribution to the company’s data operation strategy.</li>
</ul>

<h3 id="2-lessons-learned">2. Lessons Learned</h3>

<ul>
  <li>As shown in the figure below, SQL JOINs involve a nested loop search process, which needs to be carefully considered.
<img src="/assets/2024-05-19-ip-address-to-country/3.webp" alt="" /></li>
</ul>

<h5 id="tip-1-columns-used-in-join-conditions-should-have-lightweight-data-types">(TIP 1) Columns used in JOIN conditions should have lightweight data types.</h5>
<ul>
  <li>In the existing approach, the <code class="language-plaintext highlighter-rouge">cidr</code> column was of the CIDR type, but in the new approach, it was parsed into BIGINT to make the data type lighter.</li>
</ul>

<h5 id="tip-2-operators-used-in-join-conditions-should-have-lightweight-processes">(TIP 2) Operators used in JOIN conditions should have lightweight processes.</h5>
<ul>
  <li>In the existing approach, the heavier <code class="language-plaintext highlighter-rouge">&lt;&lt;=</code> operator was used, but in the new approach, the <code class="language-plaintext highlighter-rouge">BETWEEN</code> operator was used to reduce the burden.</li>
</ul>

<hr />

<h2 id="published-by-joshua-kim"><em>Published by</em> Joshua Kim</h2>
<p><img src="/assets/profile/joshua-profile.png" alt="Joshua Kim" /></p>]]></content><author><name></name></author><category term="English" /><category term="PostgreSQL" /><summary type="html"><![CDATA[“Optimized the process of mapping user country information using IP addresses in a data warehouse. The previous method was inefficient due to long processing times, but the new approach reduced query execution time by 90%.”]]></summary></entry><entry><title type="html">데이터 분석가의 SQL 최적화 일기: 코호트 리텐션 Batch Query 만들기</title><link href="http://localhost:4000/retention-batch-query/" rel="alternate" type="text/html" title="데이터 분석가의 SQL 최적화 일기: 코호트 리텐션 Batch Query 만들기" /><published>2024-01-01T00:00:00+09:00</published><updated>2024-01-01T00:00:00+09:00</updated><id>http://localhost:4000/retention-batch-query</id><content type="html" xml:base="http://localhost:4000/retention-batch-query/"><![CDATA[<blockquote>
  <p>코호트 리텐션의 의미와 중요성에 대해 말씀드리고, Batch Query를 사용하여 회원가입 월 코호트 별로 Monthly Range Retention을 계산하는 방법을 제시해드릴게요.</p>
</blockquote>

<h3 id="contents">CONTENTS</h3>
<ol>
  <li>코호트 리텐션의 의미와 중요성
    <ul>
      <li>1.1. 리텐션</li>
      <li>1.2. 코호트</li>
      <li>1.3. 코호트 리텐션</li>
      <li>1.4. 코호트 리텐션의 중요성</li>
    </ul>
  </li>
  <li>쿼리 작업 목표</li>
  <li>일회성 쿼리문
    <ul>
      <li>3.1. 쿼리문 보기</li>
      <li>3.2. 문제점</li>
    </ul>
  </li>
  <li>해결 아이디어</li>
  <li>Batch Query를 통해 접근하기</li>
  <li>결론</li>
</ol>

<hr />

<h3 id="disclaimer">DISCLAIMER</h3>
<p>본 아티클은 필자의 전/현 재직 기업의 데이터 분석 현황과 관련이 없으며, 단지 평소에 문제 의식을 지녔던 점에 대한 해결 방법을 스스로 도출해본 내용입니다. 쿼리문 작성에 다른 외부 레퍼런스를 참고하지 않았으며, 분석 환경에 따라 본 내용이 적합하지 않을 수 있으므로 반드시 비판적 고찰을 해주시면 감사드리겠습니다.</p>

<h1 id="1-코호트-리텐션의-의미와-중요성">1. 코호트 리텐션의 의미와 중요성</h1>

<h3 id="11-리텐션">1.1. 리텐션</h3>

<p>먼저, 리텐션은 “시간이 흐름에 따라 얼마나 많은 사용자들이 우리 프로덕트에 재참여하는지”를 나타내는 지표입니다. 이미 많은 분들이 아시듯 리텐션은 PMF를 달성하기 위해 분석해야 할 중요한 지표입니다. 이 정의가 꽤나 간단해보이지만, 측정하는 과정에서 실상은 그렇지 않습니다. “재참여”를 “재”와 “참여”로 나누어 각각의 사전 정의가 이루어져야 하기 때문입니다.</p>

<p><strong>“참여” 개념 정의하기</strong></p>

<p>사용자가 우리 프로덕트에 “참여”한다는 것이 정확히 어떤 순간인지 정의해야 합니다. 예를 들어, 접속, 30초 이상 세션 유지, 특정 퍼널 단계 도달 등 여러 이벤트 중 하나가 “참여”로 간주될 수 있습니다. 저는 개인적으로 아래 3가지 측면 정의를 모두 사전에 준비하여 Target Metric에 따라 적시적소에 모니터링하는 것이 필요하다고 느꼈습니다.</p>

<p>(1) “접속”을 하는 것만으로 참여한 것으로 간주하자!</p>
<ul>
  <li>DAU, WAU, MAU, Stickiness 등의 지표와 직접적으로 연관된 정의 방법이며, 광고 노출 효과를 극대화하는 경우 유용합니다.</li>
</ul>

<p>(2) “구매”까지 해야 참여한 것으로 간주하자!</p>
<ul>
  <li>재구매율 등의 지표와 직접적으로 연관된 정의 방법이며, Recurring Revenue가 중요한 프로덕트에서 중요합니다.</li>
</ul>

<p>(3) “아하 모먼트”에 도달해야 참여한 것으로 간주하자!</p>
<ul>
  <li><a href="https://www.youtube.com/watch?v=0KgOCKJ1PG4">토스의 이승건 대표님에 따르면</a>, 아하 모먼트란 프로덕트의 핵심 가치의 경험하는 순간을 의미합니다.</li>
  <li>X, Y, Z의 조합으로 이루어진 여러 가지 “X 이벤트를 Y 기간 내에 Z번 수행한다” 중 리텐션이 극명하게 높은(가령, 95%) 항목을 사전에 발견하여, 빠르게 PMF를 달성해야 할 때 유용합니다.</li>
</ul>

<p><strong>“재” 개념 정의하기</strong></p>

<p>사용자가 복귀했다는 것을 어떻게 계산할 것인가에 대한 정의가 필요합니다. <a href="https://product.kyobobook.co.kr/detail/S000001766457">양승화님의 그로스해킹에 따르면</a>, Classic Retention, Range Retention, Rolling Retention 중 프로덕트의 특성에 따라 적절한 방법을 선택할 수 있습니다.</p>

<p>(1) Classic Retention: 사용자가 최초로 “참여”한 Day 0 이후, 각 Day N 별로 한 번 더 “참여”했는지 계산합니다.</p>

<p>(2) Range Retention: Day N이 아니라 Week N, Bi-week N, Month N 별로 한 번 더 “참여”했는지 계산합니다.</p>

<p>(3) Rolling Retention: Day N 이후에 한 번이라도 “참여”한 경우를 계산합니다. (이탈률의 반대 개념)</p>

<p><strong>이러한 정의와 측정 방법을 통해 효과적인 리텐션 지표 측정이 가능해질 것입니다.</strong></p>

<h3 id="12-코호트">1.2. 코호트</h3>

<p>코호트의 개념을 두 가지로 혼용하는 경향이 있습니다.</p>
<ol>
  <li><em>“코호트는 세그먼트다. 즉, 사용자가 지닌 여러 가지 Feature 조합을 통해 그룹화된 클러스터다.”</em></li>
  <li><em>“코호트는 세그먼트의 일부로서, 특정 이벤트의 최초 수행일시를 기준으로 그룹화된 클러스터다.” (최초 프로덕트 방문일, 회원가입일, 최초 결제일 등)</em></li>
</ol>

<p>개인적으로는 세그먼트와의 혼동을 줄이기 위해 2번의 개념을 선호하지만, 코호트를 융통성 있게 설정하기 위해 1번 개념에서 언급한 다른 Feature 조합도 선택적으로 추가할 수 있는 “열린 개념”으로 받아들이고 있습니다.</p>

<ul>
  <li>예시 1) 사용자를 최초 프로덕트 방문일 기준으로 그룹화한다. → 코호트 O</li>
  <li>예시 2) 사용자를 최초 접속 국가 기준으로 그룹화한다. → 코호트 X</li>
  <li>예시 3) 사용자를 최초 프로덕트 방문일 및 접속 국가 기준으로 그룹화한다. → 코호트 O</li>
</ul>

<p>이렇게 하면 특정 이벤트의 최초 수행일시를 중심으로 하면서도 다양한 특성을 고려할 수 있어서 코호트를 보다 유연하게 활용할 수 있을 것입니다.</p>

<h3 id="13-코호트-리텐션">1.3. 코호트 리텐션</h3>

<p>코호트 리텐션이란, 기존의 리텐션 개념을 코호트에 따라 시리즈를 달리하여 계산한 지표를 의미합니다. 예를 들면, 최초 프로덕트 방문일을 기준으로 사용자들의 리텐션이 상승 추세인지, 혹은 하락 추세인지를 알 수 있는 것이죠.</p>

<h3 id="14-코호트-리텐션의-중요성">1.4. 코호트 리텐션의 중요성</h3>

<p>아래의 리텐션 지표를 통해 PMF 달성 여부를 확인할 수 있지만, 문제를 파악하거나 액션 포인트를 도출하는 데는 그다지 도움이 되지 않습니다.</p>

<p><img src="/assets/2024-01-01-retention-batch-query/retention.webp" alt="" /></p>
<blockquote>
  <p><a href="https://mermaid.js.org/syntax/xyChart.html">mermaid</a>를 통해 필자가 직접 작성</p>
</blockquote>

<p>그러나 코호트 리텐션 값을 확인할 수 있다면, 프로덕트의 기능 업데이트나 캠페인 론칭 등에 따른 사후 효과를 확인하고, 리텐션 향상을 위해 우리가 어떤 액션에 좀 더 집중해야 하는지 확인하는 데 도움을 줄 수 있습니다.</p>

<p><img src="/assets/2024-01-01-retention-batch-query/cohort-retention.webp" alt="" /></p>
<blockquote>
  <p><a href="https://mermaid.js.org/syntax/xyChart.html">mermaid</a>를 통해 필자가 직접 작성</p>
</blockquote>

<h1 id="2-쿼리-작업-목표">2. 쿼리 작업 목표</h1>

<p>쿼리 작업 목표는 다음과 같습니다. 아래와 같은 테이블을 대시보드에 반영해보고자 합니다. 즉, 회원가입 연월(YYYY-MM) 코호트별 리텐션(Monthly Range)테이블을 배포하여 다양한 이해당사자 분들이 리텐션 지표의 시계열 추이를 확인하시는 데 도움을 드리려는 것입니다.</p>

<p><img src="/assets/2024-01-01-retention-batch-query/task-goal.webp" alt="" /></p>
<blockquote>
  <p>제가 직접 샘플로 만들어본 위 테이블에서는 시간이 흐를수록 리텐션이 향상되는 추이를 보여주고 있군요.</p>
</blockquote>

<p>그런데, 위와 같은 테이블을 만들기 위해서는 SQL의 최후 출력 상태가 다음과 같은 Unpivoted한 형태가 되어야 합니다. 물론 Pivoted한 형태로 직접 출력하는 방법도 있지만, 오늘의 토픽인 “Batch Query 만들기”를 위해서는 Unpivoted한 형태가 되어야 합니다. Table을 Update를 방지하고, 오로지 Insert 작업만 수행함으로써 연산 부하를 방지하기 위함인데요. 지금부터 차차 읽어가시면 이해가 되실 겁니다.</p>

<p><img src="/assets/2024-01-01-retention-batch-query/last-query-results.webp" alt="" /></p>
<blockquote>
  <p>필자가 직접 작성</p>
</blockquote>

<h1 id="3-일회성-쿼리문">3. 일회성 쿼리문</h1>

<h3 id="31-쿼리문-보기">3.1. 쿼리문 보기</h3>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">WITH</span>

<span class="c1">-- 1. 사용자들의 "참여" (회원가입 및 로그인 이벤트) 소스 테이블을 불러온다.</span>
<span class="n">CTE_engagements</span> <span class="k">AS</span> <span class="p">(</span>
    <span class="k">SELECT</span>
        <span class="n">user_id</span><span class="p">,</span>
        <span class="n">DATE_TRUNC</span><span class="p">(</span><span class="s1">'DAY'</span><span class="p">,</span> <span class="nb">datetime</span><span class="p">)</span> <span class="k">AS</span> <span class="nb">date</span>
    <span class="k">FROM</span>
        <span class="n">signups_logins</span>
    <span class="k">GROUP</span> <span class="k">BY</span>
        <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span>
<span class="p">),</span>

<span class="c1">-- 2. 사용자들을 회원가입일 기준의 코호트로 Labeling해준다.</span>
<span class="n">CTE_cohorts</span> <span class="k">AS</span> <span class="p">(</span>
    <span class="k">SELECT</span>
        <span class="n">user_id</span><span class="p">,</span>
        <span class="k">MIN</span><span class="p">(</span><span class="nb">date</span><span class="p">)</span> <span class="k">AS</span> <span class="n">cohort_date</span>
    <span class="k">FROM</span>
        <span class="n">CTE_engagements</span>
    <span class="k">GROUP</span> <span class="k">BY</span>
        <span class="mi">1</span>
<span class="p">),</span>

<span class="c1">-- 3. 사용자들의 "참여" 테이블과 "코호트 Labeling" 테이블을 조인하여 "Day N"도 함께 표시해준다.</span>
<span class="n">CTE_engagements_with_cohorts_daily</span> <span class="k">AS</span> <span class="p">(</span>
    <span class="k">SELECT</span>
        <span class="n">ENG</span><span class="p">.</span><span class="n">user_id</span><span class="p">,</span>
        <span class="n">ENG</span><span class="p">.</span><span class="nb">date</span><span class="p">,</span>
        <span class="n">COH</span><span class="p">.</span><span class="n">cohort_date</span><span class="p">,</span>
        <span class="n">DATE_DIFF</span><span class="p">(</span>
            <span class="n">ENG</span><span class="p">.</span><span class="nb">date</span><span class="p">,</span>
            <span class="n">COH</span><span class="p">.</span><span class="n">cohort_date</span><span class="p">,</span>
            <span class="k">DAY</span>
        <span class="p">)</span> <span class="k">AS</span> <span class="n">day_n</span>
    <span class="k">FROM</span>
        <span class="n">CTE_engagements</span> <span class="n">ENG</span>
    <span class="k">LEFT</span> <span class="k">JOIN</span>
        <span class="n">CTE_cohorts</span> <span class="n">COH</span>
        <span class="k">USING</span> <span class="p">(</span><span class="n">user_id</span><span class="p">)</span>
<span class="p">),</span>

<span class="c1">-- 4. "Day N"을 "Month N"으로 변환해준다.</span>
<span class="n">CTE_engagements_with_cohorts_monthly</span> <span class="k">AS</span> <span class="p">(</span>
    <span class="k">SELECT</span>
        <span class="n">user_id</span><span class="p">,</span>
        <span class="n">DATE_TRUNC</span><span class="p">(</span><span class="s1">'MONTH'</span><span class="p">,</span> <span class="nb">date</span><span class="p">)</span> <span class="k">AS</span> <span class="n">yyyymm</span><span class="p">,</span>
        <span class="n">DATE_TRUNC</span><span class="p">(</span><span class="s1">'MONTH'</span><span class="p">,</span> <span class="n">cohort_date</span><span class="p">)</span> <span class="k">AS</span> <span class="n">cohort_yyyymm</span><span class="p">,</span>
        <span class="n">DATE_DIFF</span><span class="p">(</span>
            <span class="nb">date</span><span class="p">,</span>
            <span class="n">cohort_date</span><span class="p">,</span>
            <span class="k">MONTH</span>
        <span class="p">)</span> <span class="k">AS</span> <span class="n">month_n</span>
    <span class="k">FROM</span>
        <span class="n">CTE_engagements_with_cohorts_daily</span>
<span class="p">),</span>

<span class="c1">-- 5. 코호트 및 "Month N" 기준으로 사용자 수를 집계한다.</span>
<span class="n">CTE_month_n_cnt</span> <span class="k">AS</span> <span class="p">(</span>
    <span class="k">SELECT</span>
        <span class="n">cohort_yyyymm</span><span class="p">,</span>
        <span class="n">month_n</span><span class="p">,</span>
        <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="n">user_id</span><span class="p">)</span> <span class="k">AS</span> <span class="n">users_cnt</span>
    <span class="k">FROM</span>
        <span class="n">CTE_engagements_with_cohorts_monthly</span>
    <span class="k">GROUP</span> <span class="k">BY</span>
        <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span>
<span class="p">),</span>

<span class="c1">-- 6. 최종 리텐션을 계산한다.</span>
<span class="n">CTE_monthly_retention</span> <span class="k">AS</span> <span class="p">(</span>
    <span class="k">SELECT</span>
        <span class="n">cohort_yyyymm</span><span class="p">,</span>
        <span class="n">month_n</span><span class="p">,</span>
        <span class="k">CAST</span><span class="p">(</span><span class="n">users_cnt</span> <span class="k">AS</span> <span class="nb">DOUBLE</span><span class="p">)</span>
        <span class="o">/</span>
        <span class="k">CAST</span><span class="p">(</span><span class="n">FIRST_VALUE</span><span class="p">(</span><span class="n">users_cnt</span><span class="p">)</span> <span class="n">OVER</span> <span class="p">(</span>
            <span class="k">PARTITION</span> <span class="k">BY</span> <span class="n">cohort_yyyymm</span>
            <span class="k">ORDER</span> <span class="k">BY</span> <span class="n">month_n</span>
            <span class="k">ROWS</span> <span class="k">BETWEEN</span> <span class="n">UNBOUNDED</span> <span class="k">PRECEDING</span> <span class="k">AND</span> <span class="n">UNBOUNDED</span> <span class="k">FOLLOWING</span>
            <span class="p">)</span> <span class="k">AS</span> <span class="nb">DOUBLE</span>
        <span class="p">)</span> <span class="k">AS</span> <span class="n">monthly_retention</span>
    <span class="k">FROM</span>
        <span class="n">CTE_month_n_cnt</span>
    <span class="k">ORDER</span> <span class="k">BY</span>
        <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span>
<span class="p">)</span>
<span class="k">SELECT</span>
    <span class="o">*</span>
<span class="k">FROM</span>
    <span class="n">CTE_monthly_retention</span>
<span class="p">;</span>
</code></pre></div></div>

<h3 id="32-문제점">3.2. 문제점</h3>

<p>위 쿼리문의 출력 결과는 앞서 잠깐 보여드린 아래와 같은 형태의 테이블을 출력합니다. 그런데, 매번 전체 소스 테이블을 메모리에 올려 리텐션을 계산하려면 연산량이 과도하게 많이 들어 리소스 낭비로 이어지게 됩니다.</p>

<p><img src="/assets/2024-01-01-retention-batch-query/last-query-results.webp" alt="" /></p>
<blockquote>
  <p>필자가 직접 작성</p>
</blockquote>

<h1 id="4-해결-아이디어">4. 해결 아이디어</h1>

<p>마침, Cohort 칼럼과 Month 칼럼이 시계열 형식을 지니고 있으므로 미래의 데이터가 과거의 데이터에 영향을 끼칠 수 없습니다. 또한, 출력된 테이블은  <a href="https://www.kimballgroup.com/data-warehouse-business-intelligence-resources/kimball-techniques/dimensional-modeling-techniques/periodic-snapshot-fact-table/">Periodic Snapshot Fact Table</a>의 유형에 해당합니다. 바로 이 점으로부터 우리는 Batch Query를 활용할 수 있는 여지를 발견할 수 있습니다. 즉, 아래와 같이 매월 1일 00:01 UTC마다 새롭게 획득한 리텐션 값들을 Insert할 수 있는 Batch Query를 작성할 수 있는 것입니다. 특히 이벤트 로그 데이터의 크기가 매우 큰 프로덕트를 운영하고 있다면, 굳이 매번 일회성 쿼리문을 실행할 필요가 없는 셈이죠.</p>

<p><img src="/assets/2024-01-01-retention-batch-query/idea.webp" alt="" /></p>
<blockquote>
  <p>즉, 매월 초마다 좌측 테이블의 빨간색 영역들을 순차적으로 신규 계산하여 테이블 Insert 스케줄링을 구현할 수 있는 것이죠. (필자가 직접 작성)</p>
</blockquote>

<h1 id="5-batch-query를-통해-접근하기">5. Batch Query를 통해 접근하기</h1>

<p><strong>STEP 1) 사용자들의 “참여” 소스 테이블을 불러온다. (단, 현재 시점 기준으로 7개월 전의 월초부터 1개월 전의 월말까지 항목만)</strong></p>

<p><img src="/assets/2024-01-01-retention-batch-query/step1.webp" alt="" /></p>
<blockquote>
  <p>필자가 직접 작성</p>
</blockquote>

<ul>
  <li>로그인했을 때 사용자가 “참여”했다고 가정 하에, 로그인 이벤트를 불러온다.</li>
  <li>코호트는 “회원가입” 기준으로 정의할 것이므로, 회원가입 이벤트도 함께 불러온다.</li>
  <li>Monthly Range Retention은 Month 0부터 Month 6까지만 계산한다.</li>
</ul>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">WITH</span>  
  
<span class="c1">-- 1. 사용자들의 "참여" (회원가입 및 로그인 이벤트) 소스 테이블을 불러온다.  </span>
<span class="c1">-- (단, 현재 시점 기준으로 7개월 전의 월초부터 1개월 전의 월말까지 항목만)  </span>
<span class="n">CTE_engagements</span> <span class="k">AS</span> <span class="p">(</span>  
    <span class="k">SELECT</span>  
        <span class="n">user_id</span><span class="p">,</span>  
        <span class="n">DATE_TRUNC</span><span class="p">(</span><span class="s1">'DAY'</span><span class="p">,</span> <span class="nb">datetime</span><span class="p">)</span> <span class="k">AS</span>  <span class="nb">date</span>  
    <span class="k">FROM</span>
        <span class="k">source</span><span class="p">.</span><span class="n">signups_logins</span>
    <span class="nv">"if is_incremental()"</span>
    <span class="k">WHERE</span>  
        <span class="c1">-- 현재 시점 기준으로 7개월 전의 월초부터 ~  </span>
        <span class="n">DATE_TRUNC</span><span class="p">(</span><span class="s1">'MONTH'</span><span class="p">,</span> <span class="k">CURRENT_DATE</span><span class="p">)</span> <span class="o">-</span> <span class="n">INTERVAL</span> <span class="s1">'7'</span> <span class="k">MONTH</span>  
        <span class="o">&lt;=</span> <span class="n">DATE_TRUNC</span><span class="p">(</span><span class="s1">'DAY'</span><span class="p">,</span> <span class="nb">datetime</span><span class="p">)</span>  
        <span class="c1">-- ~ 현재 시점 기준으로 1개월 전의 월말까지  </span>
        <span class="k">AND</span> <span class="n">DATE_TRUNC</span><span class="p">(</span><span class="s1">'DAY'</span><span class="p">,</span> <span class="nb">datetime</span><span class="p">)</span>  
        <span class="o">&lt;=</span> <span class="n">DATE_TRUNC</span><span class="p">(</span><span class="s1">'MONTH'</span><span class="p">,</span> <span class="k">CURRENT_DATE</span><span class="p">)</span> <span class="o">-</span> <span class="n">INTERVAL</span> <span class="s1">'1'</span> <span class="k">DAY</span>  
    <span class="nv">"endif"</span>
    <span class="k">GROUP</span> <span class="k">BY</span>  
        <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span>  
<span class="p">),</span>
</code></pre></div></div>

<p><strong>STEP 2) 사용자들을 회원가입일 기준의 코호트로 Labeling해준다.</strong></p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">-- 2. 사용자들을 회원가입일 기준의 코호트로 Labeling해준다.  </span>
<span class="n">CTE_cohorts</span> <span class="k">AS</span> <span class="p">(</span>  
    <span class="k">SELECT</span>  
        <span class="n">user_id</span><span class="p">,</span>  
        <span class="k">MIN</span><span class="p">(</span><span class="nb">date</span><span class="p">)</span> <span class="k">AS</span> <span class="n">cohort_date</span>  
    <span class="k">FROM</span>  
        <span class="n">CTE_engagements</span>  
    <span class="k">GROUP</span> <span class="k">BY</span>  
        <span class="mi">1</span>  
<span class="p">),</span>
</code></pre></div></div>

<p><strong>STEP 3) 사용자들의 “참여” 테이블과 “코호트 Labeling” 테이블을 조인하여 “Day N”도 함께 표시해준다.</strong></p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">-- 3. 사용자들의 "참여" 테이블과 "코호트 Labeling" 테이블을 조인하여 "Day N"도 함께 표시해준다.  </span>
<span class="n">CTE_engagements_with_cohorts_daily</span> <span class="k">AS</span> <span class="p">(</span>  
    <span class="k">SELECT</span>  
        <span class="n">ENG</span><span class="p">.</span><span class="n">user_id</span><span class="p">,</span>  
        <span class="n">ENG</span><span class="p">.</span><span class="nb">date</span><span class="p">,</span>  
        <span class="n">COH</span><span class="p">.</span><span class="n">cohort_date</span><span class="p">,</span>  
        <span class="n">DATE_DIFF</span><span class="p">(</span>  
            <span class="n">ENG</span><span class="p">.</span><span class="nb">date</span><span class="p">,</span>  
            <span class="n">COH</span><span class="p">.</span><span class="n">cohort_date</span><span class="p">,</span>  
            <span class="k">DAY</span>  
        <span class="p">)</span> <span class="k">AS</span> <span class="n">day_n</span>  
    <span class="k">FROM</span>  
        <span class="n">CTE_engagements</span> <span class="n">ENG</span>  
    <span class="k">LEFT</span> <span class="k">JOIN</span>  
        <span class="n">CTE_cohorts</span> <span class="n">COH</span>  
        <span class="k">USING</span> <span class="p">(</span><span class="n">user_id</span><span class="p">)</span>  
<span class="p">),</span>
</code></pre></div></div>

<p><strong>STEP 4) “Day N”을 “Month N”으로 변환해준다.</strong></p>
<ul>
  <li>Monthly Range Retention을 계산해야 하기 때문이다.</li>
</ul>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">-- 4. "Day N"을 "Month N"으로 변환해준다.  </span>
<span class="n">CTE_engagements_with_cohorts_monthly</span> <span class="k">AS</span> <span class="p">(</span>  
    <span class="k">SELECT</span>  
        <span class="n">user_id</span><span class="p">,</span>  
        <span class="n">DATE_TRUNC</span><span class="p">(</span><span class="s1">'MONTH'</span><span class="p">,</span> <span class="nb">date</span><span class="p">)</span> <span class="k">AS</span> <span class="n">yyyymm</span><span class="p">,</span>  
        <span class="n">DATE_TRUNC</span><span class="p">(</span><span class="s1">'MONTH'</span><span class="p">,</span> <span class="n">cohort_date</span><span class="p">)</span> <span class="k">AS</span> <span class="n">cohort_yyyymm</span><span class="p">,</span>  
        <span class="n">DATE_DIFF</span><span class="p">(</span>  
            <span class="nb">date</span><span class="p">,</span>  
            <span class="n">cohort_date</span><span class="p">,</span>  
            <span class="k">MONTH</span>  
        <span class="p">)</span> <span class="k">AS</span> <span class="n">month_n</span>  
    <span class="k">FROM</span>  
        <span class="n">CTE_engagements_with_cohorts_daily</span>  
<span class="p">),</span>
</code></pre></div></div>

<p><strong>STEP 5) 코호트 및 “Month N” 기준으로 사용자 수를 집계한다.</strong></p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">-- 5. 코호트 및 "Month N" 기준으로 사용자 수를 집계한다.  </span>
<span class="n">CTE_month_n_cnt</span> <span class="k">AS</span> <span class="p">(</span>  
    <span class="k">SELECT</span>  
        <span class="n">cohort_yyyymm</span><span class="p">,</span>  
        <span class="n">month_n</span><span class="p">,</span>  
        <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="n">user_id</span><span class="p">)</span> <span class="k">AS</span> <span class="n">users_cnt</span>  
    <span class="k">FROM</span>  
        <span class="n">CTE_engagements_with_cohorts_monthly</span>  
    <span class="k">GROUP</span> <span class="k">BY</span>  
        <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span>  
<span class="p">),</span>
</code></pre></div></div>

<p><strong>STEP 6) 최종 리텐션을 계산한다.</strong></p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">-- 6. 최종 리텐션을 계산한다.  </span>
<span class="n">CTE_monthly_retention</span> <span class="k">AS</span> <span class="p">(</span>  
    <span class="k">SELECT</span>  
        <span class="n">cohort_yyyymm</span><span class="p">,</span>  
        <span class="n">month_n</span><span class="p">,</span>  
        <span class="k">CAST</span><span class="p">(</span><span class="n">users_cnt</span> <span class="k">AS</span> <span class="nb">DOUBLE</span><span class="p">)</span>  
        <span class="o">/</span>  
        <span class="k">CAST</span><span class="p">(</span><span class="n">FIRST_VALUE</span><span class="p">(</span><span class="n">users_cnt</span><span class="p">)</span> <span class="n">OVER</span> <span class="p">(</span>  
            <span class="k">PARTITION</span> <span class="k">BY</span> <span class="n">cohort_yyyymm</span>  
            <span class="k">ORDER</span> <span class="k">BY</span> <span class="n">month_n</span>  
            <span class="k">ROWS</span> <span class="k">BETWEEN</span> <span class="n">UNBOUNDED</span> <span class="k">PRECEDING</span> <span class="k">AND</span> <span class="n">UNBOUNDED</span> <span class="k">FOLLOWING</span>  
        <span class="p">)</span>  
        <span class="k">AS</span> <span class="n">monthly_retention</span>  
    <span class="k">FROM</span>  
        <span class="n">CTE_month_n_cnt</span>  
    <span class="k">ORDER</span> <span class="k">BY</span>  
        <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span>  
<span class="p">)</span>
</code></pre></div></div>

<p><strong>STEP 7) 중복되지 않은 신규 항목들만 Insert할 수 있도록 조건화한다.</strong></p>

<p><img src="/assets/2024-01-01-retention-batch-query/step7.webp" alt="" /></p>
<blockquote>
  <p>필자가 직접 작성</p>
</blockquote>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">-- 7. 중복되지 않은 신규 항목들만 Insert할 수 있도록 조건화한다.  </span>
<span class="n">CTE_monthly_retention_inserted</span> <span class="k">AS</span> <span class="p">(</span>  
    <span class="k">SELECT</span>  
        <span class="o">*</span>  
    <span class="k">FROM</span>  
        <span class="n">CTE_monthly_retention</span>  
    <span class="nv">"if is_incremental()"</span>
    <span class="k">WHERE</span>  
        <span class="c1">-- 현재 시점 기준으로 1개월 전의 코호트: Month 0 리텐션 값만 Insert한다.  </span>
        <span class="p">(</span><span class="n">cohort_yyyymm</span> <span class="o">=</span> <span class="n">DATE_TRUNC</span><span class="p">(</span><span class="s1">'MONTH'</span><span class="p">,</span> <span class="k">CURRENT_DATE</span><span class="p">)</span> <span class="o">-</span> <span class="n">INTERVAL</span> <span class="s1">'1'</span> <span class="k">MONTH</span> <span class="k">AND</span> <span class="n">month_n</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>  
        <span class="c1">-- 현재 시점 기준으로 2개월 전의 코호트: Month 1 리텐션 값만 Insert한다.  </span>
        <span class="k">OR</span> <span class="p">(</span><span class="n">cohort_yyyymm</span> <span class="o">=</span> <span class="n">DATE_TRUNC</span><span class="p">(</span><span class="s1">'MONTH'</span><span class="p">,</span> <span class="k">CURRENT_DATE</span><span class="p">)</span> <span class="o">-</span> <span class="n">INTERVAL</span> <span class="s1">'2'</span> <span class="k">MONTH</span> <span class="k">AND</span> <span class="n">month_n</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>  
        <span class="c1">-- 현재 시점 기준으로 3개월 전의 코호트: Month 2 리텐션 값만 Insert한다.  </span>
        <span class="k">OR</span> <span class="p">(</span><span class="n">cohort_yyyymm</span> <span class="o">=</span> <span class="n">DATE_TRUNC</span><span class="p">(</span><span class="s1">'MONTH'</span><span class="p">,</span> <span class="k">CURRENT_DATE</span><span class="p">)</span> <span class="o">-</span> <span class="n">INTERVAL</span> <span class="s1">'3'</span> <span class="k">MONTH</span> <span class="k">AND</span> <span class="n">month_n</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span>  
        <span class="c1">-- 현재 시점 기준으로 4개월 전의 코호트: Month 3 리텐션 값만 Insert한다.  </span>
        <span class="k">OR</span> <span class="p">(</span><span class="n">cohort_yyyymm</span> <span class="o">=</span> <span class="n">DATE_TRUNC</span><span class="p">(</span><span class="s1">'MONTH'</span><span class="p">,</span> <span class="k">CURRENT_DATE</span><span class="p">)</span> <span class="o">-</span> <span class="n">INTERVAL</span> <span class="s1">'4'</span> <span class="k">MONTH</span> <span class="k">AND</span> <span class="n">month_n</span> <span class="o">=</span> <span class="mi">3</span><span class="p">)</span>  
        <span class="c1">-- 현재 시점 기준으로 5개월 전의 코호트: Month 4 리텐션 값만 Insert한다.  </span>
        <span class="k">OR</span> <span class="p">(</span><span class="n">cohort_yyyymm</span> <span class="o">=</span> <span class="n">DATE_TRUNC</span><span class="p">(</span><span class="s1">'MONTH'</span><span class="p">,</span> <span class="k">CURRENT_DATE</span><span class="p">)</span> <span class="o">-</span> <span class="n">INTERVAL</span> <span class="s1">'5'</span> <span class="k">MONTH</span> <span class="k">AND</span> <span class="n">month_n</span> <span class="o">=</span> <span class="mi">4</span><span class="p">)</span>  
        <span class="c1">-- 현재 시점 기준으로 6개월 전의 코호트: Month 5 리텐션 값만 Insert한다.  </span>
        <span class="k">OR</span> <span class="p">(</span><span class="n">cohort_yyyymm</span> <span class="o">=</span> <span class="n">DATE_TRUNC</span><span class="p">(</span><span class="s1">'MONTH'</span><span class="p">,</span> <span class="k">CURRENT_DATE</span><span class="p">)</span> <span class="o">-</span> <span class="n">INTERVAL</span> <span class="s1">'6'</span> <span class="k">MONTH</span> <span class="k">AND</span> <span class="n">month_n</span> <span class="o">=</span> <span class="mi">5</span><span class="p">)</span>  
        <span class="c1">-- 현재 시점 기준으로 7개월 전의 코호트: Month 6 리텐션 값만 Insert한다.  </span>
        <span class="k">OR</span> <span class="p">(</span><span class="n">cohort_yyyymm</span> <span class="o">=</span> <span class="n">DATE_TRUNC</span><span class="p">(</span><span class="s1">'MONTH'</span><span class="p">,</span> <span class="k">CURRENT_DATE</span><span class="p">)</span> <span class="o">-</span> <span class="n">INTERVAL</span> <span class="s1">'7'</span> <span class="k">MONTH</span> <span class="k">AND</span> <span class="n">month_n</span> <span class="o">=</span> <span class="mi">6</span><span class="p">)</span>  
    <span class="nv">"endif"</span>
    <span class="k">ORDER</span> <span class="k">BY</span>  
        <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span>  
<span class="p">)</span>
</code></pre></div></div>

<p><strong>STEP 8) 출력한다.</strong></p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">SELECT</span>  
    <span class="o">*</span>  
<span class="k">FROM</span>  
    <span class="n">CTE_monthly_retention_inserted</span>  
<span class="p">;</span>
</code></pre></div></div>

<h1 id="6-결론">6. 결론</h1>

<p>Data Mart나 Batch Query에 대한 이론은 누구나 쉽게 온라인에서 공부할 수 있지만, 실제 Metrics 별로 모범이 될 만한 레퍼런스를 찾기가 어려운 것 같습니다. 특히, 리텐션의 경우 분명히 일회성 쿼리의 문제점을 해결해야 할 필요성이 클 것임에도 불구하고 저는 개인적으로 구글링을 통해서 적절한 레퍼런스를 전혀 찾지 못했습니다. 그래서 이참에 퍼블릭 레퍼런스를 제가 한 번 만들어보자는 결심이 들어 이렇게 글을 적어봤습니다.</p>

<p>그러나 저의 레퍼런스가 절대로 정답은 아닐 것입니다. Batch Query 모범 사례를 찾기 어렵다는 점은 그만큼 각 프로덕트의 도메인 특수성과 데이터의 형태가 극명하게 달라 절대불변의 정답이 없다는 의미일지도 모르겠습니다.</p>

<p>그러므로, 저의 사례는 가볍게 참고만 해주시고, 독자 분들께서 처한 다양한 특수성에 따라 가장 효율적인 리텐션 측정 환경을 구축하시길 바라겠습니다. 물론, 저의 논리적 오류나 개선 방향에 대한 피드백도 언제나 감사히 받겠습니다. 읽어주셔서 감사합니다.</p>

<hr />

<h2 id="published-by-joshua-kim"><em>Published by</em> Joshua Kim</h2>
<p><img src="/assets/profile/joshua-profile.png" alt="Joshua Kim" /></p>]]></content><author><name></name></author><category term="Korean" /><category term="Data Analysis" /><category term="SQL" /><category term="Data Warehouse" /><summary type="html"><![CDATA[코호트 리텐션의 의미와 중요성에 대해 말씀드리고, Batch Query를 사용하여 회원가입 월 코호트 별로 Monthly Range Retention을 계산하는 방법을 제시해드릴게요.]]></summary></entry><entry><title type="html">데이터 분석가의 SQL 최적화 일기: SELF JOIN을 피하는 방법</title><link href="http://localhost:4000/how-to-avoid-self-joins/" rel="alternate" type="text/html" title="데이터 분석가의 SQL 최적화 일기: SELF JOIN을 피하는 방법" /><published>2023-11-30T00:00:00+09:00</published><updated>2023-11-30T00:00:00+09:00</updated><id>http://localhost:4000/how-to-avoid-self-joins</id><content type="html" xml:base="http://localhost:4000/how-to-avoid-self-joins/"><![CDATA[<blockquote>
  <p>대고객 서빙을 위해 엄청나게 큰 사이즈의 소스 테이블로부터 최적화된 데이터 마트 설계 고민을 많이 하고 있는 만큼, 이번에는 SELF JOIN 사례를 중심으로 SQL 성능에 대한 이야기를 들려드리겠습니다.</p>
</blockquote>

<h3 id="contents">CONTENTS</h3>
<ol>
  <li>들어가는 글</li>
  <li>Python과 달리 거칠게 사고해야 하는 SQL</li>
  <li>SELF JOIN을 하면 연산량이 제곱으로 늘어난다.</li>
  <li>Subquery와 EXISTS 사용하기</li>
  <li>결론: 무조건적 우월성은 없다.</li>
</ol>

<hr />

<h3 id="disclaimer">DISCLAIMER</h3>

<p>본 자료는 작성자 본인의 견해일 뿐이며, 실제 데이터베이스의 환경에 따라 적합하지 않을 수 있습니다. 이미지 출처를 제외한 모든 쿼리문과 내용은 본인의 경험에 의해 작성되었습니다. 작성된 쿼리문은 샘플로 작성한 것이며, 본인의 과거 및 현재 재직 회사의 업무 현황과 무관합니다.</p>

<h1 id="1-들어가는-글">1. 들어가는 글</h1>

<p><img src="/assets/2023-11-30-how-to-avoid-self-joins/join-meme.webp" alt="" /></p>
<blockquote>
  <p><a href="https://miro.medium.com/v2/resize:fit:800/1*DTET9ngrx2Gzu6ZJk0G9BQ.jpeg">Source</a></p>
</blockquote>

<p>안녕하세요. 저는 친구들 얼굴을 보면 위와 같은 이상한 생각을 하는 데이터 분석가 Joshua라고 합니다.</p>

<p>저는 일반적인 B2C 기업에서 데이터 분석가로 근무하며, GA4, Amplitude, BigQuery, Redash 등을 활용하여 A/B 테스트, 지표 모니터링 등을 수행하며 회사의 등대 역할을 하며 지냈습니다. 다른 분들과 비슷한 역할을 수행했던 것이죠.</p>

<p>또한 GA4, Amplitude 등과 같은 B2B 데이터 분석 플랫폼 서비스를 만드는 경험도 살짝 했는데요. 그러다보니 저의 R&amp;R은 서비스 자체의 데이터 분석 업무 외에도, 고객들에게 데이터를 서빙하기 위한 데이터 마트 설계와 최적화 업무에 집중되기도 했습니다. 제 타이틀을 멋있게 가공하면 최근에 떠오르는 포지션인 Analytics Engineer, 반쪽 짜리 데이터 엔지니어, 아니면 대충 쿼리 머신 혹은 분지니어(?)인 것 같기도 합니다. 😅</p>

<p>대고객 서빙을 위해 엄청나게 큰 사이즈의 소스 테이블로부터 최적화된 데이터 마트 설계 고민을 많이 하고 있는 만큼, 이번에는 SELF JOIN 사례를 중심으로 SQL 성능에 대한 이야기를 들려드리겠습니다.
(SQL 전문가 분들이 많이 계시는 만큼, 제 글을 비판적으로 고찰해주시면 감사하겠습니다! 😄)</p>

<p>쿼리로 고통 받으며 눈동자에 비가 내렸던 경험 이야기, 시작합니다! (울지마~ 울지마~ 울지마~)</p>

<p><img src="/assets/2023-11-30-how-to-avoid-self-joins/crying-cat-meme.avif" alt="" /></p>
<blockquote>
  <p><a href="https://www.google.com/url?sa=i&amp;url=https%3A%2F%2Fwww.dailydot.com%2Fnews%2Fcat-crying-memes-explainer%2F&amp;psig=AOvVaw1JpDJ5k_6Tx93h2YT8in_Y&amp;ust=1702536707113000&amp;source=images&amp;cd=vfe&amp;opi=89978449&amp;ved=0CBMQjRxqFwoTCMC01dLpi4MDFQAAAAAdAAAAABAD">Source</a></p>
</blockquote>

<h1 id="2-python과-달리-거칠게-사고해야-하는-sql">2. Python과 달리 거칠게 사고해야 하는 SQL</h1>

<p>SQL을 통해 OLAP(Online Analytical Processing)에 해당하는 데이터 웨어하우스를 구축하다보면, 종종  <strong>SELF JOIN</strong>이 필요합니다. 가령, 소스 테이블의 복사본인 Staging Table을 Pivoting 해야 하거나, 칼럼 A와 칼럼 B 간의 관계 규칙을 찾아 Data Cleaning을 해야 하는 경우에 특히 발생하는 것 같았어요.</p>

<p>가령, Python의 Pandas Dataframe 환경에서는 메소드를 통해 너무나도 쉽게 Pivoting을 하거나, 반복문과 조건문을 통해 칼럼 사이의 관계 규칙을 고작 몇 줄 코드 만으로 Data Cleaning을 할 수 있을 것입니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pandas</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">.</span><span class="n">pivot</span>
<span class="n">pandas</span><span class="p">.</span><span class="nf">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">value</span> <span class="k">if</span> <span class="n">condition</span> <span class="ow">is</span> <span class="n">true</span> <span class="k">if</span> <span class="n">x</span> <span class="n">condition</span> <span class="k">else</span> <span class="n">value</span> <span class="n">of</span> <span class="n">condition</span> <span class="ow">is</span> <span class="n">false</span><span class="p">)</span>
</code></pre></div></div>

<p>하지만 안타깝게도 SQL에서는 다소 거친 방법으로 쿼리문을 작성해야 하므로 좀 더 테이블 자체를 기반의 Logical Thinking을 하는 것이 중요합니다.</p>

<p>가령 다음 기본적인 사례와 같이, 국가 별로 MAU를 집계할 경우에 SQL은 훨씬 거칠게 표현합니다.</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">SELECT</span>  
   <span class="n">DATE_TRUNC</span><span class="p">(</span><span class="s1">'MONTH'</span><span class="p">,</span> <span class="nb">datetime</span><span class="p">)</span> <span class="k">AS</span> <span class="n">yyyymm</span><span class="p">,</span>  
   <span class="n">country</span><span class="p">,</span>  
   <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="n">user_id</span><span class="p">)</span> <span class="k">AS</span> <span class="n">mau</span>  
<span class="k">FROM</span>  
   <span class="n">source_events</span>  
<span class="k">GROUP</span> <span class="k">BY</span>  
   <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span>  
<span class="k">ORDER</span> <span class="k">BY</span>  
   <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span>  
<span class="p">;</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">source_events</span><span class="p">[</span><span class="sh">'</span><span class="s">yyyymm</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">to_datetime</span><span class="p">(</span><span class="n">source_events</span><span class="p">[</span><span class="sh">'</span><span class="s">datetime</span><span class="sh">'</span><span class="p">]).</span><span class="n">dt</span><span class="p">.</span><span class="nf">to_period</span><span class="p">(</span><span class="sh">'</span><span class="s">M</span><span class="sh">'</span><span class="p">)</span>  
<span class="n">result_df</span> <span class="o">=</span> <span class="n">source_events</span><span class="p">.</span><span class="nf">groupby</span><span class="p">([</span><span class="sh">'</span><span class="s">yyyymm</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">country</span><span class="sh">'</span><span class="p">]).</span><span class="nf">agg</span><span class="p">(</span><span class="n">mau</span><span class="o">=</span><span class="p">(</span><span class="sh">'</span><span class="s">user_id</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">nunique</span><span class="sh">'</span><span class="p">)).</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>  
<span class="n">result_df</span> <span class="o">=</span> <span class="n">result_df</span><span class="p">.</span><span class="nf">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">yyyymm</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">country</span><span class="sh">'</span><span class="p">]).</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>  
<span class="nf">print</span><span class="p">(</span><span class="n">result_df</span><span class="p">)</span>
</code></pre></div></div>

<p>즉, 파이썬의  <code class="language-plaintext highlighter-rouge">to_period</code>,  <code class="language-plaintext highlighter-rouge">groupby</code>,  <code class="language-plaintext highlighter-rouge">nunique</code>  등과 같은 내장 메소드의 연산 원리를 이해하여 이를  <code class="language-plaintext highlighter-rouge">DATE_TRUNC</code>,  <code class="language-plaintext highlighter-rouge">COUNT(DISTINCT …)</code>,  <code class="language-plaintext highlighter-rouge">GROUP BY</code>  등의 SQL 함수와 Statement로 표현해야 하는 것이죠.</p>

<h1 id="3-self-join을-하면-연산량이-제곱으로-늘어난다">3. SELF JOIN을 하면 연산량이 제곱으로 늘어난다.</h1>

<p>먼저 다음과 같은 쿼리문 사례를 살펴보도록 하죠.</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">SELECT</span>  
   <span class="n">MAIN</span><span class="p">.</span><span class="nb">datetime</span><span class="p">,</span>  
   <span class="n">MAIN</span><span class="p">.</span><span class="n">user_id</span><span class="p">,</span>  
   <span class="n">MAIN</span><span class="p">.</span><span class="n">session_id</span><span class="p">,</span>  
   <span class="n">MAIN</span><span class="p">.</span><span class="n">event_index</span><span class="p">,</span>  
   <span class="n">MAIN</span><span class="p">.</span><span class="n">event_param_index</span><span class="p">,</span>  
   <span class="n">MAIN</span><span class="p">.</span><span class="n">event_param_key</span><span class="p">,</span>  
   <span class="n">MAIN</span><span class="p">.</span><span class="n">event_param_value</span>  
<span class="k">FROM</span>  
   <span class="n">source_events</span> <span class="n">MAIN</span>  
<span class="k">LEFT</span> <span class="k">JOIN</span>  
   <span class="n">source_events</span> <span class="n">SUB</span>  
   <span class="k">ON</span> <span class="n">MAIN</span><span class="p">.</span><span class="n">user_id</span> <span class="o">=</span> <span class="n">SUB</span><span class="p">.</span><span class="n">user_id</span>  
      <span class="k">AND</span> <span class="n">MAIN</span><span class="p">.</span><span class="n">session_id</span> <span class="o">=</span> <span class="n">SUB</span><span class="p">.</span><span class="n">session_id</span>  
      <span class="k">AND</span> <span class="n">MAIN</span><span class="p">.</span><span class="n">event_index</span> <span class="o">=</span> <span class="n">SUB</span><span class="p">.</span><span class="n">event_index</span>  
<span class="k">WHERE</span>  
   <span class="n">MAIN</span><span class="p">.</span><span class="n">event_param_index</span> <span class="o">=</span> <span class="n">SUB</span><span class="p">.</span><span class="n">event_param_index</span> <span class="o">+</span> <span class="mi">0</span>  
   <span class="k">OR</span> <span class="n">MAIN</span><span class="p">.</span><span class="n">event_param_index</span> <span class="o">=</span> <span class="n">SUB</span><span class="p">.</span><span class="n">event_param_index</span> <span class="o">+</span> <span class="mi">1</span>  
   <span class="k">OR</span> <span class="n">MAIN</span><span class="p">.</span><span class="n">event_param_index</span> <span class="o">=</span> <span class="n">SUB</span><span class="p">.</span><span class="n">event_param_index</span> <span class="o">+</span> <span class="mi">2</span>  
   <span class="k">OR</span> <span class="n">MAIN</span><span class="p">.</span><span class="n">event_param_index</span> <span class="o">=</span> <span class="n">SUB</span><span class="p">.</span><span class="n">event_param_index</span> <span class="o">+</span> <span class="mi">3</span>
</code></pre></div></div>

<p>위 사례는 가령 이런 상황으로 이해하시면 될 것 같습니다. 사용자의 이벤트 로그 소스 테이블에서 각 이벤트의 파라미터 key-value가 unnested된 상태로 존재하거나, 혹은 특정 파라미터의 index를 기준으로 인접한 파라미터 정보들만 추출해야 하는 상황에서 위와 같은 쿼리문 작성이 필요할 것입니다.</p>

<p>SQL의 연산 과정은  <strong>FROM → XXX JOIN → WHERE → GROUP BY → SELECT → HAVING → ORDER BY</strong>  등의 순으로 진행되는데요. 위 쿼리문을 연산하는 과정에서 WHERE Statement에 진입하기 전에, 먼저 FROM과 LEFT JOIN을 통해 모든 Row를 메모리에 로드하게 됩니다.</p>

<p><img src="/assets/2023-11-30-how-to-avoid-self-joins/sql-processing.webp" alt="" /></p>
<blockquote>
  <p><a href="https://blog.kakaocdn.net/dn/ckOt66/btrjP1TVZsq/Ta9JdTTiEd9tddkKkFk2n1/img.png">Source</a></p>
</blockquote>

<p>가령,  <code class="language-plaintext highlighter-rouge">source_events</code>  테이블이 1,000,000개의 Row로 구성되어 있다면, 최대 1,000,000 * 1,000,000개의 Row가 메모리에 올라오게 되는 것이죠. 이는 쿼리 엔진의 메모리 및 트래픽 DevOps 환경이 중요한 경우 분명히 문제가 됩니다. 혹은 Usage Limit이 걸려 있을 경우에는 쿼리 실행이 몇 시간 동안 진행되다가 아침에 눈을 떠보면 트래픽 제한으로 인해 실행이 실패되었다는 매우 슬프고 참담한 상황에 마주하게 될 것입니다.</p>

<p><img src="/assets/2023-11-30-how-to-avoid-self-joins/crying-meme.webp" alt="" /></p>
<blockquote>
  <p><a href="https://res.heraldm.com/content/image/2021/07/16/20210716000671_0.jpg">Source</a></p>
</blockquote>

<p>그렇다면, 이런 상황에서 어떻게 쿼리를 최적화할 수 있을까요?</p>

<h1 id="4-subquery와-exists-사용하기">4. Subquery와 EXISTS 사용하기</h1>

<p>위에서 보셨던 쿼리문을 아래와 같이 수정해봤습니다.</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">SELECT</span>  
   <span class="nb">datetime</span><span class="p">,</span>  
   <span class="n">user_id</span><span class="p">,</span>  
   <span class="n">session_id</span><span class="p">,</span>  
   <span class="n">event_index</span><span class="p">,</span>  
   <span class="n">event_param_index</span><span class="p">,</span>  
   <span class="n">event_param_key</span><span class="p">,</span>  
   <span class="n">event_param_value</span>  
<span class="k">FROM</span>  
   <span class="n">source_events</span> <span class="n">MAIN</span>  
<span class="k">WHERE</span>  
   <span class="k">EXISTS</span> <span class="p">(</span>  
      <span class="k">SELECT</span> <span class="mi">1</span>  
      <span class="k">FROM</span> <span class="n">source_events</span> <span class="n">SUB</span>  
      <span class="k">WHERE</span>  
         <span class="n">event_type</span> <span class="o">=</span> <span class="s1">'click_button'</span>  
         <span class="k">AND</span> <span class="n">MAIN</span><span class="p">.</span><span class="n">user_id</span> <span class="o">=</span> <span class="n">SUB</span><span class="p">.</span><span class="n">user_id</span>  
         <span class="k">AND</span> <span class="n">MAIN</span><span class="p">.</span><span class="n">session_id</span> <span class="o">=</span> <span class="n">SUB</span><span class="p">.</span><span class="n">session_id</span>  
         <span class="k">AND</span> <span class="n">MAIN</span><span class="p">.</span><span class="n">event_index</span> <span class="o">=</span> <span class="n">SUB</span><span class="p">.</span><span class="n">event_index</span>  
         <span class="k">AND</span> <span class="p">(</span>  
            <span class="n">MAIN</span><span class="p">.</span><span class="n">event_param_index</span> <span class="o">=</span> <span class="n">SUB</span><span class="p">.</span><span class="n">event_param_index</span> <span class="o">+</span> <span class="mi">0</span>  
            <span class="k">OR</span> <span class="n">MAIN</span><span class="p">.</span><span class="n">event_param_index</span> <span class="o">=</span> <span class="n">SUB</span><span class="p">.</span><span class="n">event_param_index</span> <span class="o">+</span> <span class="mi">1</span>  
            <span class="k">OR</span> <span class="n">MAIN</span><span class="p">.</span><span class="n">event_param_index</span> <span class="o">=</span> <span class="n">SUB</span><span class="p">.</span><span class="n">event_param_index</span> <span class="o">+</span> <span class="mi">2</span>  
            <span class="k">OR</span> <span class="n">MAIN</span><span class="p">.</span><span class="n">event_param_index</span> <span class="o">=</span> <span class="n">SUB</span><span class="p">.</span><span class="n">event_param_index</span> <span class="o">+</span> <span class="mi">3</span>  
         <span class="p">)</span>  
   <span class="p">)</span>
</code></pre></div></div>

<p>자, 어떻게 달라졌는지 차근차근 살펴보도록 하죠.</p>

<h3 id="1-먼저-left-join이-사라지고-where-statement의-subquery가-추가되었습니다">1. 먼저, LEFT JOIN이 사라지고, WHERE Statement의 Subquery가 추가되었습니다.</h3>

<p>JOIN보다 Subquery가 반드시 모든 상황에서 성능이 우월하지는 않지만, 이 상황에서는 메모리 데이터의 사이즈는 상당 부분 해소되었습니다. 앞서 말씀 드린 것처럼, SQL은 WHERE Statement를 고려하기 전에 먼저 FROM과 LEFT JOIN을 먼저 실행하게 되는데, WHERE Statement의 Subquery로 옮김으로써 LEFT JOIN에서 실행되어야 하는 작업을 WHERE에서 동시에 연산하여 메모리에 올릴 수 있게 되었습니다.</p>

<p>가령,  <code class="language-plaintext highlighter-rouge">source_events</code>  테이블의 Row 수가 1,000,000개 이고, WHERE를 통해 Filter out된 Row 수가 10,000개라면, 메모리에 올라가게 되는 Row 수는 이전의 최대 1,000,000 * 1,000,000개에서 1,000,000 * 10,000개로 1% 수준으로 급감하였습니다.</p>

<h3 id="2-in보다-exists가-연산-속도가-더-빠릅니다">2. IN보다 EXISTS가 연산 속도가 더 빠릅니다.</h3>

<p>IN과 EXISTS 모두 “<strong>XXX한 경우가 존재하니?</strong>”를 질문하는 과정으로 추상화할 수 있을 것 같은데요.</p>

<p>만약 IN을 통해 Filter out하려고 하면 가령 아래와 같은 쿼리문을 작성해야 합니다.</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">WHERE</span>  
   <span class="n">MAIN</span><span class="p">.</span><span class="n">event_param_index</span> <span class="k">IN</span> <span class="p">(</span><span class="k">SELECT</span> <span class="n">SUB</span><span class="p">.</span><span class="n">event_param_index</span> <span class="o">+</span> <span class="mi">0</span> <span class="k">FROM</span> <span class="p">...)</span>  
   <span class="k">AND</span> <span class="n">MAIN</span><span class="p">.</span><span class="n">event_param_index</span> <span class="k">IN</span> <span class="p">(</span><span class="k">SELECT</span> <span class="n">SUB</span><span class="p">.</span><span class="n">event_param_index</span> <span class="o">+</span> <span class="mi">1</span> <span class="k">FROM</span> <span class="p">...)</span>  
   <span class="k">AND</span> <span class="n">MAIN</span><span class="p">.</span><span class="n">event_param_index</span> <span class="k">IN</span> <span class="p">(</span><span class="k">SELECT</span> <span class="n">SUB</span><span class="p">.</span><span class="n">event_param_index</span> <span class="o">+</span> <span class="mi">2</span> <span class="k">FROM</span> <span class="p">...)</span>  
   <span class="k">AND</span> <span class="n">MAIN</span><span class="p">.</span><span class="n">event_param_index</span> <span class="k">IN</span> <span class="p">(</span><span class="k">SELECT</span> <span class="n">SUB</span><span class="p">.</span><span class="n">event_param_index</span> <span class="o">+</span> <span class="mi">3</span> <span class="k">FROM</span> <span class="p">...)</span>  
<span class="p">...</span>
</code></pre></div></div>

<p>위 과정은 한 가지 단점이 있습니다.  <code class="language-plaintext highlighter-rouge">SUB.event_param_index</code>  칼럼의 값들을 일일이 출력해야 하는데요. 즉, 다양한 값들로 구성된 칼럼을 메모리에 로드해야 한다는 것이죠.</p>

<p>그러나 EXISTS를 통해 Filter out하려고 하면 아래와 같은 쿼리문으로 수정될 수 있습니다.</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">WHERE</span>  
   <span class="k">EXISTS</span> <span class="p">(</span>  
      <span class="k">SELECT</span> <span class="mi">1</span>  
      <span class="k">FROM</span> <span class="p">...</span>  
      <span class="k">WHERE</span>  
         <span class="p">...</span>  
         <span class="k">AND</span> <span class="p">(</span>  
         <span class="n">MAIN</span><span class="p">.</span><span class="n">event_param_index</span> <span class="o">=</span> <span class="n">SUB</span><span class="p">.</span><span class="n">event_param_index</span> <span class="o">+</span> <span class="mi">0</span>  
         <span class="k">OR</span> <span class="n">MAIN</span><span class="p">.</span><span class="n">event_param_index</span> <span class="o">=</span> <span class="n">SUB</span><span class="p">.</span><span class="n">event_param_index</span> <span class="o">+</span> <span class="mi">1</span>  
         <span class="k">OR</span> <span class="n">MAIN</span><span class="p">.</span><span class="n">event_param_index</span> <span class="o">=</span> <span class="n">SUB</span><span class="p">.</span><span class="n">event_param_index</span> <span class="o">+</span> <span class="mi">2</span>  
         <span class="k">OR</span> <span class="n">MAIN</span><span class="p">.</span><span class="n">event_param_index</span> <span class="o">=</span> <span class="n">SUB</span><span class="p">.</span><span class="n">event_param_index</span> <span class="o">+</span> <span class="mi">3</span>  
   <span class="p">)</span>
</code></pre></div></div>

<p>이 과정은 위에서 말씀 드린 IN의 단점을 상당 부분 해소합니다.  <code class="language-plaintext highlighter-rouge">SUB.event_param_index</code>  칼럼의 값들을 일일이 출력했던 것과 달리, 이번에는 조건을 만족하기만 하면 단순히 일괄적으로  <code class="language-plaintext highlighter-rouge">1</code>로만 구성된 칼럼을 메모리에 로드하게 됩니다. Data Type 측면에서 훨씬 메모리의 부담을 경감시킬 수 있습니다. (혹은 <code class="language-plaintext highlighter-rouge">1</code>이 아니라,  <code class="language-plaintext highlighter-rouge">True</code>나  <code class="language-plaintext highlighter-rouge">False</code>와 같은 Boolean 타입으로 출력하면 더 확실하게 경감시킬 수 있을 것 같네요.)</p>

<h1 id="5-결론-무조건적-우월성은-없다">5. 결론: 무조건적 우월성은 없다.</h1>

<p>자 이제 다시 최적화된 쿼리문 전체를 보시죠.</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">SELECT</span>  
   <span class="nb">datetime</span><span class="p">,</span>  
   <span class="n">user_id</span><span class="p">,</span>  
   <span class="n">session_id</span><span class="p">,</span>  
   <span class="n">event_index</span><span class="p">,</span>  
   <span class="n">event_param_index</span><span class="p">,</span>  
   <span class="n">event_param_key</span><span class="p">,</span>  
   <span class="n">event_param_value</span>  
<span class="k">FROM</span>  
   <span class="n">source_events</span> <span class="n">MAIN</span>  
<span class="k">WHERE</span>  
   <span class="k">EXISTS</span> <span class="p">(</span>  
      <span class="k">SELECT</span> <span class="mi">1</span>  
      <span class="k">FROM</span> <span class="n">source_events</span> <span class="n">SUB</span>  
      <span class="k">WHERE</span>  
         <span class="n">event_type</span> <span class="o">=</span> <span class="s1">'click_button'</span>  
         <span class="k">AND</span> <span class="n">MAIN</span><span class="p">.</span><span class="n">user_id</span> <span class="o">=</span> <span class="n">SUB</span><span class="p">.</span><span class="n">user_id</span>  
         <span class="k">AND</span> <span class="n">MAIN</span><span class="p">.</span><span class="n">session_id</span> <span class="o">=</span> <span class="n">SUB</span><span class="p">.</span><span class="n">session_id</span>  
         <span class="k">AND</span> <span class="n">MAIN</span><span class="p">.</span><span class="n">event_index</span> <span class="o">=</span> <span class="n">SUB</span><span class="p">.</span><span class="n">event_index</span>  
         <span class="k">AND</span> <span class="p">(</span>  
            <span class="n">MAIN</span><span class="p">.</span><span class="n">event_param_index</span> <span class="o">=</span> <span class="n">SUB</span><span class="p">.</span><span class="n">event_param_index</span> <span class="o">+</span> <span class="mi">0</span>  
            <span class="k">OR</span> <span class="n">MAIN</span><span class="p">.</span><span class="n">event_param_index</span> <span class="o">=</span> <span class="n">SUB</span><span class="p">.</span><span class="n">event_param_index</span> <span class="o">+</span> <span class="mi">1</span>  
            <span class="k">OR</span> <span class="n">MAIN</span><span class="p">.</span><span class="n">event_param_index</span> <span class="o">=</span> <span class="n">SUB</span><span class="p">.</span><span class="n">event_param_index</span> <span class="o">+</span> <span class="mi">2</span>  
            <span class="k">OR</span> <span class="n">MAIN</span><span class="p">.</span><span class="n">event_param_index</span> <span class="o">=</span> <span class="n">SUB</span><span class="p">.</span><span class="n">event_param_index</span> <span class="o">+</span> <span class="mi">3</span>  
         <span class="p">)</span>  
   <span class="p">)</span>
</code></pre></div></div>

<p>프로그래밍에는 반드시 “<strong>방법 A가 방법 B보다 우월하다.</strong>”라는 것은 존재하지 않은 것처럼, 각자의 환경에 따라 취사선택하며 최적화를 하는 것이 중요할 것입니다.</p>

<p>WHERE Statement의 Subquery가 JOIN보다 반드시 우월한 것도 아니고, 경우에 따라 EXISTS가 IN보다 반드시 뛰어난 성능을 보이지 않을 수도 있습니다.</p>

<p>또한, 일반적으로 Subquery와 EXISTS 문법은 SQL 초급 사용자 분들께는 살짝 팔로업하기 어려울 수 있으므로, 가독성 측면에서 추후 유지보수의 장애로 작용할 수도 있을 것입니다.</p>

<p><img src="/assets/2023-11-30-how-to-avoid-self-joins/infinite-challenge.webp" alt="" /></p>
<blockquote>
  <p><a href="https://i.pinimg.com/736x/cd/c3/57/cdc35735e9efc721d26a0f3f780178a4.jpg">Source</a></p>
</blockquote>

<p>앞으로, 대용량의 데이터 소스를 다루시다가 SELF JOIN 때문에 트래픽 문제가 발생하신다면 위와 같은 사례로도 접근 가능하다는 점을 참고하시고, 각자 처한 환경에 따라 최적화하여 가성비 좋은 데이터 분석을 하시길 바랄게요. 부족한 글을 읽어주셔서 감사합니다!</p>

<p><img src="/assets/2023-11-30-how-to-avoid-self-joins/bye-guys.webp" alt="" /></p>
<blockquote>
  <p>퇴사하겠다는 의미가 아니라, 계속 쿼리 작성하러 가겠다는 의미</p>
</blockquote>

<hr />

<h2 id="published-by-joshua-kim"><em>Published by</em> Joshua Kim</h2>
<p><img src="/assets/profile/joshua-profile.png" alt="Joshua Kim" /></p>]]></content><author><name></name></author><category term="Korean" /><category term="Data Analysis" /><category term="SQL" /><summary type="html"><![CDATA[대고객 서빙을 위해 엄청나게 큰 사이즈의 소스 테이블로부터 최적화된 데이터 마트 설계 고민을 많이 하고 있는 만큼, 이번에는 SELF JOIN 사례를 중심으로 SQL 성능에 대한 이야기를 들려드리겠습니다.]]></summary></entry><entry><title type="html">데이터 분석가의 SQL 최적화 일기: Static vs. Rolling Stickiness</title><link href="http://localhost:4000/static-vs-rolling-stickiness/" rel="alternate" type="text/html" title="데이터 분석가의 SQL 최적화 일기: Static vs. Rolling Stickiness" /><published>2023-11-19T00:00:00+09:00</published><updated>2023-11-19T00:00:00+09:00</updated><id>http://localhost:4000/static-vs-rolling-stickiness</id><content type="html" xml:base="http://localhost:4000/static-vs-rolling-stickiness/"><![CDATA[<blockquote>
  <p>대고객 서빙을 위해 엄청나게 큰 사이즈의 소스 테이블로부터 최적화된 데이터 마트 설계 고민을 많이 하고 있는 만큼, Stickiness 지표 사례를 중심으로 SQL 성능에 대한 이야기를 들려드리겠습니다.</p>
</blockquote>

<h3 id="contents">CONTENTS</h3>
<ol>
  <li>들어가는 글</li>
  <li>Rolling MAU vs. 30일 이동평균선</li>
  <li>Static MAU</li>
  <li>Stickiness 지표</li>
  <li>Rolling Stickiness</li>
  <li>Static Stickiness</li>
  <li>Data Mart를 통해 Rolling MAU 도입하기</li>
  <li>결론: Query Cost vs Data Freshness</li>
</ol>

<hr />

<h3 id="disclaimer">DISCLAIMER</h3>
<blockquote>
  <p>본 자료는 작성자 본인의 견해일 뿐이며, 실제 데이터베이스의 환경에 따라 적합하지 않을 수 있습니다. 이미지 출처를 제외한 모든 쿼리문과 내용은 본인의 경험에 의해 작성되었습니다. 작성된 쿼리문은 샘플로 작성한 것이며, 본인의 과거 및 현재 재직 회사의 업무 현황과 무관합니다.</p>
</blockquote>

<h1 id="1-들어가는-글">1. 들어가는 글</h1>

<p><img src="/assets/2023-11-19-static-vs-rolling-stickiness/unfinished-work.webp" alt="" /></p>
<blockquote>
  <p><a href="https://datasciencedojo.com/blog/data-science-memes/">Source</a></p>
</blockquote>

<p>안녕하세요. 저는 위 아이 처럼 데이터 분석가로 근무하고 있는 Joshua라고 합니다.</p>

<p>저는 일반적인 B2C 기업에서 데이터 분석가로 근무하며, GA4, Amplitude, BigQuery, Redash 등을 활용하여 A/B 테스트, 지표 모니터링 등을 수행하며 회사의 등대 역할을 하며 지냈습니다. 다른 분들과 비슷한 역할을 수행했던 것이죠.</p>

<p>또한 GA4, Amplitude 등과 같은 B2B 데이터 분석 플랫폼 서비스를 만드는 경험도 살짝 했는데요. 그러다보니 저의 R&amp;R은 서비스 자체의 데이터 분석 업무 외에도, 고객들에게 데이터를 서빙하기 위한 데이터 마트 설계와 최적화 업무에 집중되기도 했습니다. 제 타이틀을 멋있게 가공하면 최근에 떠오르는 포지션인 Analytics Engineer, 반쪽 짜리 데이터 엔지니어, 아니면 대충 쿼리 머신 혹은 분지니어(?)인 것 같기도 합니다. 😅</p>

<p>아무튼 대고객 서빙을 위해 엄청나게 큰 사이즈의 소스 테이블로부터 최적화된 데이터 마트 설계 고민을 많이 하고 있는 만큼, Stickiness 지표 사례를 중심으로 SQL 성능에 대한 이야기를 들려드리겠습니다.</p>

<p>(SQL 전문가 분들이 많이 계시는 만큼, 제 글을 비판적으로 고찰해주시면 감사하겠습니다! 😄)</p>

<h1 id="2-rolling-mau-vs-30일-이동평균선">2. Rolling MAU vs. 30일 이동평균선</h1>

<p>Rolling MAU란 마치 30일 이동평균선 인디케이터 등과 유사하게, 각 시점마다 최근 30일 동안의 MAU를 측정하는 지표입니다. 아래 GA4의 리포트는 WAU와 MAU를 모두 Rolling 방식으로 집계하고 있는 대표적인 사례라고 할 수 있을 것 같아서 가져와봤어요!</p>

<p><img src="/assets/2023-11-19-static-vs-rolling-stickiness/user-activity-over-time.webp" alt="" /></p>
<blockquote>
  <p><a href="https://measureschool.com/ga4-active-users/">Source</a></p>
</blockquote>

<p>하지만, 30일 이동평균선 인디케이터와 Rolling MAU의 연산 방식에는 중대한 차이점이 있습니다.</p>

<p><img src="/assets/2023-11-19-static-vs-rolling-stickiness/trading-view.webp" alt="" /></p>
<blockquote>
  <p><a href="https://www.tradingwithrayner.com/20-30-day-moving-average/">Source</a></p>
</blockquote>

<p>먼저 30일 이동평균선을 SQL스럽게 작성해본다면, 단순히  <code class="language-plaintext highlighter-rouge">AVG Window Functions</code>를 통해 즉각적으로 연산할 수 있습니다. Window Functions는 이미 출력된  <code class="language-plaintext highlighter-rouge">price</code>  칼럼 자체를 통해 연산하므로,  <code class="language-plaintext highlighter-rouge">daily_prices</code>  테이블을 중복으로 불러오지 않아 연산량이 기하급수적으로 증가하지 않습니다.</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">WITH</span>
<span class="n">CTE_ma_30d</span> <span class="k">AS</span> <span class="p">(</span>
   <span class="k">SELECT</span>
      <span class="nb">date</span><span class="p">,</span>
      <span class="n">price</span><span class="p">,</span>
      <span class="k">AVG</span><span class="p">(</span><span class="n">price</span><span class="p">)</span> <span class="n">OVER</span> <span class="p">(</span>
         <span class="k">ORDER</span> <span class="k">BY</span> <span class="nb">date</span>
         <span class="k">ROWS</span> <span class="k">BETWEEN</span> <span class="mi">29</span> <span class="k">PRECEDING</span> <span class="k">AND</span> <span class="k">CURRENT</span> <span class="k">ROW</span>
      <span class="p">)</span> <span class="k">AS</span> <span class="n">ma_30d</span>
   <span class="k">FROM</span>
      <span class="n">daily_prices</span>
   <span class="k">ORDER</span> <span class="k">BY</span>
      <span class="mi">1</span>
<span class="p">)</span>
<span class="k">SELECT</span>
   <span class="o">*</span>
<span class="k">FROM</span>
   <span class="n">CTE_ma_30d</span>
<span class="p">;</span>
</code></pre></div></div>

<p>반면, Rolling MAU의 연산 방식은 중대한 문제점이 있습니다. 즉, Window Functions를 통해 연산하는 것이 어렵다는 점입니다. 아래 쿼리문을 살펴보면,  <code class="language-plaintext highlighter-rouge">SELECT Statement</code>  내 서브쿼리를 통해 Outer Table의 각  <code class="language-plaintext highlighter-rouge">date</code>마다 일일이 Inner Table의 가변적인 기간마다 모든  <code class="language-plaintext highlighter-rouge">user_id</code>  고유값 개수를  <code class="language-plaintext highlighter-rouge">COUNT</code>하게 됩니다. 즉,  <code class="language-plaintext highlighter-rouge">session_starts</code>  테이블 내의  <code class="language-plaintext highlighter-rouge">date</code>  고유값 개수가 365개라면, 각  <code class="language-plaintext highlighter-rouge">rolling_mau</code>  칼럼의 값을 계산하기 위해서는 동일한 테이블을 365번이나 메모리에 올려야 하는 것이죠.</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">WITH</span>
<span class="n">CTE_rolling_mau</span> <span class="k">AS</span> <span class="p">(</span>
   <span class="k">SELECT</span>
      <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span><span class="p">,</span>
      <span class="p">(</span>
         <span class="k">SELECT</span>
            <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="n">user_id</span><span class="p">)</span>
         <span class="k">FROM</span>
            <span class="n">session_starts</span> <span class="n">SUB</span>
         <span class="k">WHERE</span>
            <span class="n">DATE_ADD</span><span class="p">(</span><span class="s1">'DAY'</span><span class="p">,</span> <span class="o">-</span><span class="mi">29</span><span class="p">,</span> <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">SUB</span><span class="p">.</span><span class="nb">date</span>
            <span class="k">AND</span> <span class="n">SUB</span><span class="p">.</span><span class="nb">date</span> <span class="o">&lt;=</span> <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span>
      <span class="p">)</span> <span class="k">AS</span> <span class="n">rolling_mau</span>
   <span class="k">FROM</span>
      <span class="n">session_starts</span> <span class="n">MAIN</span>
   <span class="k">GROUP</span> <span class="k">BY</span>
      <span class="mi">1</span>
   <span class="k">ORDER</span> <span class="k">BY</span>
      <span class="mi">1</span>
<span class="p">)</span>
<span class="k">SELECT</span>
   <span class="o">*</span>
<span class="k">FROM</span>
   <span class="n">CTE_rolling_mau</span>
<span class="p">;</span>
</code></pre></div></div>

<p>결국, 30일 이동평균선과 달리 Rolling MAU의 경우 단순한 집계로 가능한 영역이 아니라,  <code class="language-plaintext highlighter-rouge">COUNT(DISTINCT user_id)</code>를 수행하기 위한 테이블 재탐색이 각 Row마다 중복 발생해야 하는 영역입니다. 따라서 이는 쿼리문의 성능과 비용 관리에 매우 부정적인 영향을 끼치게 됩니다.</p>

<h1 id="3-static-mau">3. Static MAU</h1>

<p>Static MAU는 제가 직접 마음대로 지어본 용어인데요. 😅 Rolling MAU에서 겪은 문제점에 대해 다음과 같은 방식으로 타협을 해봤습니다.</p>

<p><img src="/assets/2023-11-19-static-vs-rolling-stickiness/cat.webp" alt="" /></p>
<blockquote>
  <p><a href="https://www.reddit.com/r/ProgrammerHumor/comments/szxooa/the_difference_between_dynamic_vs_static_ip/?rdt=33714">Source</a></p>
</blockquote>

<p><strong>“어쩔 수 없네. 그럼, MAU는 Rolling 방식이 아닌 각 월 별로 Static하게 집계해보자!”</strong></p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">WITH</span>
<span class="n">CTE_static_mau</span> <span class="k">AS</span> <span class="p">(</span>
   <span class="k">SELECT</span>
      <span class="n">DATE_TRUNC</span><span class="p">(</span><span class="s1">'MONTH'</span><span class="p">,</span> <span class="nb">date</span><span class="p">)</span> <span class="k">AS</span> <span class="k">month</span><span class="p">,</span>
      <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="n">user_id</span><span class="p">)</span> <span class="k">AS</span> <span class="n">static_mau</span>
   <span class="k">FROM</span>
      <span class="n">session_starts</span>
   <span class="k">GROUP</span> <span class="k">BY</span>
      <span class="mi">1</span>
   <span class="k">ORDER</span> <span class="k">BY</span>
      <span class="mi">1</span>
<span class="p">)</span>
<span class="k">SELECT</span>
   <span class="o">*</span>
<span class="k">FROM</span>
   <span class="n">CTE_static_mau</span>
<span class="p">;</span>
</code></pre></div></div>

<p>Static MAU는 Rolling MAU에 비해 다음과 같은 장/단점이 존재할 것 같습니다.</p>
<ul>
  <li><strong>장점</strong>: 쿼리 비용이 크게 절감되고 연산 속도가 빨라집니다.</li>
  <li><strong>단점</strong>: 쿼리가 실행되는 시점 당월의 경우, 월말이 도래하기 전까지는 MAU가 과소평가되어 데이터 분석의 Freshness가 저하됩니다. 즉, 오늘이 1월 2일이라면 1월의 MAU는 1월 1일부터 1월 2일까지만 집계되겠죠.</li>
</ul>

<h1 id="4-stickiness-지표">4. Stickiness 지표</h1>

<p>한편, 흔히 <code class="language-plaintext highlighter-rouge">DAU➗MAU</code>로 표현되는 Stickiness(사용자 고착도)를 측정하는 경우에는 Static과 Rolling 방식 사이의 고민이 더욱 깊어지게 됩니다.</p>

<p>Stickiness 지표는 토스, Instagram, YouTube, TikTok, 블라인드 등 활성 사용자들이 습관적으로 앱에 방문함으로써 광고 노출 효과 등을 극대화해야 하는 서비스에서 매우 중요한 지표입니다. 나쁘게 말하면, 사용자의 중독도를 파악하기 위한 지표인 것이죠. 😂</p>

<p><img src="/assets/2023-11-19-static-vs-rolling-stickiness/facebook.webp" alt="" /></p>
<blockquote>
  <p><a href="https://velog.io/@datarian/retention4">Source</a></p>
</blockquote>

<h1 id="5-rolling-stickiness">5. Rolling Stickiness</h1>

<p>Stickiness도 마찬가지로, Rolling Stickiness와 Static Stickiness로 구분하여 연산할 수 있는데요. (Static Stickiness도 제가 마음대로 지어본 용어입니다.) 먼저 Rolling Stickiness 지표 산출을 위한 쿼리문은 다음과 같습니다.
(참고로, 분모가 0이 되는 케이스의 경우, 0으로 반환되도록  <code class="language-plaintext highlighter-rouge">COALSECE(TRY(…), 0)</code> 함수를 사용했습니다. 혼동이 없으시길 바랄게요! 🙃)</p>

<p>이 경우 Rolling MAU 연산 방식과 마찬가지로, Outer Table의 각  <code class="language-plaintext highlighter-rouge">date</code>마다 일일이 Inner Table의 모든  <code class="language-plaintext highlighter-rouge">user_id</code>  고유값 개수를  <code class="language-plaintext highlighter-rouge">COUNT</code>하게 됩니다. 즉, 메모리 사용량과 트래픽 수준이 급격하게 상승할 것입니다.</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">WITH</span>
<span class="n">CTE_rolling_stickiness</span> <span class="k">AS</span> <span class="p">(</span>
   <span class="k">SELECT</span>
      <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span><span class="p">,</span>
      <span class="n">COALESCE</span><span class="p">(</span>
         <span class="n">TRY</span><span class="p">(</span>
            <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="n">user_id</span><span class="p">)</span>
            <span class="o">/</span>
            <span class="p">(</span>
               <span class="k">SELECT</span>
                  <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="n">user_id</span><span class="p">)</span>
               <span class="k">FROM</span>
                  <span class="n">session_start</span> <span class="n">SUB</span>
               <span class="k">WHERE</span>
                  <span class="n">DATE_ADD</span><span class="p">(</span><span class="s1">'DAY'</span><span class="p">,</span> <span class="o">-</span><span class="mi">29</span><span class="p">,</span> <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">SUB</span><span class="p">.</span><span class="nb">date</span>
                  <span class="k">AND</span> <span class="n">SUB</span><span class="p">.</span><span class="nb">date</span> <span class="o">&lt;=</span> <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span>
            <span class="p">)</span>
         <span class="p">),</span>
         <span class="mi">0</span>
      <span class="p">)</span> <span class="k">AS</span> <span class="n">rolling_stickiness</span>
   <span class="k">FROM</span>
      <span class="n">session_starts</span> <span class="n">MAIN</span>
   <span class="k">GROUP</span> <span class="k">BY</span>
      <span class="mi">1</span>
   <span class="k">ORDER</span> <span class="k">BY</span>
      <span class="mi">1</span>
<span class="p">)</span>
<span class="k">SELECT</span>
   <span class="o">*</span>
<span class="k">FROM</span>
   <span class="n">CTE_rolling_stickiness</span>
<span class="p">;</span>
</code></pre></div></div>

<h1 id="6-static-stickiness">6. Static Stickiness</h1>

<p>그러나 Static Stickiness 방식으로 접근할 경우 쿼리문은 다음과 같습니다. DAU와 Static MAU를 Inline View로 먼저 계산한 후, 각 일자 별  <code class="language-plaintext highlighter-rouge">dau</code>를 고정된 월의  <code class="language-plaintext highlighter-rouge">mau</code>로 나누어주는 방식입니다. 이 경우, 쿼리 비용과 연산 속도를 크게 개선할 수 있게 됩니다.</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">WITH</span>
<span class="n">CTE_dau</span> <span class="k">AS</span> <span class="p">(</span>
   <span class="k">SELECT</span>
      <span class="nb">date</span><span class="p">,</span>
      <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="n">user_id</span><span class="p">)</span> <span class="k">AS</span> <span class="n">dau</span>
   <span class="k">FROM</span>
      <span class="n">session_starts</span>
   <span class="k">GROUP</span> <span class="k">BY</span>
      <span class="mi">1</span>
<span class="p">),</span>
<span class="n">CTE_static_mau</span> <span class="k">AS</span> <span class="p">(</span>
   <span class="k">SELECT</span>
      <span class="n">DATE_TRUNC</span><span class="p">(</span><span class="s1">'MONTH'</span><span class="p">,</span> <span class="nb">date</span><span class="p">)</span> <span class="k">AS</span> <span class="k">month</span><span class="p">,</span>
      <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="n">user_id</span><span class="p">)</span> <span class="k">AS</span> <span class="n">static_mau</span>
   <span class="k">FROM</span>
      <span class="n">session_starts</span>
   <span class="k">GROUP</span> <span class="k">BY</span>
      <span class="mi">1</span>
<span class="p">),</span>
<span class="n">CTE_static_stickiness</span> <span class="k">AS</span> <span class="p">(</span>
   <span class="k">SELECT</span>
      <span class="n">dau</span><span class="p">.</span><span class="nb">date</span><span class="p">,</span>
      <span class="n">COALESCE</span><span class="p">(</span>
         <span class="n">TRY</span><span class="p">(</span><span class="n">dau</span><span class="p">.</span><span class="n">dau</span> <span class="o">/</span> <span class="n">static_mau</span><span class="p">.</span><span class="n">static_mau</span><span class="p">),</span>
         <span class="mi">0</span>
      <span class="p">)</span> <span class="k">AS</span> <span class="n">static_stickiness</span>
   <span class="k">FROM</span>
      <span class="n">dau</span>
   <span class="k">LEFT</span> <span class="k">JOIN</span>
      <span class="n">static_mau</span>
      <span class="k">ON</span> <span class="n">DATE_TRUNC</span><span class="p">(</span><span class="s1">'MONTH'</span><span class="p">,</span> <span class="n">dau</span><span class="p">.</span><span class="nb">date</span><span class="p">)</span> <span class="o">=</span> <span class="n">static_mau</span><span class="p">.</span><span class="k">month</span>
   <span class="k">ORDER</span> <span class="k">BY</span>
      <span class="mi">1</span>
<span class="p">)</span>
<span class="k">SELECT</span>
   <span class="o">*</span>
<span class="k">FROM</span>
   <span class="n">CTE_static_stickiness</span>
<span class="p">;</span>
</code></pre></div></div>

<p>물론, Static Stickiness는 Rolling Stickiness에 비해 다음과 같은 장/단점이 존재합니다.</p>
<ul>
  <li><strong>장점</strong>: 쿼리 비용이 크게 절감되고 연산 속도가 빨라집니다.</li>
  <li><strong>단점</strong>: 당월의 경우, 월말이 도래하기 전까지는 MAU가 과소평가되어 Stickiness가 비정상적으로 높은 값으로 측정됩니다. 즉, 오늘이 1월 1일이라면,  <code class="language-plaintext highlighter-rouge">DAU=MAU</code>  이므로  <code class="language-plaintext highlighter-rouge">Stickiness=100%</code>인 말도 안되는 수치가 대시보드에 표시될 것입니다.😨</li>
</ul>

<p><code class="language-plaintext highlighter-rouge">Stickiness=100%</code>  로 표현되면, 사내 구성원들에게 잘못된 의사결정의 근거를 전달하게 될 위험성이 존재합니다. 따라서, Static Stickiness 방식을 사내에 도입하게 될 경우, 매월 초 자정에만 Appending되도록 하는 스케줄링을 두어야 할 것입니다. 즉, 1월 1일부터 1월 31일까지의 Stickiness 지표는 2월 1일이 되어야만 대시보드에 표현되는 것이죠. 그렇다면, Stickiness 지표는 최대 30일 이상 지연되어 서비스의 신속한 Action Item을 실행하기가 어려워질 것입니다. Stickiness는 Data Freshness가 중요한 지표 중 하나인데도 불구하고 말이죠.</p>

<h1 id="7-data-mart를-통해-rolling-mau-도입하기">7. Data Mart를 통해 Rolling MAU 도입하기</h1>

<p>그러면 대안이 없을까요? 없으면 제가 이 글을 안 썼겠죠.🤭 Data Mart 내에 Incremental Strategy를 적용한 <code class="language-plaintext highlighter-rouge">rolling_mau</code>  테이블 스케줄링을 구축한다면 앞서 언급한 Rolling Stickiness의 치명적인 단점을 개선할 수 있습니다. 가령, 다음과 같이 매일 자정에 Appending되는  <code class="language-plaintext highlighter-rouge">fact_rolling_mau</code>  테이블을 생성한다고 가정해보겠습니다.</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">WITH</span>
<span class="n">fact_rolling_mau</span> <span class="k">AS</span> <span class="p">(</span>
   <span class="k">SELECT</span>
      <span class="n">DATE_ADD</span><span class="p">(</span><span class="s1">'DAY'</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="k">CURRENT_DATE</span><span class="p">)</span> <span class="k">AS</span> <span class="nb">date</span><span class="p">,</span>
      <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="n">user_id</span><span class="p">)</span> <span class="k">AS</span> <span class="n">rolling_mau</span>
   <span class="k">FROM</span>
      <span class="n">session_starts</span>
   <span class="k">WHERE</span>
      <span class="n">DATE_ADD</span><span class="p">(</span><span class="s1">'DAY'</span><span class="p">,</span> <span class="o">-</span><span class="mi">30</span><span class="p">,</span> <span class="k">CURRENT_DATE</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="nb">date</span>
      <span class="k">AND</span> <span class="nb">date</span> <span class="o">&lt;=</span> <span class="n">DATE_ADD</span><span class="p">(</span><span class="s1">'DAY'</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="k">CURRENT_DATE</span><span class="p">)</span>
<span class="p">)</span>
<span class="k">SELECT</span>
   <span class="o">*</span>
<span class="k">FROM</span>
   <span class="n">fact_rolling_mau</span>
<span class="p">;</span>
</code></pre></div></div>

<p>즉 다음과 같이,  <code class="language-plaintext highlighter-rouge">fact_rolling_mau</code>  테이블은 중복 연산 문제를 벗어난 채 매일 새로운  <code class="language-plaintext highlighter-rouge">rolling_mau</code>  값을 업데이트하게 됩니다.</p>

<table>
  <thead>
    <tr>
      <th><strong>date</strong></th>
      <th><strong>rolling_mau</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>2023-01-01</td>
      <td>100,000</td>
    </tr>
    <tr>
      <td>2023-01-01</td>
      <td>101,000</td>
    </tr>
    <tr>
      <td>…</td>
      <td>…</td>
    </tr>
    <tr>
      <td>2023-01-01</td>
      <td>99,700</td>
    </tr>
    <tr>
      <td>2023-01-01</td>
      <td>110,000</td>
    </tr>
    <tr>
      <td>…</td>
      <td>…</td>
    </tr>
  </tbody>
</table>

<p>이제 이미 생성된  <code class="language-plaintext highlighter-rouge">fact_rolling_mau</code>  테이블을 통해 Rolling Stickiness를 계산하는 쿼리문을 작성하면 다음과 같습니다.</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">WITH</span>
<span class="n">CTE_dau</span> <span class="k">AS</span> <span class="p">(</span>
   <span class="k">SELECT</span>
      <span class="nb">date</span><span class="p">,</span>
      <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="n">user_id</span><span class="p">)</span> <span class="k">AS</span> <span class="n">dau</span>
   <span class="k">FROM</span>
      <span class="n">session_starts</span>
   <span class="k">GROUP</span> <span class="k">BY</span>
      <span class="mi">1</span>
<span class="p">),</span>
<span class="n">CTE_rolling_stickiness</span> <span class="k">AS</span> <span class="p">(</span>
   <span class="k">SELECT</span>
      <span class="n">dau</span><span class="p">.</span><span class="nb">date</span><span class="p">,</span>
      <span class="n">COALESCE</span><span class="p">(</span>
         <span class="n">TRY</span><span class="p">(</span><span class="n">dau</span><span class="p">.</span><span class="n">dau</span> <span class="o">/</span> <span class="n">fact_rolling_mau</span><span class="p">.</span><span class="n">rolling_mau</span><span class="p">),</span>
         <span class="mi">0</span>
      <span class="p">)</span> <span class="k">AS</span> <span class="n">rolling_stickiness</span>
   <span class="k">FROM</span>
      <span class="n">CTE_dau</span>
   <span class="k">LEFT</span> <span class="k">JOIN</span>
      <span class="n">fact_rolling_mau</span>
      <span class="k">ON</span> <span class="n">dau</span><span class="p">.</span><span class="nb">date</span> <span class="o">=</span> <span class="n">rolling_mau</span><span class="p">.</span><span class="nb">date</span>
   <span class="k">ORDER</span> <span class="k">BY</span>
      <span class="mi">1</span>
<span class="p">)</span>
<span class="k">SELECT</span>
   <span class="o">*</span>
<span class="k">FROM</span>
   <span class="n">CTE_rolling_stickiness</span>
<span class="p">;</span>
</code></pre></div></div>

<h1 id="8-결론-query-cost-vs-data-freshness">8. 결론: Query Cost vs Data Freshness</h1>

<p>결국 Rolling MAU, Rolling Stickiness 지표에 대한 이야기를 다루다보니 자연스럽게 Data Mart의 필요성으로 귀결되는 것 같습니다. Data Mart는 단순히 쿼리 결과의 정확성이나 일관성만을 위해 필요한 것이 아니라, 이처럼 Query Cost vs Data Freshness 사이의 상충 관계를 극복하기 위해서도 필요하다고 할 수 있습니다. 특히, 서비스의 사용 규모에 따라 소스 테이블의 사이즈가 방대해질수록 Data Mart의 활용은 필수적일 것입니다. 부족한 글을 읽어주셔서 감사합니다!</p>

<hr />

<h2 id="published-by-joshua-kim"><em>Published by</em> Joshua Kim</h2>
<p><img src="/assets/profile/joshua-profile.png" alt="Joshua Kim" /></p>]]></content><author><name></name></author><category term="Korean" /><category term="Data Analysis" /><category term="SQL" /><category term="Data Warehouse" /><summary type="html"><![CDATA[대고객 서빙을 위해 엄청나게 큰 사이즈의 소스 테이블로부터 최적화된 데이터 마트 설계 고민을 많이 하고 있는 만큼, Stickiness 지표 사례를 중심으로 SQL 성능에 대한 이야기를 들려드리겠습니다.]]></summary></entry><entry><title type="html">데이터 분석가의 파이썬 클라이언트 개발기 feat. pyinstaller</title><link href="http://localhost:4000/pyinstaller/" rel="alternate" type="text/html" title="데이터 분석가의 파이썬 클라이언트 개발기 feat. pyinstaller" /><published>2023-07-15T00:00:00+09:00</published><updated>2023-07-15T00:00:00+09:00</updated><id>http://localhost:4000/pyinstaller</id><content type="html" xml:base="http://localhost:4000/pyinstaller/"><![CDATA[<blockquote>
  <p>파이썬 파일을 실행하기 위해서는 파이썬의 High-level 언어를 Low-level로 변환해주는 <strong>Interpreter</strong>가 필요하고, 또 파이썬 파일 내에서 Load해야 하는 <strong>모듈</strong> 역시 함께 사전에 설치되어야 하는데요.  <code class="language-plaintext highlighter-rouge">pyinstaller</code>는 이러한 Interpreter와 모듈을 함께 동봉한 채로 파이썬 파일을 패키징하여 하나의 실행 파일로 만들어주는 역할을 하는 것이죠.</p>
</blockquote>

<h3 id="contents">CONTENTS</h3>
<ol>
  <li>데이터 분석가로 살아가며</li>
  <li>누워서 떡 먹듯 업무 자동화를 경험하실 수 있도록 하려면 어떻게 해야 할까요?</li>
  <li>파이썬 설치와 실행 방법을 모르더라도 <code class="language-plaintext highlighter-rouge">pyinstaller</code> 하나면 모든 것이 가능해요!</li>
  <li><code class="language-plaintext highlighter-rouge">.ipynb</code> 파일을 <code class="language-plaintext highlighter-rouge">.exe</code> 파일로 만드는 방법</li>
  <li>데이터 분석가가 갖추어야 하는 중요한 태도, “떠먹여 드리기”</li>
</ol>

<hr />

<h1 id="1-데이터-분석가로-살아가며">1. 데이터 분석가로 살아가며</h1>

<p><img src="/assets/2023-07-15-pyinstaller/milk.png" alt="" /></p>

<p>저는 블록체인 지갑 기업에서 데이터 분석가로 근무하고 있는 Joshua라고 합니다. 원래 이 업계에서 다른 포지션으로 근무하고 있었지만, 머신러닝과 빅데이터에 대한 천명(?)과 같은 깊은 흥미를 느끼게 되어 직장과 AI 대학원 생활을 2년 동안 병행해왔는데요. 정말 감사하게도 대학원을 잘 졸업하고, 지금 회사에서 데이터 분석가 포지션으로 근무하게 된지 1년이 넘어가고 있습니다.</p>

<p>훌륭하신, 그리고 인간적인 동료 분들과 함께 매일 치열하게 프로덕트에 대해 고민하고 있는데요. 특히, 한 분, 한 분과 이야기를 하거나 협업을 하다보면 제게 많은 자극을 알게 모르게 주시기도 하고, 스스로도 성장 욕구가 끊임 없이 일어나기도 한답니다. (입사 당시에도 그렇고, 1년이 지난 지금도 그 감정이 오롯이 유지되고 있어요.)</p>

<p><strong>머리로 기억하고 있는 선배 동료 분들의 어록 모음</strong></p>
<blockquote>
  <p>“조급한 마음으로 업무를 하게 되면 나중에 어떤 모습으로든 사고가 날 수 있다. 항상 차근차근 기초에 충실하는 게 중요해요.”
“3년 후, 5년 후의 미래를 종종 그려보며 커리어 방향을 점검해보는 게 되게 중요해요.”
“저는 나이가 들수록 말을 하거나 글을 쓰는 등 표현하는 게 부담스러워져요. 내가 알고 느끼는 것이 틀릴 수도 있으니까요.”</p>
</blockquote>

<p>이런 동료 분들과 함께, 그리고 성장 가능성이 무궁무진한 블록체인 도메인 속에서 매일 밤 이불을 덮으며 “<strong>나는 꼭 월드 클래스가 될 거야</strong>”라는 생각을 하며 지내고 있어요.</p>

<p>데이터 분석가의 메인 업무에 대한 이야기는 다음 아티클에서 또 전달해드리도록 하고, 오늘은 조금 희귀한(?) 스토리를 전달해드리고자 합니다.</p>

<p>가끔 몇몇 동료 분들이 제게 이런 말씀을 하실 때가 많아요.</p>
<blockquote>
  <p>“Joshua님은 데이터 분석가인데 왜 개발을 하고 계세요?”</p>
</blockquote>

<p>그럴 때마다 저는 이렇게 답변 드리곤 합니다.</p>
<blockquote>
  <p>“저.. 저는 단지 데이터 추출과 가공 때문에 코드를 짜고 있는 건데요? 개발 잘 몰라요^^;;;;;”</p>
</blockquote>

<p>물론 시간이 흐르며, 프론트엔드와 백엔드 개발도 데이터 크롤링과 가공의 프로세스도 지니고 있어서 상당히 유사한 작업이 많다는 사실을 이해하게 되어 지금은 살짝 인정을 하고 있어요. (그럼에도 불구하고 데이터 분석은 결이 좀 다르다구요!😆)</p>

<p>아무튼, 이번 아티클에서 제가 전달해드리려는 내용은 “<strong>데이터 분석가로서 반드시 알 필요는 없는, 그렇지만 알아두면 재미있고 쓸모 있는 클라이언트 개발 후기</strong>”입니다!</p>

<p>곰곰이 생각해보면, 현 회사에서 데이터 분석가로서 Day-to-day Responsibilities가 크게  <strong>메인 업무</strong>와  <strong>서브 업무</strong>  두 가지로 카테고리화되는 것 같아요.</p>

<p><strong>| 메인 업무</strong></p>
<ul>
  <li>핵심 지표 모니터링을 위한 대시보드 생성 및 관리</li>
  <li>Ad-hoc 데이터 분석</li>
  <li>A/B 테스트 결과 데이터 분석</li>
  <li>이벤트 로그 스키마 정의</li>
</ul>

<p><strong>| 서브 업무</strong></p>
<ul>
  <li>API 크롤링을 통한 시장 데이터 수집 후 분석</li>
  <li>블록체인 온체인 데이터 수집 후 분석</li>
  <li>블록체인 메인넷 리서치</li>
  <li>기타 등등</li>
</ul>

<p>특히  <strong>서브 업무</strong>는 데이터 분석가로서 Must-have 업무가 아닐 수 있지만, 저는 개인적으로 서브 업무를 함으로써 회사의 사업 전략과 프로덕트에 대한 Domain Knowledge를 키워갈 수 있는 매우 값진 경험이라고 생각하는데요.</p>

<p>최근에는 사내 재무팀 분들을 위해 내부용 파이썬 업무 자동화 클라이언트를 개발하여 배포하는 과정을 겪으며, 재무팀 동료 분들이 어떤 고민을 하시는지, 그리고 어떤 목표와 역할을 위해 최선을 다하고 계시는지 진득하게 이해할 수 있었어요.</p>

<h1 id="2-누워서-떡-먹듯-업무-자동화를-경험하실-수-있도록-하려면-어떻게-해야-할까요">2. 누워서 떡 먹듯 업무 자동화를 경험하실 수 있도록 하려면 어떻게 해야 할까요?</h1>

<p><img src="/assets/2023-07-15-pyinstaller/i-dont-know-why.png" alt="" /></p>

<p>회사 내부용 목적에 대해 공개할 수는 없지만, 재무팀 업무시 매뉴얼하게 데이터를 확인하는 것이 거의 불가능한 업무 포인트가 있었는데요. 그 부분을 API를 통해 크롤링할 수 있도록 파이썬 모듈을 만들 수 있겠다는 생각이 들었어요.</p>

<p>파이썬 크롤러 자체를 만드는 것은 어려운 일이 아니었지만, 파이썬 실행 환경에 대해 생각해보니 고민이 생겼어요.</p>
<blockquote>
  <p>“데이터 분석가와 백엔드 개발자에게는 파이썬 클라이언트를 설치하고, 노트북 상에서 코드를 실행하거나 명령 프롬프트 상에서 파이썬을 실행하는 게 너무나도 익숙한 일인데, 이게 과연 재무팀 분들께도 익숙한 일일까?”</p>
</blockquote>

<p>물론, 업무 자동화로 인한 시간 절감 효과가 파이썬 실행 환경 적응 시간보다 훨씬 크다면 큰 문제가 되지는 않겠지만, 그럼에도 불구하고  <code class="language-plaintext highlighter-rouge">CX(Colleague Experience?)</code>를 고려한 업무 자동화 환경을 제공해드리고 싶었거든요.</p>

<h1 id="3-파이썬-설치와-실행-방법을-모르더라도-pyinstaller-하나면-모든-것이-가능해요">3. 파이썬 설치와 실행 방법을 모르더라도 <code class="language-plaintext highlighter-rouge">pyinstaller</code> 하나면 모든 것이 가능해요!</h1>

<p>개발자 친구에게 이 고민을 털어놓기도 하고, 개인적으로 구글링을 하면서 알게 된 것은 바로  <strong>Python Executable File</strong>이라는 개념이었어요. 즉, 파이썬 환경을 구축하지 않고, 혹은 명령 프롬프트 같은 화성 같은 환경을 경험하지 않고도, <code class="language-plaintext highlighter-rouge">.exe</code> 확장자의 파일 자체를 클릭하는 것만으로 업무 자동화가 진행되는 실행 파일을 만드는 방법인 것이죠.</p>

<p><img src="/assets/2023-07-15-pyinstaller/infinite-challenge.jpeg" alt="" /></p>

<p>정말 감사하게도, 파이썬에는  <code class="language-plaintext highlighter-rouge">pyinstaller</code>라는 모듈이 있어요.</p>

<p><a href="https://pyinstaller.org/en/stable/">PyInstaller Manual</a>에 따르면,  <code class="language-plaintext highlighter-rouge">pyinstaller</code>는 Python 애플리케이션 및 실행에 필요한 모든 환경을 하나의 패키지로 묶어줌으로써, 사용자가 Python Interpreter나 모듈을 설치하지 않고 패키지 자체를 실행할 수 있도록 해주는 유틸리티입니다.</p>

<p>파이썬 파일을 실행하기 위해서는 파이썬의 High-level 언어를 Low-level로 변환해주는 <strong>Interpreter</strong>가 필요하고, 또 파이썬 파일 내에서 Load해야 하는 <strong>모듈</strong> 역시 함께 사전에 설치되어야 하는데요.  <code class="language-plaintext highlighter-rouge">pyinstaller</code>는 이러한 Interpreter와 모듈을 함께 동봉한 채로 파이썬 파일을 패키징하여 하나의 실행 파일로 만들어주는 역할을 하는 것이죠.</p>

<p><img src="https://miro.medium.com/v2/resize:fit:1400/0*uKgfsMJQvUG5okP2.jpg" alt="" /></p>

<h1 id="4-ipynb-파일을-exe-파일로-만드는-방법">4. <code class="language-plaintext highlighter-rouge">.ipynb</code> 파일을 <code class="language-plaintext highlighter-rouge">.exe</code> 파일로 만드는 방법</h1>

<p>우선 업무 자동화에 필요한 파이썬 코드를 Jupyter Notebook으로 완성을 합니다.</p>

<p><img src="/assets/2023-07-15-pyinstaller/step01.webp" alt="" /></p>

<p>사용자가 입력한 정수의 제곱값을 리턴해주는 귀여운 코드를 적어봤어요.</p>

<p><code class="language-plaintext highlighter-rouge">.ipynb</code>을 <code class="language-plaintext highlighter-rouge">.py</code> 형식의 파일로 변환하여 다운로드합니다.</p>

<p><img src="/assets/2023-07-15-pyinstaller/step02.webp" alt="" /></p>

<p>원하는 경로에 .py 파일을 이동해줍니다.</p>

<p><img src="/assets/2023-07-15-pyinstaller/step03.webp" alt="" /></p>

<p>이제  <code class="language-plaintext highlighter-rouge">pyinstaller</code>  모듈을 설치하기 위해 명령 프롬프트를 실행합니다. (Anaconda Powershell Prompt나 Anaconda Prompt가 아닌, Windows 자체의 Command Prompt를 의미해요.)</p>

<p><img src="/assets/2023-07-15-pyinstaller/step04.webp" alt="" /></p>

<p><code class="language-plaintext highlighter-rouge">pyinstaller</code>  모듈 설치를 위해  <code class="language-plaintext highlighter-rouge">pip install pyinstaller</code>  명령어를 입력해줍니다.</p>

<p><img src="/assets/2023-07-15-pyinstaller/step05.webp" alt="" /></p>

<p>이제 명령 환경을 <code class="language-plaintext highlighter-rouge">.py</code> 파일이 보관되어 있는 디렉토리로 변경해줍니다.</p>

<p><img src="/assets/2023-07-15-pyinstaller/step06.webp" alt="" /></p>

<p><code class="language-plaintext highlighter-rouge">pyinstaller --onefile joshua_pyinstaller_practice.py</code>  명령어를 통해 패키징을 시작합니다. (onefile은 하나의 파일로 패키징해줘야 함을 의미해요!)</p>

<p><img src="/assets/2023-07-15-pyinstaller/step07.webp" alt="" /></p>

<p>그런데 가끔(아니 매우 자주), 안타깝게도 프롬프트가  <code class="language-plaintext highlighter-rouge">pyinstaller</code>라는 명령어를 제대로 이해하지 못하는 경우가 발생해요. 이 경우, 대부분 시스템 환경 변수를 프롬프트가 모르기 때문에 발생합니다.</p>

<p>Windows Task Bar의 검색창에서 <code class="language-plaintext highlighter-rouge">Environment Variables</code>를 검색하여 시스템 환경 변수 관리 페이지를 실행합니다.</p>

<p><img src="/assets/2023-07-15-pyinstaller/step08.webp" alt="" /></p>

<p>Advanced 탭 내의 Environment Variables 버튼을 클릭합니다.</p>

<p><img src="/assets/2023-07-15-pyinstaller/step09.webp" alt="" /></p>

<p>User variables의 New를 클릭합니다.</p>

<p><img src="/assets/2023-07-15-pyinstaller/step10.webp" alt="" /></p>

<p>잠시 홀드하고, 파이썬이 설치되어 있는 경로를 확인해야 해요. 즉, 파이썬의 Scripts 폴더를 찾아야 하는데요. 보통  <code class="language-plaintext highlighter-rouge">Users\AppData\Local\Programs\Python\Python311</code>  경로에 Scripts 폴더가 있어요.</p>

<p><img src="/assets/2023-07-15-pyinstaller/step11.webp" alt="" /></p>

<p>경로를 PATH 이름으로 환경 변수 리스트에 추가해주세요.</p>

<p><img src="/assets/2023-07-15-pyinstaller/step12.webp" alt="" /></p>

<p><img src="/assets/2023-07-15-pyinstaller/step13.webp" alt="" /></p>

<p>이런 환경 설정이 너무 어렵다면, 사실  <a href="https://www.python.org/downloads/">Python3 Setup 파일</a>을 다시 다운로드하여 Modify하는 방법이 있어요. 그럼 자동으로 환경 변수 세팅을 완료해주거든요.</p>

<p><img src="/assets/2023-07-15-pyinstaller/step14.webp" alt="" /></p>

<p>Modify를 클릭하세요.</p>

<p>pip 체크 여부를 반드시 확인한 후 Next 버튼을 클릭합니다.</p>

<p><img src="/assets/2023-07-15-pyinstaller/step15.webp" alt="" /></p>

<p>pip을 꼭 체크해주세요.</p>

<p>Add Python to environment variables를 꼭 체크 후 Install을 진행해주세요.</p>

<p><img src="/assets/2023-07-15-pyinstaller/step16.webp" alt="" /></p>

<p>그런 후, Add Python to environment variables를 반드시 체크해주세요.</p>

<p>자 이제 다시,  <code class="language-plaintext highlighter-rouge">pyinstaller</code>  패키징을 시작합니다.</p>

<p><img src="/assets/2023-07-15-pyinstaller/step17.webp" alt="" /></p>

<p>드디어 성공했군요! 👏</p>

<p><img src="/assets/2023-07-15-pyinstaller/step18.webp" alt="" /></p>

<p><code class="language-plaintext highlighter-rouge">.py</code> 파일이 보관되어 있는 경로를 찾아가보면, 새로운 폴더와 파일들이 생성된 것을 확인할 수 있습니다. 이 중, 우리가 배포해야 할 실행 파일은 <code class="language-plaintext highlighter-rouge">dist</code> 폴더에 있으니, <code class="language-plaintext highlighter-rouge">dist</code> 폴더를 클릭합니다.</p>

<p><img src="/assets/2023-07-15-pyinstaller/step19.webp" alt="" /></p>

<p><code class="language-plaintext highlighter-rouge">.exe</code> 파일이 생성이 된 것을 확인할 수 있습니다. 한 번 실행해볼까요?</p>

<p><img src="/assets/2023-07-15-pyinstaller/step20.webp" alt="" /></p>

<p>잘 실행되네요!😃</p>

<p><img src="/assets/2023-07-15-pyinstaller/step21.webp" alt="" /></p>

<p><img src="/assets/2023-07-15-pyinstaller/congratulations.jpeg" alt="" /></p>

<p>이제 마치 클라이언트 형태로 <code class="language-plaintext highlighter-rouge">.exe</code> 파일만 배포하면, 파이썬 환경 설치에 대한 부담 없이도 누구나 편리하게 원클릭 업무 자동화를 누릴 수 있답니다!</p>

<h1 id="5--데이터-분석가가-갖추어야-하는-중요한-태도-떠먹여-드리기">5.  데이터 분석가가 갖추어야 하는 중요한 태도, “떠먹여 드리기”</h1>

<p><img src="/assets/2023-07-15-pyinstaller/feeding.png" alt="" /></p>

<p>제가 회사에서 동료 분들께 반 농담, 반 진담으로 말씀 드리는 슬로건이 있는데요. 바로 “<code class="language-plaintext highlighter-rouge">떠먹여 드릴게요</code>”라는 표현입니다.</p>

<p>데이터는 늘 어렵고, 핵심을 꿰뚫이는 더욱 어려운 것 같아요. 데이터 분석가에게도 늘 어려운 일인데, 다른 동료 분들께는 얼마나 더 어려울까요.</p>

<p><strong>데이터 드리븐 문화</strong>를 위해 함께 데이터를 F/UP해야 하는 동료 분들의 부담을 조금이라도 줄여드리는 Soft한 역량이 데이터 분석가에게 요구되기 때문에, 떠먹여 드리기 위한 노력을 지속적으로 실천하는 것이 정말 중요하다고 생각하는데요. 가만히 누워서 입만 벌리고 계셔도 떠먹여 드릴 수 있는, 그런 데이터 분석가가 되는 것이 제게는 Midterm 목표가 된 것 같습니다.</p>

<p>이런 의미에서 이번 파이썬 클라이언트 개발기는 단순한 개발기 이상으로, 데이터를 업무에 빠르게 반영하여 Pain Point를 손쉽게 해결해드리고자 노력해본 저의 “<code class="language-plaintext highlighter-rouge">떠먹여 드릴게요</code>” 프로젝트 중 하나였습니다.</p>

<p>떠먹여 드리기도 하고, 저 또한 귀중한 서브 지식들을 함양할 수 있었던 것 같아서 참 뿌듯하기도 했어요. 앞으로 또 어떤  <strong>서브 업무</strong>들이 저를 기다리고 있을까요? 먼 산을 보며 글을 마칩니다. 읽어주셔서 감사합니다.</p>

<hr />

<h2 id="published-by-joshua-kim"><em>Published by</em> Joshua Kim</h2>
<p><img src="/assets/profile/joshua-profile.png" alt="Joshua Kim" /></p>]]></content><author><name></name></author><category term="Korean" /><category term="Python" /><summary type="html"><![CDATA[파이썬 파일을 실행하기 위해서는 파이썬의 High-level 언어를 Low-level로 변환해주는 Interpreter가 필요하고, 또 파이썬 파일 내에서 Load해야 하는 모듈 역시 함께 사전에 설치되어야 하는데요. pyinstaller는 이러한 Interpreter와 모듈을 함께 동봉한 채로 파이썬 파일을 패키징하여 하나의 실행 파일로 만들어주는 역할을 하는 것이죠.]]></summary></entry></feed>