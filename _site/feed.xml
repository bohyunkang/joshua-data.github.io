<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2024-08-25T22:34:20+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Joshua Kim</title><subtitle>Analytics Engineer | Data Analyst</subtitle><entry><title type="html">NOT IN 대신 JOIN을 통한 쿼리 최적화</title><link href="http://localhost:4000/join-instead-of-not-in-ko/" rel="alternate" type="text/html" title="NOT IN 대신 JOIN을 통한 쿼리 최적화" /><published>2024-08-13T00:00:00+09:00</published><updated>2024-08-13T00:00:00+09:00</updated><id>http://localhost:4000/join-instead-of-not-in-ko</id><content type="html" xml:base="http://localhost:4000/join-instead-of-not-in-ko/"><![CDATA[<blockquote>
  <p>“이번 프로젝트에서는 엔터프라이즈 데이터 웨어하우스(EDW) 환경에서 발생한 쿼리 성능 문제를 해결하기 위해, <code class="language-plaintext highlighter-rouge">core_fct_events</code> 테이블의 Incremental 업데이트 전략을 최적화했습니다. 기존의 비효율적인 <code class="language-plaintext highlighter-rouge">NOT IN</code> 구문을 <code class="language-plaintext highlighter-rouge">LEFT JOIN</code>으로 대체하여 데이터 중복 검사를 최적화함으로써, 오케스트레이션 전체 소요 시간을 50분에서 2분으로 단축했습니다. 이로 인해 약 96%의 성능 개선을 이루었으며, 데이터 처리 효율성과 시스템 자원 활용도를 크게 향상시켜 서비스의 안정성과 확장성을 강화했습니다.”</p>
</blockquote>

<hr />

<h1 id="목차">목차</h1>
<ol>
  <li>STAR Summary</li>
  <li>Situation</li>
  <li>Tasks</li>
  <li>Actions</li>
  <li>Results</li>
</ol>

<hr />

<h1 id="1-star-summary">1. STAR Summary</h1>

<h3 id="situation">Situation</h3>
<ul>
  <li>엔터프라이즈 데이터 웨어하우스(EDW)에서 <strong>ELT 파이프라인의 오케스트레이션 작업이 예상보다 많은 시간을 소요</strong>하고 있었습니다. 특히, <code class="language-plaintext highlighter-rouge">core_fct_events</code> 테이블의 업데이트 과정에서 성능 문제가 발생하고 있었습니다.</li>
</ul>

<h3 id="tasks">Tasks</h3>
<ul>
  <li><code class="language-plaintext highlighter-rouge">core_fct_events</code> 테이블의 Incremental Strategy를 개선하여 오케스트레이션 작업의 <strong>전체 소요 시간을 줄이는 것</strong>을 목표로 삼았습니다. 이를 통해 증가하는 데이터 트래픽을 원활하게 처리하고, 서비스의 신뢰성을 높이려 했습니다.</li>
</ul>

<h3 id="actions">Actions</h3>
<ul>
  <li>쿼리 성능을 저하시키던 <strong><code class="language-plaintext highlighter-rouge">NOT IN</code> 구문을 <code class="language-plaintext highlighter-rouge">LEFT JOIN</code>으로 변경</strong>하여, 중복 데이터를 효과적으로 필터링하는 동시에 성능을 최적화했습니다.</li>
</ul>

<h3 id="results">Results</h3>
<ul>
  <li>쿼리 최적화를 통해 오케스트레이션 전체 소요 시간이 <strong>50분에서 2분으로 대폭 감소</strong>했습니다. 이는 약 <strong>96%의 성능 개선</strong>을 의미하며, 데이터 처리 효율성을 크게 향상시켰습니다.</li>
</ul>

<hr />

<h1 id="2-situation">2. Situation</h1>

<blockquote>
  <ul>
    <li>엔터프라이즈 데이터 웨어하우스(EDW)에서 <strong>ELT 파이프라인의 오케스트레이션 작업이 예상보다 많은 시간을 소요</strong>하고 있었습니다. 특히, <code class="language-plaintext highlighter-rouge">core_fct_events</code> 테이블의 업데이트 과정에서 성능 문제가 발생하고 있었습니다.</li>
  </ul>
</blockquote>

<p><img src="/assets/2024-08-13-join-instead-of-not-in/1.webp" alt="" /></p>

<h3 id="구체적인-상황">구체적인 상황</h3>
<ul>
  <li>회사에서 B2B BI 서비스를 제공하기 위해 엔터프라이즈 데이터 웨어하우스(EDW) 환경을 운영하고 있었습니다. 매일 자정 무렵, 사용자 이벤트 데이터를 기반으로 한 복잡한 데이터 변환(Transformation) 작업이 수행되고 있었습니다. <strong>그러나 이 과정에서 예상보다 시간이 오래 걸리는 문제</strong>가 발생했습니다. 특히, <strong><code class="language-plaintext highlighter-rouge">core_fct_events</code>라는 주요 이벤트 테이블의 Incremental 업데이트 과정</strong>이 전체 오케스트레이션 시간의 대부분을 차지하고 있었습니다. 이로 인해 데이터 갱신이 지연되고, 서비스 품질에 부정적인 영향을 줄 우려가 있었습니다.</li>
</ul>

<hr />

<h1 id="3-tasks">3. Tasks</h1>

<blockquote>
  <ul>
    <li><code class="language-plaintext highlighter-rouge">core_fct_events</code> 테이블의 Incremental Strategy를 개선하여 오케스트레이션 작업의 <strong>전체 소요 시간을 줄이는 것</strong>을 목표로 삼았습니다. 이를 통해 증가하는 데이터 트래픽을 원활하게 처리하고, 서비스의 신뢰성을 높이려 했습니다.</li>
  </ul>
</blockquote>

<h3 id="문제의-근본-원인">문제의 근본 원인</h3>
<ul>
  <li><code class="language-plaintext highlighter-rouge">core_fct_events</code> 테이블의 업데이트 과정에서 발생하는 세 가지 주요 문제를 확인했습니다.</li>
</ul>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="k">WITH</span>
    <span class="n">CTE_src_events</span> <span class="k">AS</span> <span class="p">(</span>
        <span class="k">SELECT</span>
            <span class="k">DISTINCT</span>
            <span class="nb">datetime</span><span class="p">,</span>
            <span class="n">app_id</span><span class="p">,</span>
            <span class="n">user_id</span><span class="p">,</span>
            <span class="n">event_name</span>
        <span class="k">FROM</span>
            <span class="n">src_events</span>
        <span class="c1">-- Incremental Strategy: Read rows with a datetime greater than the maximum datetime currently stored in the table.</span>
        <span class="p">{</span><span class="o">%</span> <span class="n">if</span> <span class="n">is_incremental</span><span class="p">()</span> <span class="o">%</span><span class="p">}</span>
        <span class="k">WHERE</span>
            <span class="p">(</span><span class="k">SELECT</span> <span class="k">MAX</span><span class="p">(</span><span class="nb">datetime</span><span class="p">)</span> <span class="k">FROM</span> <span class="p">{{</span> <span class="n">this</span> <span class="p">}})</span> <span class="o">&lt;</span> <span class="nb">datetime</span>
        <span class="p">{</span><span class="o">%</span> <span class="n">endif</span> <span class="o">%</span><span class="p">}</span>
    <span class="p">)</span>
    <span class="k">SELECT</span>
        <span class="o">*</span>
    <span class="k">FROM</span>
        <span class="n">CTE_src_events</span>
    <span class="c1">-- Incremental Strategy: Exclude data that already exists in the table. Do not insert those rows.</span>
    <span class="p">{</span><span class="o">%</span> <span class="n">if</span> <span class="n">is_incremental</span><span class="p">()</span> <span class="o">%</span><span class="p">}</span>
    <span class="k">WHERE</span>
        <span class="p">(</span><span class="nb">datetime</span><span class="p">,</span> <span class="n">app_id</span><span class="p">,</span> <span class="n">user_id</span><span class="p">,</span> <span class="n">event_name</span><span class="p">)</span> <span class="k">NOT</span> <span class="k">IN</span> <span class="p">(</span><span class="k">SELECT</span> <span class="nb">datetime</span><span class="p">,</span> <span class="n">app_id</span><span class="p">,</span> <span class="n">user_id</span><span class="p">,</span> <span class="n">event_name</span> <span class="k">FROM</span> <span class="p">{{</span> <span class="n">this</span> <span class="p">}})</span>
    <span class="p">{</span><span class="o">%</span> <span class="n">endif</span> <span class="o">%</span><span class="p">}</span>
</code></pre></div></div>

<h5 id="1-데이터의-대용량성">1. 데이터의 대용량성</h5>
<ul>
  <li><code class="language-plaintext highlighter-rouge">core_fct_events</code> 테이블은 모든 사용자 이벤트 로그 데이터를 포함하고 있어 테이블 크기가 매우 컸습니다.</li>
</ul>

<h5 id="2-중복-데이터의-존재">2. 중복 데이터의 존재</h5>
<ul>
  <li>소스 테이블 자체에 중복 데이터가 존재하므로 <code class="language-plaintext highlighter-rouge">DISTINCT</code> 키워드를 사용해 중복 제거를 해야 했습니다.</li>
</ul>

<h5 id="3-비효율적인-중복-검사-방법">3. 비효율적인 중복 검사 방법</h5>
<ul>
  <li>기존 쿼리에서 <code class="language-plaintext highlighter-rouge">NOT IN</code> 구문을 사용하여 새로운 데이터와 기존 데이터를 비교하는 작업이 성능 병목의 주된 원인이었습니다. 이 구문은 Nested Loop 검색을 유발하여 테이블이 커질수록 성능이 저하될 수밖에 없었습니다.</li>
</ul>

<hr />

<h1 id="4-actions">4. Actions</h1>

<blockquote>
  <ul>
    <li>쿼리 성능을 저하시키던 <strong><code class="language-plaintext highlighter-rouge">NOT IN</code> 구문을 <code class="language-plaintext highlighter-rouge">LEFT JOIN</code>으로 변경</strong>하여, 중복 데이터를 효과적으로 필터링하는 동시에 성능을 최적화했습니다.</li>
  </ul>
</blockquote>

<h3 id="구체적인-조치-사항">구체적인 조치 사항</h3>

<h5 id="1-문제-분석-및-대안-탐색">1. 문제 분석 및 대안 탐색</h5>
<ul>
  <li>먼저 기존의 <code class="language-plaintext highlighter-rouge">NOT IN</code> 구문이 성능 병목을 일으키는 주요 원인임을 확인했습니다. <code class="language-plaintext highlighter-rouge">NOT IN</code> 구문은 데이터베이스 엔진이 <strong>Nested Loop</strong>를 통해 모든 가능한 조합을 확인해야 하므로, 매우 비효율적입니다.</li>
</ul>

<p><img src="/assets/2024-08-13-join-instead-of-not-in/2.webp" alt="" /></p>

<h5 id="2-쿼리-리팩토링">2. 쿼리 리팩토링</h5>
<ul>
  <li>기존 <code class="language-plaintext highlighter-rouge">NOT IN</code> 구문을 <code class="language-plaintext highlighter-rouge">LEFT JOIN</code>으로 변경했습니다. <code class="language-plaintext highlighter-rouge">LEFT JOIN</code>을 사용하면 기존 테이블과 새 데이터 간의 비교를 보다 효율적으로 수행할 수 있습니다. 구체적으로, <strong><code class="language-plaintext highlighter-rouge">LEFT JOIN</code> 후 <code class="language-plaintext highlighter-rouge">NULL</code> 값을 필터링하여 기존 데이터에 없는 새로운 데이터만 삽입</strong>하도록 했습니다.</li>
</ul>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="k">SELECT</span>
        <span class="n">MAIN</span><span class="p">.</span><span class="o">*</span>
    <span class="k">FROM</span> 
        <span class="n">CTE_src_events</span> <span class="n">MAIN</span>
    <span class="c1">-- Incremental Strategy: Exclude data that already exists in the table. Do not insert those rows.</span>
    <span class="p">{</span><span class="o">%</span> <span class="n">if</span> <span class="n">is_incremental</span><span class="p">()</span> <span class="o">%</span><span class="p">}</span>
    <span class="k">LEFT</span> <span class="k">JOIN</span>
        <span class="p">{{</span> <span class="n">this</span> <span class="p">}}</span> <span class="n">THIS</span>
        <span class="k">ON</span> <span class="n">MAIN</span><span class="p">.</span><span class="nb">datetime</span> <span class="o">=</span> <span class="n">THIS</span><span class="p">.</span><span class="nb">datetime</span>
        <span class="k">AND</span> <span class="n">MAIN</span><span class="p">.</span><span class="n">app_id</span> <span class="o">=</span> <span class="n">THIS</span><span class="p">.</span><span class="n">app_id</span>
        <span class="k">AND</span> <span class="n">MAIN</span><span class="p">.</span><span class="n">user_id</span> <span class="o">=</span> <span class="n">THIS</span><span class="p">.</span><span class="n">user_id</span>
        <span class="k">AND</span> <span class="n">MAIN</span><span class="p">.</span><span class="n">event_name</span> <span class="o">=</span> <span class="n">THIS</span><span class="p">.</span><span class="n">event_name</span>
    <span class="k">WHERE</span>
        <span class="n">THIS</span><span class="p">.</span><span class="nb">datetime</span> <span class="k">IS</span> <span class="k">NULL</span>    
    <span class="p">{</span><span class="o">%</span> <span class="n">endif</span> <span class="o">%</span><span class="p">}</span>
</code></pre></div></div>

<h5 id="3-성능-테스트-및-검증">3. 성능 테스트 및 검증</h5>
<ul>
  <li>쿼리 변경 후, 다양한 데이터 세트를 사용하여 성능 테스트를 진행했습니다. 이를 통해 쿼리 실행 시간이 크게 단축되었음을 확인하였습니다. <strong>최적화된 쿼리 실행 시간은 기존의 50분에서 약 2분으로 줄어들었습니다.</strong></li>
</ul>

<hr />

<h1 id="5-results">5. Results</h1>

<blockquote>
  <ul>
    <li>쿼리 최적화를 통해 오케스트레이션 전체 소요 시간이 <strong>50분에서 2분으로 대폭 감소</strong>했습니다. 이는 약 <strong>96%의 성능 개선</strong>을 의미하며, 데이터 처리 효율성을 크게 향상시켰습니다.</li>
  </ul>
</blockquote>

<p><img src="/assets/2024-08-13-join-instead-of-not-in/3.webp" alt="" /></p>

<h3 id="1-성능-개선">1. 성능 개선</h3>
<ul>
  <li>오케스트레이션 전체 소요 시간이 <strong>50분에서 2분으로</strong> 대폭 감소했습니다. 이는 약 <strong>96%의 성능 개선</strong>으로, 데이터 처리 속도를 획기적으로 향상시켰습니다.</li>
</ul>

<h3 id="2-리소스-효율성-향상">2. 리소스 효율성 향상</h3>
<ul>
  <li>데이터베이스 자원의 효율적인 사용을 통해 시스템 부하가 감소하였으며, 이로 인해 다른 쿼리 및 작업도 더욱 원활하게 실행될 수 있었습니다.</li>
</ul>

<h3 id="3-서비스-신뢰성-강화">3. 서비스 신뢰성 강화</h3>
<ul>
  <li>데이터 갱신이 빠르고 안정적으로 이루어짐으로써 사용자에게 보다 신뢰성 있는 서비스를 제공할 수 있었습니다.</li>
</ul>

<h3 id="4-미래-확장성-확보">4. 미래 확장성 확보</h3>
<ul>
  <li>트래픽 증가와 데이터 확장에 대비한 최적화 작업을 통해, 향후 데이터 처리 요구 사항을 보다 쉽게 충족할 수 있는 기반을 마련했습니다.</li>
</ul>

<h3 id="결론">결론</h3>
<ul>
  <li>이번 쿼리 최적화 프로젝트는 데이터 웨어하우스의 성능을 크게 향상시키는 동시에, 애널리틱스 엔지니어링 역량을 한층 강화하는 계기가 되었습니다. 데이터 처리 효율성을 극대화하고, BI 서비스의 품질을 높이는 데 중요한 기여를 했습니다.</li>
</ul>

<hr />

<h2 id="published-by-joshua-kim"><em>Published by</em> Joshua Kim</h2>
<p><img src="/assets/profile/joshua-profile.png" alt="Joshua Kim" /></p>]]></content><author><name></name></author><category term="Korean" /><category term="PostgreSQL" /><summary type="html"><![CDATA[“이번 프로젝트에서는 엔터프라이즈 데이터 웨어하우스(EDW) 환경에서 발생한 쿼리 성능 문제를 해결하기 위해, core_fct_events 테이블의 Incremental 업데이트 전략을 최적화했습니다. 기존의 비효율적인 NOT IN 구문을 LEFT JOIN으로 대체하여 데이터 중복 검사를 최적화함으로써, 오케스트레이션 전체 소요 시간을 50분에서 2분으로 단축했습니다. 이로 인해 약 96%의 성능 개선을 이루었으며, 데이터 처리 효율성과 시스템 자원 활용도를 크게 향상시켜 서비스의 안정성과 확장성을 강화했습니다.”]]></summary></entry><entry><title type="html">Query Optimization by Using JOIN Instead of NOT IN</title><link href="http://localhost:4000/join-instead-of-not-in-en/" rel="alternate" type="text/html" title="Query Optimization by Using JOIN Instead of NOT IN" /><published>2024-08-13T00:00:00+09:00</published><updated>2024-08-13T00:00:00+09:00</updated><id>http://localhost:4000/join-instead-of-not-in-en</id><content type="html" xml:base="http://localhost:4000/join-instead-of-not-in-en/"><![CDATA[<blockquote>
  <p>“In this project, I optimized the incremental update strategy for the <code class="language-plaintext highlighter-rouge">core_fct_events</code> table to address query performance issues in our Enterprise Data Warehouse (EDW) environment. By replacing the inefficient <code class="language-plaintext highlighter-rouge">NOT IN</code> clause with a <code class="language-plaintext highlighter-rouge">LEFT JOIN</code>, I streamlined the duplicate data check process, reducing the overall orchestration time from 50 minutes to 2 minutes. This resulted in approximately a 96% performance improvement, significantly enhancing data processing efficiency and system resource utilization, thereby strengthening service stability and scalability.”</p>
</blockquote>

<hr />

<h1 id="table-of-contents">Table of Contents</h1>
<ol>
  <li>STAR Summary</li>
  <li>Situation</li>
  <li>Tasks</li>
  <li>Actions</li>
  <li>Results</li>
</ol>

<hr />

<h1 id="1-star-summary">1. STAR Summary</h1>

<h3 id="situation">Situation</h3>
<ul>
  <li>In our Enterprise Data Warehouse (EDW), <strong>the orchestration process of the ELT pipeline was taking significantly longer than expected.</strong> Specifically, there were performance issues during the update process of the <code class="language-plaintext highlighter-rouge">core_fct_events</code> table.</li>
</ul>

<h3 id="tasks">Tasks</h3>
<ul>
  <li>The goal was to optimize the incremental strategy of the <code class="language-plaintext highlighter-rouge">core_fct_events</code> table to <strong>reduce the overall orchestration time</strong>. This would enable us to handle increasing data traffic more efficiently and enhance service reliability.</li>
</ul>

<h3 id="actions">Actions</h3>
<ul>
  <li>I <strong>replaced the <code class="language-plaintext highlighter-rouge">NOT IN</code> clause with a <code class="language-plaintext highlighter-rouge">LEFT JOIN</code></strong> to effectively filter duplicate data while optimizing performance.</li>
</ul>

<h3 id="results">Results</h3>
<ul>
  <li>Through query optimization, the total orchestration time was <strong>reduced from 50 minutes to 2 minutes</strong>, achieving approximately <strong>96% performance improvement</strong> and significantly enhancing data processing efficiency.</li>
</ul>

<hr />

<h1 id="2-situation">2. Situation</h1>

<blockquote>
  <ul>
    <li>In our Enterprise Data Warehouse (EDW), <strong>the orchestration process of the ELT pipeline was taking significantly longer than expected.</strong> Specifically, there were performance issues during the update process of the <code class="language-plaintext highlighter-rouge">core_fct_events</code> table.</li>
  </ul>
</blockquote>

<p><img src="/assets/2024-08-13-join-instead-of-not-in/1.webp" alt="" /></p>

<h3 id="specific-situation">Specific Situation</h3>
<ul>
  <li>Our company operates an Enterprise Data Warehouse (EDW) environment to provide B2B BI services. Every midnight, a complex data transformation process based on user event data is performed. <strong>However, this process was taking longer than expected.</strong> In particular, <strong>the incremental update process of the <code class="language-plaintext highlighter-rouge">core_fct_events</code> table, a key event table</strong>, was taking up most of the orchestration time. This delay in data refresh posed a risk of negatively impacting service quality.</li>
</ul>

<hr />

<h1 id="3-tasks">3. Tasks</h1>

<blockquote>
  <ul>
    <li>The goal was to optimize the incremental strategy of the <code class="language-plaintext highlighter-rouge">core_fct_events</code> table to <strong>reduce the overall orchestration time</strong>. This would enable us to handle increasing data traffic more efficiently and enhance service reliability.</li>
  </ul>
</blockquote>

<h3 id="root-causes-of-the-problem">Root Causes of the Problem</h3>
<ul>
  <li>I identified three major issues in the update process of the <code class="language-plaintext highlighter-rouge">core_fct_events</code> table.</li>
</ul>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="k">WITH</span>
    <span class="n">CTE_src_events</span> <span class="k">AS</span> <span class="p">(</span>
        <span class="k">SELECT</span>
            <span class="k">DISTINCT</span>
            <span class="nb">datetime</span><span class="p">,</span>
            <span class="n">app_id</span><span class="p">,</span>
            <span class="n">user_id</span><span class="p">,</span>
            <span class="n">event_name</span>
        <span class="k">FROM</span>
            <span class="n">src_events</span>
        <span class="c1">-- Incremental Strategy: Read rows with a datetime greater than the maximum datetime currently stored in the table.</span>
        <span class="p">{</span><span class="o">%</span> <span class="n">if</span> <span class="n">is_incremental</span><span class="p">()</span> <span class="o">%</span><span class="p">}</span>
        <span class="k">WHERE</span>
            <span class="p">(</span><span class="k">SELECT</span> <span class="k">MAX</span><span class="p">(</span><span class="nb">datetime</span><span class="p">)</span> <span class="k">FROM</span> <span class="p">{{</span> <span class="n">this</span> <span class="p">}})</span> <span class="o">&lt;</span> <span class="nb">datetime</span>
        <span class="p">{</span><span class="o">%</span> <span class="n">endif</span> <span class="o">%</span><span class="p">}</span>
    <span class="p">)</span>
    <span class="k">SELECT</span>
        <span class="o">*</span>
    <span class="k">FROM</span>
        <span class="n">CTE_src_events</span>
    <span class="c1">-- Incremental Strategy: Exclude data that already exists in the table. Do not insert those rows.</span>
    <span class="p">{</span><span class="o">%</span> <span class="n">if</span> <span class="n">is_incremental</span><span class="p">()</span> <span class="o">%</span><span class="p">}</span>
    <span class="k">WHERE</span>
        <span class="p">(</span><span class="nb">datetime</span><span class="p">,</span> <span class="n">app_id</span><span class="p">,</span> <span class="n">user_id</span><span class="p">,</span> <span class="n">event_name</span><span class="p">)</span> <span class="k">NOT</span> <span class="k">IN</span> <span class="p">(</span><span class="k">SELECT</span> <span class="nb">datetime</span><span class="p">,</span> <span class="n">app_id</span><span class="p">,</span> <span class="n">user_id</span><span class="p">,</span> <span class="n">event_name</span> <span class="k">FROM</span> <span class="p">{{</span> <span class="n">this</span> <span class="p">}})</span>
    <span class="p">{</span><span class="o">%</span> <span class="n">endif</span> <span class="o">%</span><span class="p">}</span>
</code></pre></div></div>

<h5 id="1-large-data-volume">1. Large Data Volume</h5>
<ul>
  <li>The <code class="language-plaintext highlighter-rouge">core_fct_events</code> table contained all user event log data, making the table size very large.</li>
</ul>

<h5 id="2-presence-of-duplicate-rows">2. Presence of Duplicate Rows</h5>
<ul>
  <li>Due to the existence of duplicate data in the source table itself, the <code class="language-plaintext highlighter-rouge">DISTINCT</code> keyword had to be used to remove duplicates.</li>
</ul>

<h5 id="3-inefficient-duplicate-check-method">3. Inefficient Duplicate Check Method</h5>
<ul>
  <li>The existing query used the <code class="language-plaintext highlighter-rouge">NOT IN</code> clause to compare new data with existing data, which was the main cause of the performance bottleneck. This clause triggers nested loop searches, causing performance degradation as the table size increases.</li>
</ul>

<hr />

<h1 id="4-actions">4. Actions</h1>

<blockquote>
  <ul>
    <li><strong>I replaced the <code class="language-plaintext highlighter-rouge">NOT IN</code> clause with a <code class="language-plaintext highlighter-rouge">LEFT JOIN</code></strong> to effectively filter duplicate data while optimizing performance.</li>
  </ul>
</blockquote>

<h3 id="specific-actions-taken">Specific Actions Taken</h3>

<h5 id="1-problem-analysis-and-alternative-exploration">1. Problem Analysis and Alternative Exploration</h5>
<ul>
  <li>First, I identified that the <code class="language-plaintext highlighter-rouge">NOT IN</code> clause was the primary cause of the performance bottleneck. The <code class="language-plaintext highlighter-rouge">NOT IN</code> clause requires the database engine to check all possible combinations through <strong>nested loops</strong>, making it highly inefficient.</li>
</ul>

<p><img src="/assets/2024-08-13-join-instead-of-not-in/2.webp" alt="" /></p>

<h5 id="2-query-refactoring">2. Query Refactoring</h5>
<ul>
  <li>I replaced the existing <code class="language-plaintext highlighter-rouge">NOT IN</code> clause with a <code class="language-plaintext highlighter-rouge">LEFT JOIN</code>. Using a <code class="language-plaintext highlighter-rouge">LEFT JOIN</code> allows for more efficient comparison between the existing table and the new data. Specifically, <strong>after performing the <code class="language-plaintext highlighter-rouge">LEFT JOIN</code>, only new data that does not exist in the existing data is inserted by filtering for <code class="language-plaintext highlighter-rouge">NULL</code> values.</strong></li>
</ul>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="k">SELECT</span>
        <span class="n">MAIN</span><span class="p">.</span><span class="o">*</span>
    <span class="k">FROM</span> 
        <span class="n">CTE_src_events</span> <span class="n">MAIN</span>
    <span class="c1">-- Incremental Strategy: Exclude data that already exists in the table. Do not insert those rows.</span>
    <span class="p">{</span><span class="o">%</span> <span class="n">if</span> <span class="n">is_incremental</span><span class="p">()</span> <span class="o">%</span><span class="p">}</span>
    <span class="k">LEFT</span> <span class="k">JOIN</span>
        <span class="p">{{</span> <span class="n">this</span> <span class="p">}}</span> <span class="n">THIS</span>
        <span class="k">ON</span> <span class="n">MAIN</span><span class="p">.</span><span class="nb">datetime</span> <span class="o">=</span> <span class="n">THIS</span><span class="p">.</span><span class="nb">datetime</span>
        <span class="k">AND</span> <span class="n">MAIN</span><span class="p">.</span><span class="n">app_id</span> <span class="o">=</span> <span class="n">THIS</span><span class="p">.</span><span class="n">app_id</span>
        <span class="k">AND</span> <span class="n">MAIN</span><span class="p">.</span><span class="n">user_id</span> <span class="o">=</span> <span class="n">THIS</span><span class="p">.</span><span class="n">user_id</span>
        <span class="k">AND</span> <span class="n">MAIN</span><span class="p">.</span><span class="n">event_name</span> <span class="o">=</span> <span class="n">THIS</span><span class="p">.</span><span class="n">event_name</span>
    <span class="k">WHERE</span>
        <span class="n">THIS</span><span class="p">.</span><span class="nb">datetime</span> <span class="k">IS</span> <span class="k">NULL</span>    
    <span class="p">{</span><span class="o">%</span> <span class="n">endif</span> <span class="o">%</span><span class="p">}</span>
</code></pre></div></div>

<h5 id="3-performance-testing-and-validation">3. Performance Testing and Validation</h5>
<ul>
  <li>After modifying the query, I conducted performance tests using various data sets. This confirmed that the query execution time was significantly reduced. <strong>The optimized query execution time was reduced from 50 minutes to approximately 2 minutes.</strong></li>
</ul>

<hr />

<h1 id="5-results">5. Results</h1>

<blockquote>
  <ul>
    <li>Through query optimization, the total orchestration time was <strong>reduced from 50 minutes to 2 minutes</strong>, achieving approximately <strong>96% performance improvement</strong> and significantly enhancing data processing efficiency.</li>
  </ul>
</blockquote>

<p><img src="/assets/2024-08-13-join-instead-of-not-in/3.webp" alt="" /></p>

<h3 id="1-performance-improvement">1. Performance Improvement</h3>
<ul>
  <li>The total orchestration time was reduced <strong>from 50 minutes to 2 minutes</strong>, representing approximately <strong>96% performance improvement</strong>, drastically enhancing data processing speed.</li>
</ul>

<h3 id="2-improved-resource-efficiency">2. Improved Resource Efficiency</h3>
<ul>
  <li>Efficient use of database resources reduced system load, allowing other queries and tasks to execute more smoothly.</li>
</ul>

<h3 id="3-enhanced-service-reliability">3. Enhanced Service Reliability</h3>
<ul>
  <li>Faster and more reliable data updates provided a more dependable service to users.</li>
</ul>

<h3 id="4-future-scalability-secured">4. Future Scalability Secured</h3>
<ul>
  <li>The optimization efforts in preparation for increased traffic and data expansion have laid a foundation for easily meeting future data processing requirements.</li>
</ul>

<h3 id="conclusion">Conclusion</h3>
<ul>
  <li>This query optimization project significantly enhanced the performance of our data warehouse while also strengthening our analytics engineering capabilities. It was a valuable contribution to maximizing data processing efficiency and improving the quality of our BI services.</li>
</ul>

<hr />

<h2 id="published-by-joshua-kim"><em>Published by</em> Joshua Kim</h2>
<p><img src="/assets/profile/joshua-profile.png" alt="Joshua Kim" /></p>]]></content><author><name></name></author><category term="English" /><category term="PostgreSQL" /><summary type="html"><![CDATA[“In this project, I optimized the incremental update strategy for the core_fct_events table to address query performance issues in our Enterprise Data Warehouse (EDW) environment. By replacing the inefficient NOT IN clause with a LEFT JOIN, I streamlined the duplicate data check process, reducing the overall orchestration time from 50 minutes to 2 minutes. This resulted in approximately a 96% performance improvement, significantly enhancing data processing efficiency and system resource utilization, thereby strengthening service stability and scalability.”]]></summary></entry><entry><title type="html">Data-driven VOC Analysis and Automated Dashboard Development: Reducing Cost and Maximizing Efficiency</title><link href="http://localhost:4000/voc-dashboard-en/" rel="alternate" type="text/html" title="Data-driven VOC Analysis and Automated Dashboard Development: Reducing Cost and Maximizing Efficiency" /><published>2024-07-20T00:00:00+09:00</published><updated>2024-07-20T00:00:00+09:00</updated><id>http://localhost:4000/voc-dashboard-en</id><content type="html" xml:base="http://localhost:4000/voc-dashboard-en/"><![CDATA[<blockquote>
  <p>“I learned that internal team members were facing difficulties in following up on Zendesk customer inquiries, so I developed a Redash VOC dashboard to address this issue. The system automatically collected and preprocessed Zendesk data, then used the OpenAI API to categorize and summarize customer inquiries by topic. Additionally, a Slack notification was set up to alert the team each Monday about the topics with the highest increase in inquiries, helping identify and respond to customer issues more efficiently. As a result, we were able to eliminate about $275 in opportunity costs each month and reduce the time spent by team members on VOC follow-ups.”</p>
</blockquote>

<hr />

<h1 id="table-of-contents">Table of Contents</h1>
<ol>
  <li>STAR Summary</li>
  <li>Situation</li>
  <li>Tasks</li>
  <li>Actions</li>
  <li>Results</li>
</ol>

<hr />

<h1 id="1-star-summary">1. STAR Summary</h1>

<h3 id="situation">Situation</h3>
<ul>
  <li>Internal team members were struggling to efficiently track and follow up on Zendesk customer inquiries. Reading through all the inquiries required <strong>an excessive amount of time and effort</strong>, and implementing an external VOC analysis service posed <strong>a cost burden</strong>.</li>
</ul>

<h3 id="tasks">Tasks</h3>
<ol>
  <li>I decided to <strong>categorize and summarize</strong> customer inquiries and create a Redash VOC <strong>dashboard</strong>.</li>
  <li>I also decided to build <strong>a Slack notification bot</strong> to alert the team about the most urgent customer inquiry topics.</li>
</ol>

<h3 id="actions">Actions</h3>
<ol>
  <li>
    <p><strong>Data Pipeline</strong></p>

    <p>1.1. Data Collection and Preprocessing <code class="language-plaintext highlighter-rouge">(Zendesk Tickets → Google Sheets → BigQuery)</code></p>

    <p>1.2. Topic Categorization <code class="language-plaintext highlighter-rouge">(OpenAI API)</code></p>

    <p>1.3. Summarization <code class="language-plaintext highlighter-rouge">(OpenAI API)</code></p>
  </li>
  <li>
    <p><strong>Dashboard and Notification Bot</strong></p>

    <p>2.1. Creating the Dashboard <code class="language-plaintext highlighter-rouge">(BigQuery → Redash)</code></p>

    <p>2.2. Building the Notification Bot <code class="language-plaintext highlighter-rouge">(BigQuery → Slack API)</code></p>
  </li>
</ol>

<h3 id="results">Results</h3>
<ol>
  <li><strong>Cost Savings</strong>
    <ul>
      <li>We solved the problem internally at a cost of $25 per month, avoiding the need for an external service that would have cost $300 per month.</li>
    </ul>
  </li>
  <li><strong>Time Savings</strong>
    <ul>
      <li>The time required for internal team members to follow up on VOC, identify issues, and respond was significantly reduced.</li>
    </ul>
  </li>
</ol>

<hr />

<h1 id="2-situation">2. Situation</h1>

<blockquote>
  <p>Internal team members were struggling to efficiently track and follow up on Zendesk customer inquiries. Reading through all the inquiries required <strong>an excessive amount of time and effort</strong>, and implementing an external VOC analysis service posed <strong>a cost burden</strong>.</p>
</blockquote>

<h3 id="specific-situation">Specific Situation</h3>
<ul>
  <li>It was taking too much time to follow up on dozens to hundreds of customer inquiries each week.</li>
  <li>It was challenging to identify which topics were negatively impacting the customer experience.</li>
</ul>

<h3 id="feedback-from-internal-team-members">Feedback from Internal Team Members</h3>
<ul>
  <li><strong>C-level 1</strong>: “I’m trying to stay on top of customer sentiment by regularly reading the inquiries, but there are just too many, and it’s very time-consuming.”</li>
  <li><strong>C-level 2</strong>: “I’d like to introduce an external service for VOC analysis, but the cost is too high, so we’re hesitant.”</li>
  <li><strong>CX Manager</strong>: “I want to share more VOC insights with colleagues and improve the speed of issue resolution.”</li>
</ul>

<hr />

<h1 id="3-tasks">3. Tasks</h1>

<blockquote>
  <ol>
    <li>I decided to <strong>categorize and summarize</strong> customer inquiries and create a Redash VOC <strong>dashboard</strong>.</li>
    <li>I also decided to build <strong>a Slack notification bot</strong> to alert the team about the most urgent customer inquiry topics.</li>
  </ol>
</blockquote>

<p><img src="/assets/2024-07-20-voc-dashboard/1.png" alt="" /></p>

<hr />

<h1 id="4-actions">4. Actions</h1>

<blockquote>
  <ol>
    <li>
      <p><strong>Data Pipeline</strong></p>

      <p>1.1. Data Collection and Preprocessing <code class="language-plaintext highlighter-rouge">(Zendesk Tickets → Google Sheets → BigQuery)</code></p>

      <p>1.2. Topic Categorization <code class="language-plaintext highlighter-rouge">(OpenAI API)</code></p>

      <p>1.3. Summarization <code class="language-plaintext highlighter-rouge">(OpenAI API)</code></p>
    </li>
    <li>
      <p><strong>Dashboard and Notification Bot</strong></p>

      <p>2.1. Creating the Dashboard <code class="language-plaintext highlighter-rouge">(BigQuery → Redash)</code></p>

      <p>2.2. Building the Notification Bot <code class="language-plaintext highlighter-rouge">(BigQuery → Slack API)</code></p>
    </li>
  </ol>
</blockquote>

<h3 id="1-data-pipeline">1. <strong>Data Pipeline</strong></h3>

<p><img src="/assets/2024-07-20-voc-dashboard/2-en.png" alt="" /></p>

<h5 id="11-data-collection-and-preprocessing-zendesk-tickets--google-sheets--bigquery">1.1. Data Collection and Preprocessing <code class="language-plaintext highlighter-rouge">(Zendesk Tickets → Google Sheets → BigQuery)</code></h5>

<p><img src="/assets/2024-07-20-voc-dashboard/3-en.png" alt="" /></p>

<p>1) First, I used the <strong>Zendesk Connector</strong> available from Google Workspace Marketplace to automatically store completed Zendesk ticket data in a private Google Sheet.</p>

<p><img src="/assets/2024-07-20-voc-dashboard/4.png" alt="" /></p>

<p>2) I then loaded the Google Sheets data into Python.</p>

<details>
<summary>View Code</summary>
<div>
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   <span class="c1"># Load Raw Data from Google Sheets (to `df`)
</span>   <span class="n">gc</span> <span class="o">=</span> <span class="n">gspread</span><span class="p">.</span><span class="nf">service_account</span><span class="p">(</span><span class="n">google_sheets_credentials_fpath</span><span class="p">)</span>
   <span class="n">spreadsheet</span> <span class="o">=</span> <span class="n">gc</span><span class="p">.</span><span class="nf">open_by_url</span><span class="p">(</span><span class="n">google_sheets_url</span><span class="p">)</span>
   <span class="n">sheet</span> <span class="o">=</span> <span class="n">spreadsheet</span><span class="p">.</span><span class="nf">worksheet</span><span class="p">(</span><span class="n">google_sheets_worksheet_name</span><span class="p">)</span>
   <span class="n">sheet_data</span> <span class="o">=</span> <span class="n">sheet</span><span class="p">.</span><span class="nf">get_all_records</span><span class="p">()</span>
   <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">sheet_data</span><span class="p">)</span>
</code></pre></div>    </div>
  </div>
</details>

<p>3) After that, I proceeded with data preprocessing.</p>

<details>
<summary>Filter Only Necessary Columns</summary>
<div>
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   <span class="c1"># Rename Columns
</span>   <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">rename</span><span class="p">(</span>
      <span class="n">columns</span><span class="o">=</span><span class="p">{</span>
         <span class="sh">'</span><span class="s">created_at</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">created_datetime</span><span class="sh">'</span><span class="p">,</span>
         <span class="sh">'</span><span class="s">raw_subject</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">subject</span><span class="sh">'</span><span class="p">,</span>
         <span class="sh">'</span><span class="s">tags.0</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">zendesk_topic</span><span class="sh">'</span><span class="p">,</span>
         <span class="sh">'</span><span class="s">updated_at</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">updated_datetime</span><span class="sh">'</span>
      <span class="p">}</span>
   <span class="p">)</span>
   <span class="c1"># Extract Only Necessary Columns
</span>   <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span>
      <span class="sh">'</span><span class="s">id</span><span class="sh">'</span><span class="p">,</span>
      <span class="sh">'</span><span class="s">created_datetime</span><span class="sh">'</span><span class="p">,</span>
      <span class="sh">'</span><span class="s">zendesk_topic</span><span class="sh">'</span><span class="p">,</span>
      <span class="sh">'</span><span class="s">subject</span><span class="sh">'</span><span class="p">,</span>
      <span class="sh">'</span><span class="s">description</span><span class="sh">'</span>
   <span class="p">]]</span>
</code></pre></div>    </div>
  </div>
</details>

<details>
<summary>Change Timezone (UTC → KST)</summary>
<div>
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   <span class="c1"># Convert Existing Timestamps: UTC to KST
</span>   <span class="n">kst</span> <span class="o">=</span> <span class="n">pytz</span><span class="p">.</span><span class="nf">timezone</span><span class="p">(</span><span class="sh">'</span><span class="s">Asia/Seoul</span><span class="sh">'</span><span class="p">)</span>
   <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">created_datetime</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">created_datetime</span><span class="sh">'</span><span class="p">],</span> <span class="n">utc</span><span class="o">=</span><span class="bp">True</span><span class="p">).</span><span class="n">dt</span><span class="p">.</span><span class="nf">tz_convert</span><span class="p">(</span><span class="n">kst</span><span class="p">).</span><span class="n">dt</span><span class="p">.</span><span class="nf">tz_localize</span><span class="p">(</span><span class="bp">None</span><span class="p">)</span>
   <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">astype</span><span class="p">(</span><span class="sh">'</span><span class="s">str</span><span class="sh">'</span><span class="p">)</span> <span class="c1"># To load into BigQuery, all columns must be cast as strings.
</span></code></pre></div>    </div>
  </div>
</details>

<details>
<summary>Filter Only New Entries</summary>
<div>
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   <span class="c1"># Remove Rows Already in Target Table (Prevent Duplicates)
</span>   <span class="n">query</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">'</span><span class="s">SELECT DISTINCT id FROM `</span><span class="si">{</span><span class="n">bigquery_tickets_table_id</span><span class="si">}</span><span class="s">`</span><span class="sh">'</span>
   <span class="k">try</span><span class="p">:</span>
      <span class="n">existing_ids</span> <span class="o">=</span> <span class="n">client</span><span class="p">.</span><span class="nf">query</span><span class="p">(</span><span class="n">query</span><span class="p">).</span><span class="nf">to_dataframe</span><span class="p">()</span>
      <span class="n">existing_ids</span> <span class="o">=</span> <span class="nf">set</span><span class="p">(</span><span class="n">existing_ids</span><span class="p">[</span><span class="sh">'</span><span class="s">id</span><span class="sh">'</span><span class="p">])</span>
      <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span>
         <span class="o">~</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">id</span><span class="sh">'</span><span class="p">].</span><span class="nf">isin</span><span class="p">(</span><span class="n">existing_ids</span><span class="p">)</span>
      <span class="p">].</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
   <span class="k">except</span><span class="p">:</span>
      <span class="n">df</span> <span class="o">=</span> <span class="n">df</span>
</code></pre></div>    </div>
  </div>
</details>

<p>4) Finally, I loaded the data into the BigQuery table.</p>

<details>
<summary>View Code</summary>
<div>
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   <span class="c1"># Load Data into BigQuery Table
</span>   <span class="n">table</span> <span class="o">=</span> <span class="n">client</span><span class="p">.</span><span class="nf">get_table</span><span class="p">(</span><span class="n">bigquery_tickets_table_id</span><span class="p">)</span>
   <span class="n">client</span><span class="p">.</span><span class="nf">load_table_from_dataframe</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">table</span><span class="p">)</span>
</code></pre></div>    </div>
  </div>
</details>

<h5 id="12-topic-categorization-openai-api">1.2. Topic Categorization <code class="language-plaintext highlighter-rouge">(OpenAI API)</code></h5>

<p><img src="/assets/2024-07-20-voc-dashboard/5-en.png" alt="" /></p>

<p>1) To predefine the list of topics to be categorized, I discussed and established a classification system with a CX manager and a UX/UI designer.</p>

<ul>
  <li><strong>Topic</strong>: Broad subject categories</li>
  <li><strong>Keyword</strong>: Specific subtopics</li>
</ul>

<p><img src="/assets/2024-07-20-voc-dashboard/6.png" alt="" /></p>

<p>2) I loaded the data from the BigQuery table into Python.</p>

<details>
<summary>View Code</summary>
<div>
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   <span class="c1"># Load BigQuery `tickets` Table (to `df`)
</span>   <span class="n">query</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">'</span><span class="s">SELECT * FROM </span><span class="si">{</span><span class="n">bigquery_tickets_table_id</span><span class="si">}</span><span class="sh">'</span>
   <span class="n">df</span> <span class="o">=</span> <span class="n">bigquery_client</span><span class="p">.</span><span class="nf">query</span><span class="p">(</span><span class="n">query</span><span class="p">).</span><span class="nf">to_dataframe</span><span class="p">()</span>
</code></pre></div>    </div>
  </div>
</details>

<p>3) I then filtered out only new entries.</p>

<details>
<summary>View Code</summary>
<div>
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   <span class="c1"># Remove Rows Already in Target Table (Prevent Duplicates)
</span>   <span class="n">query</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">'</span><span class="s">SELECT DISTINCT id FROM `</span><span class="si">{</span><span class="n">bigquery_tickets_topics_table_id</span><span class="si">}</span><span class="s">`</span><span class="sh">'</span>
   <span class="k">try</span><span class="p">:</span>
      <span class="n">existing_ids</span> <span class="o">=</span> <span class="n">bigquery_client</span><span class="p">.</span><span class="nf">query</span><span class="p">(</span><span class="n">query</span><span class="p">).</span><span class="nf">to_dataframe</span><span class="p">()</span>
      <span class="n">existing_ids</span> <span class="o">=</span> <span class="nf">set</span><span class="p">(</span><span class="n">existing_ids</span><span class="p">[</span><span class="sh">'</span><span class="s">id</span><span class="sh">'</span><span class="p">])</span>
      <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span>
         <span class="o">~</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">id</span><span class="sh">'</span><span class="p">].</span><span class="nf">isin</span><span class="p">(</span><span class="n">existing_ids</span><span class="p">)</span>
      <span class="p">].</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
   <span class="k">except</span><span class="p">:</span>
      <span class="n">df</span> <span class="o">=</span> <span class="n">df</span>
</code></pre></div>    </div>
  </div>
</details>

<p>4) I created the prompt to be sent to OpenAI.</p>

<details>
<summary>System Prompt</summary>
<div>
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   Your task is to classify a single key keyword from the customer inquiry details. You must respond by selecting only from the provided list of topics. Below is the list of topics you can choose from:
      {Keyword List}
   Do not create or select any other topics.
</code></pre></div>    </div>
  </div>
</details>

<details>
<summary>User Prompt</summary>
<div>
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   Below is the customer inquiry details.
   Extract a single key topic from this text.

   Customer Inquiry Details:
      {Actual Text}

   Extraction Format: Topic
   Restrictions:
   1. Respond with only the topic.
   2. Choose only from the provided list of topics. Do not create or select any other topics.
   3. Make sure to select one from the list below:
   {Keyword List}
   
   Extraction Result:
</code></pre></div>    </div>
  </div>
</details>

<p>5) I then obtained the main topic by calling the OpenAI API.</p>

<details>
<summary>View Code</summary>
<div>
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   <span class="c1"># Define the system prompt for OpenAI
</span>   <span class="n">prompt_system</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">'''</span><span class="s">
   Your task is to classify a single key keyword from the customer inquiry details. You must respond by selecting only from the provided list of topics. Below is the list of topics you can choose from:
   </span><span class="si">{</span><span class="sh">'</span><span class="s">, </span><span class="sh">'</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="n">topics2_list</span><span class="p">)</span><span class="si">}</span><span class="s">
   Do not create or select any other topics.
   </span><span class="sh">'''</span>

   <span class="c1"># Start the OpenAI API Request for each row
</span>   <span class="n">topic2_results_list</span> <span class="o">=</span> <span class="p">[]</span>

   <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">df</span><span class="p">)):</span>

      <span class="c1"># Subject + Description
</span>      <span class="n">text</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="sh">'</span><span class="s">subject</span><span class="sh">'</span><span class="p">]</span> <span class="o">+</span> <span class="sh">'</span><span class="s"> </span><span class="sh">'</span> <span class="o">+</span> <span class="n">df</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="sh">'</span><span class="s">description</span><span class="sh">'</span><span class="p">]</span>
      <span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="p">[:</span><span class="mi">2000</span><span class="p">]</span> <span class="c1"># Limit length to 2,000 characters (to save costs)
</span>
      <span class="c1"># Define the individual prompt for API Request
</span>      <span class="n">prompt_individual</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">'''</span><span class="s">
      Below is the customer inquiry details.
      Extract a single key topic from this text.

      Customer Inquiry Details:
      </span><span class="si">{</span><span class="n">text</span><span class="si">}</span><span class="s">

      Extraction Format: Topic
      Restrictions:
      1. Respond with only the topic.
      2. Choose only from the provided list of topics. Do not create or select any other topics.
      3. Make sure to select one from the list below:
      </span><span class="si">{</span><span class="sh">'</span><span class="s">, </span><span class="sh">'</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="n">topics2_list</span><span class="p">)</span><span class="si">}</span><span class="s"> 
      
      Extraction Result:
      </span><span class="sh">'''</span>

      <span class="c1"># Start the API Request
</span>      <span class="n">result</span> <span class="o">=</span> <span class="n">openai_client</span><span class="p">.</span><span class="n">chat</span><span class="p">.</span><span class="n">completions</span><span class="p">.</span><span class="nf">create</span><span class="p">(</span>
            <span class="n">model</span> <span class="o">=</span> <span class="sh">'</span><span class="s">gpt-4</span><span class="sh">'</span><span class="p">,</span>
            <span class="n">max_tokens</span> <span class="o">=</span> <span class="mi">500</span><span class="p">,</span>
            <span class="n">n</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
            <span class="n">temperature</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
            <span class="n">stop</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span>
            <span class="n">messages</span> <span class="o">=</span> <span class="p">[</span>
               <span class="p">{</span><span class="sh">"</span><span class="s">role</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">system</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">content</span><span class="sh">"</span><span class="p">:</span> <span class="n">prompt_system</span><span class="p">},</span>
               <span class="p">{</span><span class="sh">"</span><span class="s">role</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">user</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">content</span><span class="sh">"</span><span class="p">:</span> <span class="n">prompt_individual</span><span class="p">}</span>
            <span class="p">]</span>
      <span class="p">)</span>

      <span class="c1"># Record the topic results into Empty Lists
</span>      <span class="n">topic2_result</span> <span class="o">=</span> <span class="n">result</span><span class="p">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">message</span><span class="p">.</span><span class="n">content</span><span class="p">.</span><span class="nf">replace</span><span class="p">(</span><span class="sh">'</span><span class="se">\'</span><span class="sh">'</span><span class="p">,</span> <span class="sh">''</span><span class="p">).</span><span class="nf">replace</span><span class="p">(</span><span class="sh">'</span><span class="se">\"</span><span class="sh">'</span><span class="p">,</span> <span class="sh">''</span><span class="p">).</span><span class="nf">replace</span><span class="p">(</span><span class="sh">'</span><span class="s">[</span><span class="sh">'</span><span class="p">,</span> <span class="sh">''</span><span class="p">).</span><span class="nf">replace</span><span class="p">(</span><span class="sh">'</span><span class="s">]</span><span class="sh">'</span><span class="p">,</span> <span class="sh">''</span><span class="p">).</span><span class="nf">strip</span><span class="p">()</span>
      <span class="n">topic2_results_list</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">topic2_result</span><span class="p">)</span>

   <span class="c1"># Record the 'Topic 1' results using 'Topic 2' results
</span>   <span class="n">topic1_results_list</span> <span class="o">=</span> <span class="p">[]</span>
   <span class="k">for</span> <span class="n">topic2</span> <span class="ow">in</span> <span class="n">topic2_results_list</span><span class="p">:</span>
      <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">topics_list</span><span class="p">)):</span>
            <span class="k">if</span> <span class="n">topics_list</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">topic2</span><span class="p">:</span>
               <span class="n">topic1_results_list</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">topics_list</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
               <span class="k">break</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="nf">len</span><span class="p">(</span><span class="n">topics_list</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
               <span class="n">topic1_results_list</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="sh">'</span><span class="s">Others</span><span class="sh">'</span><span class="p">)</span>
      
   <span class="c1"># Add 'Topic 1' and 'Topic 2' columns to the dataframe and select only the necessary columns
</span>   <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">openai_topic_1</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">topic1_results_list</span>
   <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">openai_topic_2</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">topic2_results_list</span>
   <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span>
      <span class="sh">'</span><span class="s">id</span><span class="sh">'</span><span class="p">,</span>
      <span class="sh">'</span><span class="s">created_datetime</span><span class="sh">'</span><span class="p">,</span>
      <span class="sh">'</span><span class="s">openai_topic_1</span><span class="sh">'</span><span class="p">,</span>
      <span class="sh">'</span><span class="s">openai_topic_2</span><span class="sh">'</span>
   <span class="p">]]</span>
</code></pre></div>    </div>
  </div>
</details>

<p>6) Finally, the topic categorization results were loaded into a BigQuery table.</p>

<details>
<summary>View Code</summary>
<div>
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   <span class="c1"># Load Data into BigQuery Table
</span>   <span class="n">table</span> <span class="o">=</span> <span class="n">bigquery_client</span><span class="p">.</span><span class="nf">get_table</span><span class="p">(</span><span class="n">bigquery_tickets_topics_table_id</span><span class="p">)</span>
   <span class="n">bigquery_client</span><span class="p">.</span><span class="nf">load_table_from_dataframe</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">table</span><span class="p">)</span>
</code></pre></div>    </div>
  </div>
</details>

<h5 id="13-summarization-openai-api">1.3. Summarization <code class="language-plaintext highlighter-rouge">(OpenAI API)</code></h5>

<p><img src="/assets/2024-07-20-voc-dashboard/7-en.png" alt="" /></p>

<p>1) I loaded the data from the BigQuery table into Python.</p>

<details>
<summary>View Code</summary>
<div>
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   <span class="c1"># Load BigQuery `tickets` Table (to `df`)
</span>   <span class="n">query</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">'</span><span class="s">SELECT * FROM </span><span class="si">{</span><span class="n">bigquery_tickets_table_id</span><span class="si">}</span><span class="sh">'</span>
   <span class="n">df</span> <span class="o">=</span> <span class="n">bigquery_client</span><span class="p">.</span><span class="nf">query</span><span class="p">(</span><span class="n">query</span><span class="p">).</span><span class="nf">to_dataframe</span><span class="p">()</span>
</code></pre></div>    </div>
  </div>
</details>

<p>2) I then filtered out only new entries.</p>

<details>
<summary>View Code</summary>
<div>
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   <span class="c1"># Remove Rows Already in Target Table (Prevent Duplicates)
</span>   <span class="n">query</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">'</span><span class="s">SELECT DISTINCT id FROM `</span><span class="si">{</span><span class="n">bigquery_tickets_summary_table_id</span><span class="si">}</span><span class="s">`</span><span class="sh">'</span>
   <span class="k">try</span><span class="p">:</span>
      <span class="n">existing_ids</span> <span class="o">=</span> <span class="n">bigquery_client</span><span class="p">.</span><span class="nf">query</span><span class="p">(</span><span class="n">query</span><span class="p">).</span><span class="nf">to_dataframe</span><span class="p">()</span>
      <span class="n">existing_ids</span> <span class="o">=</span> <span class="nf">set</span><span class="p">(</span><span class="n">existing_ids</span><span class="p">[</span><span class="sh">'</span><span class="s">id</span><span class="sh">'</span><span class="p">])</span>
      <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span>
         <span class="o">~</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">id</span><span class="sh">'</span><span class="p">].</span><span class="nf">isin</span><span class="p">(</span><span class="n">existing_ids</span><span class="p">)</span>
      <span class="p">].</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
   <span class="k">except</span><span class="p">:</span>
      <span class="n">df</span> <span class="o">=</span> <span class="n">df</span>
</code></pre></div>    </div>
  </div>
</details>

<p>3) I created the prompt to be sent to OpenAI.</p>

<details>
<summary>System Prompt</summary>
<div>
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   our task is to summarize customer inquiry details into a single sentence in Korean.
   Keep in mind that the customer is from a blockchain hardware and app wallet service company.
   The summary must be provided in a single sentence in Korean, and sensitive personal information or links must be removed.
</code></pre></div>    </div>
  </div>
</details>

<details>
<summary>User Prompt</summary>
<div>
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>      Below is a customer inquiry.
      Summarize this text into a single sentence in Korean.

      Customer inquiry:
      {text}

      Format of extraction: One sentence in Korean
      Constraints:

      1. Remember that the customer is from a blockchain hardware and app wallet service company.
      2. Summarize in Korean only. (However, proper nouns that cannot be translated may remain in English.)
      3. Respond in only one sentence.
      4. Ensure that sensitive personal information is removed. (e.g., personal details, wallet addresses, contact information, passwords, private keys, mnemonic phrases, email addresses, IP addresses, URLs, social media accounts, etc.)

      Extraction result:
</code></pre></div>    </div>
  </div>
</details>

<p>4) I performed the OpenAI summarization task by iterating over each ticket.</p>

<details>
<summary>View Code</summary>
<div>
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   <span class="c1"># Define the system prompt for OpenAI
</span>   <span class="n">prompt_system</span> <span class="o">=</span> <span class="sh">'''</span><span class="s">
   our task is to summarize customer inquiry details into a single sentence in Korean.
   Keep in mind that the customer is from a blockchain hardware and app wallet service company.
   The summary must be provided in a single sentence in Korean, and sensitive personal information or links must be removed.
   </span><span class="sh">'''</span>

   <span class="c1"># Start the OpenAI API Request for each row
</span>   <span class="n">summaries_list</span> <span class="o">=</span> <span class="p">[]</span>

   <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">df</span><span class="p">)):</span>

      <span class="c1"># Subject + Description
</span>      <span class="n">text</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="sh">'</span><span class="s">subject</span><span class="sh">'</span><span class="p">]</span> <span class="o">+</span> <span class="sh">'</span><span class="s"> </span><span class="sh">'</span> <span class="o">+</span> <span class="n">df</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="sh">'</span><span class="s">description</span><span class="sh">'</span><span class="p">]</span>
      <span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="p">[:</span><span class="mi">2000</span><span class="p">]</span> <span class="c1"># Limit length to 2,000 characters (to save costs)
</span>
      <span class="c1"># Define the individual prompt for API Request
</span>      <span class="n">prompt_individual</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">'''</span><span class="s">
      Below is a customer inquiry.
      Summarize this text into a single sentence in Korean.

      Customer inquiry:
      </span><span class="si">{</span><span class="n">text</span><span class="si">}</span><span class="s">

      Format of extraction: One sentence in Korean
      Constraints:

      1. Remember that the customer is from a blockchain hardware and app wallet service company.
      2. Summarize in Korean only. (However, proper nouns that cannot be translated may remain in English.)
      3. Respond in only one sentence.
      4. Ensure that sensitive personal information is removed. (e.g., personal details, wallet addresses, contact information, passwords, private keys, mnemonic phrases, email addresses, IP addresses, URLs, social media accounts, etc.)

      Extraction result:
      </span><span class="sh">'''</span>

      <span class="c1"># Start the API Request
</span>      <span class="n">result</span> <span class="o">=</span> <span class="n">openai_client</span><span class="p">.</span><span class="n">chat</span><span class="p">.</span><span class="n">completions</span><span class="p">.</span><span class="nf">create</span><span class="p">(</span>
            <span class="n">model</span> <span class="o">=</span> <span class="sh">'</span><span class="s">gpt-4</span><span class="sh">'</span><span class="p">,</span>
            <span class="n">max_tokens</span> <span class="o">=</span> <span class="mi">200</span><span class="p">,</span>
            <span class="n">n</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
            <span class="n">temperature</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
            <span class="n">stop</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span>
            <span class="n">messages</span> <span class="o">=</span> <span class="p">[</span>
               <span class="p">{</span><span class="sh">"</span><span class="s">role</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">system</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">content</span><span class="sh">"</span><span class="p">:</span> <span class="n">prompt_system</span><span class="p">},</span>
               <span class="p">{</span><span class="sh">"</span><span class="s">role</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">user</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">content</span><span class="sh">"</span><span class="p">:</span> <span class="n">prompt_individual</span><span class="p">}</span>
            <span class="p">]</span>
      <span class="p">)</span>

      <span class="c1"># Record the topic results into empty lists
</span>      <span class="n">summary_result</span> <span class="o">=</span> <span class="n">result</span><span class="p">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">message</span><span class="p">.</span><span class="n">content</span><span class="p">.</span><span class="nf">replace</span><span class="p">(</span><span class="sh">'</span><span class="se">\'</span><span class="sh">'</span><span class="p">,</span> <span class="sh">''</span><span class="p">).</span><span class="nf">replace</span><span class="p">(</span><span class="sh">'</span><span class="se">\"</span><span class="sh">'</span><span class="p">,</span> <span class="sh">''</span><span class="p">).</span><span class="nf">replace</span><span class="p">(</span><span class="sh">'</span><span class="s">[</span><span class="sh">'</span><span class="p">,</span> <span class="sh">''</span><span class="p">).</span><span class="nf">replace</span><span class="p">(</span><span class="sh">'</span><span class="s">]</span><span class="sh">'</span><span class="p">,</span> <span class="sh">''</span><span class="p">).</span><span class="nf">strip</span><span class="p">()</span>
      <span class="n">summaries_list</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">summary_result</span><span class="p">)</span>

   <span class="c1"># Add the summary column to the dataframe and select only the required columns
</span>   <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">openai_summary</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">summaries_list</span>
   <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span>
      <span class="sh">'</span><span class="s">id</span><span class="sh">'</span><span class="p">,</span>
      <span class="sh">'</span><span class="s">created_datetime</span><span class="sh">'</span><span class="p">,</span>
      <span class="sh">'</span><span class="s">openai_summary</span><span class="sh">'</span>
   <span class="p">]]</span>
</code></pre></div>    </div>
  </div>
</details>

<p>5) Finally, the summarized results were loaded into a BigQuery table.</p>

<details>
<summary>View Code</summary>
<div>
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   <span class="c1"># Load Data into BigQuery Table
</span>   <span class="n">table</span> <span class="o">=</span> <span class="n">bigquery_client</span><span class="p">.</span><span class="nf">get_table</span><span class="p">(</span><span class="n">bigquery_tickets_summary_table_id</span><span class="p">)</span>
   <span class="n">bigquery_client</span><span class="p">.</span><span class="nf">load_table_from_dataframe</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">table</span><span class="p">)</span>
</code></pre></div>    </div>
  </div>
</details>

<h3 id="2-dashboard-and-notification-bot">2. <strong>Dashboard and Notification Bot</strong></h3>

<h5 id="21-creating-the-dashboard-bigquery--redash">2.1. Creating the Dashboard <code class="language-plaintext highlighter-rouge">(BigQuery → Redash)</code></h5>

<p>1) I created a Redash dashboard with the following contents.</p>

<p><img src="/assets/2024-07-20-voc-dashboard/11.png" alt="" /></p>

<details>
<summary>Proportion by Topic</summary>
<div>
    <p><img src="/assets/2024-07-20-voc-dashboard/12.png" alt="" /></p>
  </div>
</details>

<details>
<summary>Trends by Topic</summary>
<div>
    <p><img src="/assets/2024-07-20-voc-dashboard/13.png" alt="" /></p>
  </div>
</details>

<details>
<summary>Trends by Keyword</summary>
<div>
    <p><img src="/assets/2024-07-20-voc-dashboard/14.png" alt="" /></p>
  </div>
</details>

<details>
<summary>Summary of Inquiries by Keyword</summary>
<div>
    <p><img src="/assets/2024-07-20-voc-dashboard/15.png" alt="" /></p>
  </div>
</details>

<details>
<summary>All Datasets</summary>
<div>
    <p><img src="/assets/2024-07-20-voc-dashboard/16.png" alt="" /></p>
  </div>
</details>

<h5 id="22-building-the-notification-bot-bigquery--slack-api">2.2. Building the Notification Bot <code class="language-plaintext highlighter-rouge">(BigQuery → Slack API)</code></h5>

<p>1) First, I wrote a BigQuery query.</p>

<details>
<summary>Extracting the detailed topics (Keywords) with the most significant increase in customer inquiries from the previous week (compared to the week before)</summary>
<div>
    <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   <span class="k">WITH</span>
   <span class="n">CTE_1w_ago_raw</span> <span class="k">AS</span> <span class="p">(</span>
      <span class="k">SELECT</span>
         <span class="n">openai_topic_2</span><span class="p">,</span>
         <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="n">id</span><span class="p">)</span> <span class="k">AS</span> <span class="n">tickets_cnt</span>
      <span class="k">FROM</span>
         <span class="nv">`bigquery_tickets_topics_table_id`</span>
      <span class="k">WHERE</span>
         <span class="n">DATE_TRUNC</span><span class="p">(</span><span class="n">DATE_ADD</span><span class="p">(</span><span class="k">CURRENT_DATE</span><span class="p">(),</span> <span class="n">INTERVAL</span> <span class="o">-</span><span class="mi">1</span> <span class="n">WEEK</span><span class="p">),</span> <span class="n">WEEK</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="nb">DATE</span><span class="p">(</span><span class="n">created_datetime</span><span class="p">)</span>
         <span class="k">AND</span> <span class="nb">DATE</span><span class="p">(</span><span class="n">created_datetime</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">DATE_TRUNC</span><span class="p">(</span><span class="k">CURRENT_DATE</span><span class="p">(),</span> <span class="n">WEEK</span><span class="p">)</span>
         <span class="k">AND</span> <span class="n">openai_topic_1</span> <span class="o">!=</span> <span class="s1">'Others'</span>
      <span class="k">GROUP</span> <span class="k">BY</span>
         <span class="mi">1</span>
   <span class="p">),</span>
   <span class="n">CTE_2w_ago_raw</span> <span class="k">AS</span> <span class="p">(</span>
      <span class="k">SELECT</span>
         <span class="n">openai_topic_2</span><span class="p">,</span>
         <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="n">id</span><span class="p">)</span> <span class="k">AS</span> <span class="n">tickets_cnt</span>
      <span class="k">FROM</span>
         <span class="nv">`bigquery_tickets_topics_table_id`</span>
      <span class="k">WHERE</span>
         <span class="n">DATE_TRUNC</span><span class="p">(</span><span class="n">DATE_ADD</span><span class="p">(</span><span class="k">CURRENT_DATE</span><span class="p">(),</span> <span class="n">INTERVAL</span> <span class="o">-</span><span class="mi">2</span> <span class="n">WEEK</span><span class="p">),</span> <span class="n">WEEK</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="nb">DATE</span><span class="p">(</span><span class="n">created_datetime</span><span class="p">)</span>
         <span class="k">AND</span> <span class="nb">DATE</span><span class="p">(</span><span class="n">created_datetime</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">DATE_TRUNC</span><span class="p">(</span><span class="n">DATE_ADD</span><span class="p">(</span><span class="k">CURRENT_DATE</span><span class="p">(),</span> <span class="n">INTERVAL</span> <span class="o">-</span><span class="mi">1</span> <span class="n">WEEK</span><span class="p">),</span> <span class="n">WEEK</span><span class="p">)</span>
         <span class="k">AND</span> <span class="n">openai_topic_1</span> <span class="o">!=</span> <span class="s1">'Others'</span>
      <span class="k">GROUP</span> <span class="k">BY</span>
         <span class="mi">1</span>
   <span class="p">),</span>
   <span class="n">CTE_diff</span> <span class="k">AS</span> <span class="p">(</span>
      <span class="k">SELECT</span>
         <span class="n">COALESCE</span><span class="p">(</span><span class="n">MAIN</span><span class="p">.</span><span class="n">openai_topic_2</span><span class="p">,</span> <span class="n">COMP</span><span class="p">.</span><span class="n">openai_topic_2</span><span class="p">)</span> <span class="k">AS</span> <span class="n">openai_topic_2</span><span class="p">,</span>
         <span class="n">MAIN</span><span class="p">.</span><span class="n">tickets_cnt</span> <span class="k">AS</span> <span class="n">tickets_cnt_1w_ago</span><span class="p">,</span>
         <span class="n">COALESCE</span><span class="p">(</span><span class="n">COMP</span><span class="p">.</span><span class="n">tickets_cnt</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="k">AS</span> <span class="n">tickets_cnt_2w_ago</span><span class="p">,</span>
         <span class="n">COALESCE</span><span class="p">(</span><span class="n">MAIN</span><span class="p">.</span><span class="n">tickets_cnt</span> <span class="o">-</span> <span class="n">COMP</span><span class="p">.</span><span class="n">tickets_cnt</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="k">AS</span> <span class="n">tickets_cnt_diff</span>
      <span class="k">FROM</span>
         <span class="n">CTE_1w_ago_raw</span> <span class="n">MAIN</span>
      <span class="k">LEFT</span> <span class="k">JOIN</span>
         <span class="n">CTE_2w_ago_raw</span> <span class="n">COMP</span>
         <span class="k">ON</span> <span class="n">MAIN</span><span class="p">.</span><span class="n">openai_topic_2</span> <span class="o">=</span> <span class="n">COMP</span><span class="p">.</span><span class="n">openai_topic_2</span>
   <span class="p">)</span>
   <span class="k">SELECT</span>
      <span class="n">openai_topic_2</span><span class="p">,</span>
      <span class="n">tickets_cnt_1w_ago</span><span class="p">,</span>
      <span class="n">tickets_cnt_2w_ago</span><span class="p">,</span>
      <span class="n">tickets_cnt_diff</span>
   <span class="k">FROM</span>
      <span class="n">CTE_diff</span>
   <span class="k">WHERE</span>
      <span class="n">tickets_cnt_diff</span> <span class="o">=</span> <span class="p">(</span><span class="k">SELECT</span> <span class="k">MAX</span><span class="p">(</span><span class="n">tickets_cnt_diff</span><span class="p">)</span> <span class="k">FROM</span> <span class="n">CTE_diff</span><span class="p">)</span>
      <span class="k">AND</span> <span class="n">tickets_cnt_diff</span> <span class="o">&gt;</span> <span class="mi">0</span>
   <span class="k">ORDER</span> <span class="k">BY</span>
      <span class="mi">1</span>
</code></pre></div>    </div>
  </div>
</details>

<p>2) I created a Slack message object.</p>

<details>
<summary>View Code</summary>
<div>
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   <span class="n">df</span> <span class="o">=</span> <span class="n">bigquery_client</span><span class="p">.</span><span class="nf">query</span><span class="p">(</span><span class="n">query</span><span class="p">).</span><span class="nf">to_dataframe</span><span class="p">()</span>

   <span class="c1"># Slack Message Title
</span>   <span class="n">message</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">'</span><span class="s">:phone: *Weekly Zendesk Summary* </span><span class="se">\n\n</span><span class="sh">'</span>
   <span class="n">message</span> <span class="o">+=</span> <span class="sa">f</span><span class="sh">'</span><span class="s">*Here are the customer inquiry topics that increased the most in the past week.* </span><span class="se">\n</span><span class="sh">'</span>

   <span class="c1"># If data exists
</span>   <span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
      <span class="n">topics</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">openai_topic_2</span><span class="sh">'</span><span class="p">].</span><span class="nf">tolist</span><span class="p">()</span>
      <span class="n">tickets_cnt_1w_agos</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">tickets_cnt_1w_ago</span><span class="sh">'</span><span class="p">].</span><span class="nf">tolist</span><span class="p">()</span>
      <span class="n">tickets_cnt_diffs</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">tickets_cnt_diff</span><span class="sh">'</span><span class="p">].</span><span class="nf">tolist</span><span class="p">()</span>
      <span class="c1"># Create Slack message
</span>      <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">topic</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">topics</span><span class="p">):</span>
         <span class="n">message</span> <span class="o">+=</span> <span class="sa">f</span><span class="sh">'</span><span class="s">- *</span><span class="si">{</span><span class="n">topic</span><span class="si">}</span><span class="s">*: Total </span><span class="si">{</span><span class="n">tickets_cnt_1w_agos</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s"> cases (Compared to the previous week +</span><span class="si">{</span><span class="n">tickets_cnt_diffs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s">) </span><span class="se">\n</span><span class="sh">'</span>

   <span class="c1"># If no data exists
</span>   <span class="k">else</span><span class="p">:</span>
      <span class="n">message</span> <span class="o">+=</span> <span class="sa">f</span><span class="sh">'</span><span class="s">- *There are no topics that increased.*:smile: </span><span class="se">\n\n</span><span class="sh">'</span>
</code></pre></div>    </div>
  </div>
</details>

<p>3) Every Monday at 9:00 AM, the following Slack notification was sent.</p>

<p><img src="/assets/2024-07-20-voc-dashboard/10-en.png" alt="" /></p>

<hr />

<h1 id="5-results">5. Results</h1>

<blockquote>
  <ol>
    <li><strong>Cost Savings</strong>
      <ul>
        <li>We solved the problem internally at a cost of $25 per month, avoiding the need for an external service that would have cost $300 per month.</li>
      </ul>
    </li>
    <li><strong>Time Savings</strong>
      <ul>
        <li>The time required for internal team members to follow up on VOC, identify issues, and respond was significantly reduced.</li>
      </ul>
    </li>
  </ol>
</blockquote>

<h3 id="1-cost-savings">1. <strong>Cost Savings</strong></h3>

<p>Conclusion)  By developing internally, we were able to eliminate approximately $275 in opportunity costs each month.</p>

<table>
  <tbody>
    <tr>
      <td> </td>
      <td><strong>External VOC Analysis Service</strong></td>
      <td><strong>Internal Development</strong></td>
    </tr>
    <tr>
      <td>Monthly Cost</td>
      <td><code class="language-plaintext highlighter-rouge">$300</code></td>
      <td><code class="language-plaintext highlighter-rouge">$25</code></td>
    </tr>
  </tbody>
</table>

<p>1) External VOC Analysis Service</p>
<ul>
  <li>The <a href="https://www.syncly.kr/">syncly</a> service we considered adopting required a minimum monthly cost of $299.</li>
</ul>

<p><img src="/assets/2024-07-20-voc-dashboard/8.png" alt="" /></p>

<p>2) Internal Development</p>
<ul>
  <li>However, internal development required the following costs:</li>
</ul>

<table>
  <tbody>
    <tr>
      <td><strong>Resource</strong></td>
      <td><strong>Monthly Cost</strong></td>
    </tr>
    <tr>
      <td>1. OpenAI API</td>
      <td><code class="language-plaintext highlighter-rouge">$25</code></td>
    </tr>
    <tr>
      <td>2. BigQuery Storage</td>
      <td>Minimal</td>
    </tr>
    <tr>
      <td>3. BigQuery Query Usage</td>
      <td>Negligible</td>
    </tr>
    <tr>
      <td>4. VM Instance Operation</td>
      <td>Minimal, as we used existing instances</td>
    </tr>
    <tr>
      <td><strong>TOTAL</strong></td>
      <td><code class="language-plaintext highlighter-rouge">$25</code> + e</td>
    </tr>
  </tbody>
</table>

<p><img src="/assets/2024-07-20-voc-dashboard/9.png" alt="ㅇㅇㅇ" /></p>
<blockquote>
  <p>Daily OpenAI API Costs</p>
</blockquote>

<h3 id="2-time-savings">2. <strong>Time Savings</strong></h3>

<p>1) Redash VOC Dashboard (Topic Categorization)</p>
<ul>
  <li>Improved <u>the ease of identifying</u> VOC issues for internal team members.</li>
</ul>

<p>2) Redash VOC Dashboard (Summarization)</p>
<ul>
  <li>Enhanced <u>the follow-up speed</u> on VOC and improved <u>accessibility</u> for internal team members.</li>
</ul>

<p>3) Slack Notification Bot</p>
<ul>
  <li>Improved issue <u>identification</u> and <u>response speed</u> by sharing the topics with the highest increase in inquiries with internal team members each week, contributing to <u>a shared understanding of the context</u>.</li>
</ul>

<hr />

<h2 id="published-by-joshua-kim"><em>Published by</em> Joshua Kim</h2>
<p><img src="/assets/profile/joshua-profile.png" alt="Joshua Kim" /></p>]]></content><author><name></name></author><category term="English" /><category term="Python" /><category term="BigQuery" /><category term="Redash" /><category term="Data Visualization" /><category term="LLM" /><summary type="html"><![CDATA[“I learned that internal team members were facing difficulties in following up on Zendesk customer inquiries, so I developed a Redash VOC dashboard to address this issue. The system automatically collected and preprocessed Zendesk data, then used the OpenAI API to categorize and summarize customer inquiries by topic. Additionally, a Slack notification was set up to alert the team each Monday about the topics with the highest increase in inquiries, helping identify and respond to customer issues more efficiently. As a result, we were able to eliminate about $275 in opportunity costs each month and reduce the time spent by team members on VOC follow-ups.”]]></summary></entry><entry><title type="html">데이터 기반 VOC 분석 및 자동화 대시보드 구축: 비용 절감과 효율성 극대화</title><link href="http://localhost:4000/voc-dashboard-ko/" rel="alternate" type="text/html" title="데이터 기반 VOC 분석 및 자동화 대시보드 구축: 비용 절감과 효율성 극대화" /><published>2024-07-20T00:00:00+09:00</published><updated>2024-07-20T00:00:00+09:00</updated><id>http://localhost:4000/voc-dashboard-ko</id><content type="html" xml:base="http://localhost:4000/voc-dashboard-ko/"><![CDATA[<blockquote>
  <p>“사내 구성원 분들이 젠데스크 고객 문의 내역 팔로업에 어려움을 겪고 있다는 사실을 공유 받아, 이를 해결하기 위해 Redash VOC 대시보드를 구축했습니다. 젠데스크 데이터를 자동으로 수집하고 전처리한 후, OpenAI API를 활용해 고객 문의 내역을 주제별로 분류하고 요약했습니다. 추가적으로, 매주 월요일마다 가장 많이 증가한 문의 주제를 슬랙으로 알림을 보내어, 고객 이슈를 효율적으로 식별하고 대응할 수 있도록 기여했습니다. 결과적으로 매월 약 $275 기회 비용을 제거할 수 있었으며, 사내 구성원 분들의 VOC 팔로업 시간을 감소시키는 성과를 얻었습니다.”</p>
</blockquote>

<hr />

<h1 id="목차">목차</h1>
<ol>
  <li>STAR Summary</li>
  <li>Situation</li>
  <li>Tasks</li>
  <li>Actions</li>
  <li>Results</li>
</ol>

<hr />

<h1 id="1-star-summary">1. STAR Summary</h1>

<h3 id="situation">Situation</h3>
<ul>
  <li>사내 구성원 분들이 젠데스크 고객 문의 내역을 효율적으로 추적하고 팔로업하는 데 어려움을 겪고 있었습니다. 모든 내역을 읽는 것은 지나치게 <strong>많은 시간과 노력</strong>을 요구했으며, 외부 VOC 분석 서비스를 도입하기에는 <strong>비용의 부담</strong>이 있었습니다.</li>
</ul>

<h3 id="tasks">Tasks</h3>
<ol>
  <li>고객 문의 내역의 <strong>주제를 분류하고 요약</strong>하여, Redash VOC <strong>대시보드</strong>를 만들기로 결정했습니다.</li>
  <li>가장 긴급한 고객 문의 주제를 알려주는 <strong>슬랙 알림 봇</strong>을 구축하기로 결정했습니다.</li>
</ol>

<h3 id="actions">Actions</h3>
<ol>
  <li>
    <p><strong>데이터 파이프라인</strong></p>

    <p>1.1. 데이터 수집 및 전처리 <code class="language-plaintext highlighter-rouge">(Zendesk Tickets → Google Sheets → BigQuery)</code></p>

    <p>1.2. 주제 분류 <code class="language-plaintext highlighter-rouge">(OpenAI API)</code></p>

    <p>1.3. 요약하기 <code class="language-plaintext highlighter-rouge">(OpenAI API)</code></p>
  </li>
  <li>
    <p><strong>대시보드와 알림 봇</strong></p>

    <p>2.1. 대시보드 만들기 <code class="language-plaintext highlighter-rouge">(BigQuery → Redash)</code></p>

    <p>2.2. 알림 봇 구축하기 <code class="language-plaintext highlighter-rouge">(BigQuery → Slack API)</code></p>
  </li>
</ol>

<h3 id="results">Results</h3>
<ol>
  <li><strong>비용 절약</strong>
    <ul>
      <li>월 $300 비용의 외부 서비스를 도입하지 않고도, 내부 개발을 통해 월 $25 비용 만으로 문제를 해소했습니다.</li>
    </ul>
  </li>
  <li><strong>시간 절감</strong>
    <ul>
      <li>사내 구성원 분들의 VOC 팔로업, 이슈 식별과 대응 속도를 향상시켰습니다.</li>
    </ul>
  </li>
</ol>

<hr />

<h1 id="2-situation">2. Situation</h1>

<blockquote>
  <p>사내 구성원 분들이 젠데스크 고객 문의 내역을 효율적으로 추적하고 팔로업하는 데 어려움을 겪고 있었습니다. 모든 내역을 읽는 것은 지나치게 <strong>많은 시간과 노력</strong>을 요구했으며, 외부 VOC 분석 서비스를 도입하기에는 <strong>비용의 부담</strong>이 있었습니다.</p>
</blockquote>

<h3 id="구체적인-상황">구체적인 상황</h3>
<ul>
  <li>매주 수십-수백개의 고객 문의 내역을 일일이 팔로업하는 과정에서 너무 많은 시간이 소모되고 있었습니다.</li>
  <li>정확히 어떤 항목이 CX에 악영향을 끼치고 있는지 흐름을 파악하기 어려웠습니다.</li>
</ul>

<h3 id="사내-구성원-분들의-말말말">사내 구성원 분들의 말말말</h3>
<ul>
  <li><strong>임원 1</strong>: “주기적으로 문의 내역을 읽으며 고객의 감을 잡아가고 있는데, 양이 너무 많아 시간 소모가 커요.”</li>
  <li><strong>임원 2</strong>: “VOC 분석을 위한 외부 서비스를 도입하고 싶지만 가격이 너무 비싸서 고민하고 있어요.”</li>
  <li><strong>CX 담당자</strong>: “CX 및 VOC 현황을 좀 더 많은 동료들에게 공유하고, 이슈 대응 속도를 개선하고 싶어요.”</li>
</ul>

<hr />

<h1 id="3-tasks">3. Tasks</h1>

<blockquote>
  <ol>
    <li>고객 문의 내역의 <strong>주제를 분류하고 요약</strong>하여, Redash VOC <strong>대시보드</strong>를 만들기로 결정했습니다.</li>
    <li>가장 긴급한 고객 문의 주제를 알려주는 <strong>슬랙 알림 봇</strong>을 구축하기로 결정했습니다.</li>
  </ol>
</blockquote>

<p><img src="/assets/2024-07-20-voc-dashboard/1.png" alt="" /></p>

<hr />

<h1 id="4-actions">4. Actions</h1>

<blockquote>
  <ol>
    <li>
      <p><strong>데이터 파이프라인</strong></p>

      <p>1.1. 데이터 수집 및 전처리 <code class="language-plaintext highlighter-rouge">(Zendesk Tickets → Google Sheets → BigQuery)</code></p>

      <p>1.2. 주제 분류 <code class="language-plaintext highlighter-rouge">(OpenAI API)</code></p>

      <p>1.3. 요약하기 <code class="language-plaintext highlighter-rouge">(OpenAI API)</code></p>
    </li>
    <li>
      <p><strong>대시보드와 알림 봇</strong></p>

      <p>2.1. 대시보드 만들기 <code class="language-plaintext highlighter-rouge">(BigQuery → Redash)</code></p>

      <p>2.2. 알림 봇 구축하기 <code class="language-plaintext highlighter-rouge">(BigQuery → Slack API)</code></p>
    </li>
  </ol>
</blockquote>

<h3 id="1-데이터-파이프라인">1. <strong>데이터 파이프라인</strong></h3>

<p><img src="/assets/2024-07-20-voc-dashboard/2-ko.png" alt="" /></p>

<h5 id="11-데이터-수집-및-전처리-zendesk-tickets--google-sheets--bigquery">1.1. 데이터 수집 및 전처리 <code class="language-plaintext highlighter-rouge">(Zendesk Tickets → Google Sheets → BigQuery)</code></h5>

<p><img src="/assets/2024-07-20-voc-dashboard/3-ko.png" alt="" /></p>

<p>1) 먼저 Google Workspace Marketplace에서 제공하는 <strong>Zendesk Connector</strong>를 통해 답변이 완료된 젠데스크 티켓 데이터를 사내 비공개 구글 시트에 자동으로 저장될 수 있도록 설정했습니다.</p>

<p><img src="/assets/2024-07-20-voc-dashboard/4.png" alt="" /></p>

<p>2) Python에서 구글 시트 데이터를 로드했습니다.</p>

<details>
<summary>코드 확인하기</summary>
<div>
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   <span class="c1"># 구글 시트 Raw Data 불러오기 (to `df`)
</span>   <span class="n">gc</span> <span class="o">=</span> <span class="n">gspread</span><span class="p">.</span><span class="nf">service_account</span><span class="p">(</span><span class="n">google_sheets_credentials_fpath</span><span class="p">)</span>
   <span class="n">spreadsheet</span> <span class="o">=</span> <span class="n">gc</span><span class="p">.</span><span class="nf">open_by_url</span><span class="p">(</span><span class="n">google_sheets_url</span><span class="p">)</span>
   <span class="n">sheet</span> <span class="o">=</span> <span class="n">spreadsheet</span><span class="p">.</span><span class="nf">worksheet</span><span class="p">(</span><span class="n">google_sheets_worksheet_name</span><span class="p">)</span>
   <span class="n">sheet_data</span> <span class="o">=</span> <span class="n">sheet</span><span class="p">.</span><span class="nf">get_all_records</span><span class="p">()</span>
   <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">sheet_data</span><span class="p">)</span>
</code></pre></div>    </div>
  </div>
</details>

<p>3) 그런 후, 데이터 전처리를 진행했습니다.</p>

<details>
<summary>필요한 칼럼만 필터링</summary>
<div>
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   <span class="c1"># 칼럼 이름 재정의하기
</span>   <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">rename</span><span class="p">(</span>
      <span class="n">columns</span><span class="o">=</span><span class="p">{</span>
         <span class="sh">'</span><span class="s">created_at</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">created_datetime</span><span class="sh">'</span><span class="p">,</span>
         <span class="sh">'</span><span class="s">raw_subject</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">subject</span><span class="sh">'</span><span class="p">,</span>
         <span class="sh">'</span><span class="s">tags.0</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">zendesk_topic</span><span class="sh">'</span><span class="p">,</span>
         <span class="sh">'</span><span class="s">updated_at</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">updated_datetime</span><span class="sh">'</span>
      <span class="p">}</span>
   <span class="p">)</span>
   <span class="c1"># 필요한 칼럼만 뽑아내기
</span>   <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span>
      <span class="sh">'</span><span class="s">id</span><span class="sh">'</span><span class="p">,</span>
      <span class="sh">'</span><span class="s">created_datetime</span><span class="sh">'</span><span class="p">,</span>
      <span class="sh">'</span><span class="s">zendesk_topic</span><span class="sh">'</span><span class="p">,</span>
      <span class="sh">'</span><span class="s">subject</span><span class="sh">'</span><span class="p">,</span>
      <span class="sh">'</span><span class="s">description</span><span class="sh">'</span>
   <span class="p">]]</span>
</code></pre></div>    </div>
  </div>
</details>

<details>
<summary>시간대 변경 (UTC → KST)</summary>
<div>
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   <span class="c1"># 기존 타임스탬프: UTC to KST 변환해주기
</span>   <span class="n">kst</span> <span class="o">=</span> <span class="n">pytz</span><span class="p">.</span><span class="nf">timezone</span><span class="p">(</span><span class="sh">'</span><span class="s">Asia/Seoul</span><span class="sh">'</span><span class="p">)</span>
   <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">created_datetime</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">created_datetime</span><span class="sh">'</span><span class="p">],</span> <span class="n">utc</span><span class="o">=</span><span class="bp">True</span><span class="p">).</span><span class="n">dt</span><span class="p">.</span><span class="nf">tz_convert</span><span class="p">(</span><span class="n">kst</span><span class="p">).</span><span class="n">dt</span><span class="p">.</span><span class="nf">tz_localize</span><span class="p">(</span><span class="bp">None</span><span class="p">)</span>
   <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">astype</span><span class="p">(</span><span class="sh">'</span><span class="s">str</span><span class="sh">'</span><span class="p">)</span> <span class="c1"># BigQuery에 Load할 때, 기본적으로 모두 String 타입이 되어야 하므로, 어쩔 수 없이 모두 String으로 Casting한다.
</span></code></pre></div>    </div>
  </div>
</details>

<details>
<summary>신규 항목들만 필터링</summary>
<div>
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   <span class="c1"># 이미 타겟 테이블에 존재하는 행을 제거해주기 (중복 방지)
</span>   <span class="n">query</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">'</span><span class="s">SELECT DISTINCT id FROM `</span><span class="si">{</span><span class="n">bigquery_tickets_table_id</span><span class="si">}</span><span class="s">`</span><span class="sh">'</span>
   <span class="k">try</span><span class="p">:</span>
      <span class="n">existing_ids</span> <span class="o">=</span> <span class="n">client</span><span class="p">.</span><span class="nf">query</span><span class="p">(</span><span class="n">query</span><span class="p">).</span><span class="nf">to_dataframe</span><span class="p">()</span>
      <span class="n">existing_ids</span> <span class="o">=</span> <span class="nf">set</span><span class="p">(</span><span class="n">existing_ids</span><span class="p">[</span><span class="sh">'</span><span class="s">id</span><span class="sh">'</span><span class="p">])</span>
      <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span>
         <span class="o">~</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">id</span><span class="sh">'</span><span class="p">].</span><span class="nf">isin</span><span class="p">(</span><span class="n">existing_ids</span><span class="p">)</span>
      <span class="p">].</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
   <span class="k">except</span><span class="p">:</span>
      <span class="n">df</span> <span class="o">=</span> <span class="n">df</span>
</code></pre></div>    </div>
  </div>
</details>

<p>4) 마지막으로 BigQuery 테이블에 적재했습니다.</p>

<details>
<summary>코드 확인하기</summary>
<div>
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   <span class="c1"># 빅쿼리 테이블에 적재하기
</span>   <span class="n">table</span> <span class="o">=</span> <span class="n">client</span><span class="p">.</span><span class="nf">get_table</span><span class="p">(</span><span class="n">bigquery_tickets_table_id</span><span class="p">)</span>
   <span class="n">client</span><span class="p">.</span><span class="nf">load_table_from_dataframe</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">table</span><span class="p">)</span>
</code></pre></div>    </div>
  </div>
</details>

<h5 id="12-주제-분류-openai-api">1.2. 주제 분류 <code class="language-plaintext highlighter-rouge">(OpenAI API)</code></h5>

<p><img src="/assets/2024-07-20-voc-dashboard/5-ko.png" alt="" /></p>

<p>1) 분류할 주제 목록을 사전에 정의하기 위해, CX 담당자 및 UX/UI 디자이너 분과 함께 논의 후 분류 체계를 세웠습니다.</p>
<ul>
  <li><strong>Topic</strong>: 넓은 범주의 주제</li>
  <li><strong>Keyword</strong>: 구체적인 세부 주제</li>
</ul>

<p><img src="/assets/2024-07-20-voc-dashboard/6.png" alt="" /></p>

<p>2) Python에서 BigQuery 테이블의 데이터를 로드했습니다.</p>

<details>
<summary>코드 확인하기</summary>
<div>
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   <span class="c1"># BigQuery `tickets` 테이블 불러오기 (to `df`)
</span>   <span class="n">query</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">'</span><span class="s">SELECT * FROM </span><span class="si">{</span><span class="n">bigquery_tickets_table_id</span><span class="si">}</span><span class="sh">'</span>
   <span class="n">df</span> <span class="o">=</span> <span class="n">bigquery_client</span><span class="p">.</span><span class="nf">query</span><span class="p">(</span><span class="n">query</span><span class="p">).</span><span class="nf">to_dataframe</span><span class="p">()</span>
</code></pre></div>    </div>
  </div>
</details>

<p>3) 그 중, 신규 항목들만 필터링했습니다.</p>

<details>
<summary>코드 확인하기</summary>
<div>
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   <span class="c1"># 이미 타겟 테이블에 존재하는 행을 제거해주기 (중복 제거)
</span>   <span class="n">query</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">'</span><span class="s">SELECT DISTINCT id FROM `</span><span class="si">{</span><span class="n">bigquery_tickets_topics_table_id</span><span class="si">}</span><span class="s">`</span><span class="sh">'</span>
   <span class="k">try</span><span class="p">:</span>
      <span class="n">existing_ids</span> <span class="o">=</span> <span class="n">bigquery_client</span><span class="p">.</span><span class="nf">query</span><span class="p">(</span><span class="n">query</span><span class="p">).</span><span class="nf">to_dataframe</span><span class="p">()</span>
      <span class="n">existing_ids</span> <span class="o">=</span> <span class="nf">set</span><span class="p">(</span><span class="n">existing_ids</span><span class="p">[</span><span class="sh">'</span><span class="s">id</span><span class="sh">'</span><span class="p">])</span>
      <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span>
         <span class="o">~</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">id</span><span class="sh">'</span><span class="p">].</span><span class="nf">isin</span><span class="p">(</span><span class="n">existing_ids</span><span class="p">)</span>
      <span class="p">].</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
   <span class="k">except</span><span class="p">:</span>
      <span class="n">df</span> <span class="o">=</span> <span class="n">df</span>
</code></pre></div>    </div>
  </div>
</details>

<p>4) OpenAI에 요청할 프롬프트를 작성했습니다.</p>

<details>
<summary>System Prompt</summary>
<div>
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   당신의 작업은 고객 문의 내역에서 하나의 핵심 키워드를 분류하는 것입니다.
   오로지 주어진 토픽 목록에서만 선택하여 응답해야 합니다.
   아래는 당신이 선택할 수 있는 토픽 목록입니다:
      {키워드 리스트}
   다른 토픽을 생성하거나 선택하지 마세요.
</code></pre></div>    </div>
  </div>
</details>

<details>
<summary>User Prompt</summary>
<div>
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   아래는 고객 문의 내역입니다.
   이 텍스트에서 하나의 핵심 토픽을 추출하세요.

   고객 문의 내역:
         {실제 텍스트}

   추출 형식: 토픽
   제한 사항: 
   1. 오로지 토픽으로만 응답하세요.
   2. 주어진 토픽 목록에서만 선택하세요. 다른 토픽을 생성하거나 선택하지 마세요.
   3. 반드시 아래 목록에서 하나를 선택하세요:
   {키워드 리스트} 

   추출 결과: 
</code></pre></div>    </div>
  </div>
</details>

<p>5) 각 티켓을 순회하며 OpenAI 주제 분류 작업을 진행했습니다.</p>

<details>
<summary>코드 확인하기</summary>
<div>
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   <span class="c1"># OpenAI에 요청할 시스템 프롬프트 정의하기
</span>   <span class="n">prompt_system</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">'''</span><span class="s">
   당신의 작업은 고객 문의 내역에서 하나의 핵심 키워드를 분류하는 것입니다.
   오로지 주어진 토픽 목록에서만 선택하여 응답해야 합니다.
   아래는 당신이 선택할 수 있는 토픽 목록입니다:
   </span><span class="si">{</span><span class="sh">'</span><span class="s">, </span><span class="sh">'</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="n">topics2_list</span><span class="p">)</span><span class="si">}</span><span class="s">
   다른 토픽을 생성하거나 선택하지 마세요.
   </span><span class="sh">'''</span>

   <span class="c1"># 각 행을 돌아가면서 OpenAI API Request 시작하기
</span>   <span class="n">topic2_results_list</span> <span class="o">=</span> <span class="p">[]</span>

   <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">df</span><span class="p">)):</span>

      <span class="c1"># 주제 + 본문
</span>      <span class="n">text</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="sh">'</span><span class="s">subject</span><span class="sh">'</span><span class="p">]</span> <span class="o">+</span> <span class="sh">'</span><span class="s"> </span><span class="sh">'</span> <span class="o">+</span> <span class="n">df</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="sh">'</span><span class="s">description</span><span class="sh">'</span><span class="p">]</span>
      <span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="p">[:</span><span class="mi">2000</span><span class="p">]</span> <span class="c1"># 2,000개 길이로 제한 (비용 절약)
</span>
      <span class="c1"># 개별적으로 요청할 프롬프트 정의
</span>      <span class="n">prompt_individual</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">'''</span><span class="s">
      아래는 고객 문의 내역입니다.
      이 텍스트에서 하나의 핵심 토픽을 추출하세요.

      고객 문의 내역:
      </span><span class="si">{</span><span class="n">text</span><span class="si">}</span><span class="s">

      추출 형식: 토픽
      제한 사항: 
      1. 오로지 토픽으로만 응답하세요.
      2. 주어진 토픽 목록에서만 선택하세요. 다른 토픽을 생성하거나 선택하지 마세요.
      3. 반드시 아래 목록에서 하나를 선택하세요:
      </span><span class="si">{</span><span class="sh">'</span><span class="s">, </span><span class="sh">'</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="n">topics2_list</span><span class="p">)</span><span class="si">}</span><span class="s"> 

      추출 결과: 
      </span><span class="sh">'''</span>

      <span class="c1"># API Request 시작
</span>      <span class="n">result</span> <span class="o">=</span> <span class="n">openai_client</span><span class="p">.</span><span class="n">chat</span><span class="p">.</span><span class="n">completions</span><span class="p">.</span><span class="nf">create</span><span class="p">(</span>
            <span class="n">model</span> <span class="o">=</span> <span class="sh">'</span><span class="s">gpt-4</span><span class="sh">'</span><span class="p">,</span>
            <span class="n">max_tokens</span> <span class="o">=</span> <span class="mi">500</span><span class="p">,</span>
            <span class="n">n</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
            <span class="n">temperature</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
            <span class="n">stop</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span>
            <span class="n">messages</span> <span class="o">=</span> <span class="p">[</span>
               <span class="p">{</span><span class="sh">"</span><span class="s">role</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">system</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">content</span><span class="sh">"</span><span class="p">:</span> <span class="n">prompt_system</span><span class="p">},</span>
               <span class="p">{</span><span class="sh">"</span><span class="s">role</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">user</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">content</span><span class="sh">"</span><span class="p">:</span> <span class="n">prompt_individual</span><span class="p">}</span>
            <span class="p">]</span>
      <span class="p">)</span>

      <span class="c1"># 토픽 결과를 Empty Lists에 기록하기
</span>      <span class="n">topic2_result</span> <span class="o">=</span> <span class="n">result</span><span class="p">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">message</span><span class="p">.</span><span class="n">content</span><span class="p">.</span><span class="nf">replace</span><span class="p">(</span><span class="sh">'</span><span class="se">\'</span><span class="sh">'</span><span class="p">,</span> <span class="sh">''</span><span class="p">).</span><span class="nf">replace</span><span class="p">(</span><span class="sh">'</span><span class="se">\"</span><span class="sh">'</span><span class="p">,</span> <span class="sh">''</span><span class="p">).</span><span class="nf">replace</span><span class="p">(</span><span class="sh">'</span><span class="s">[</span><span class="sh">'</span><span class="p">,</span> <span class="sh">''</span><span class="p">).</span><span class="nf">replace</span><span class="p">(</span><span class="sh">'</span><span class="s">]</span><span class="sh">'</span><span class="p">,</span> <span class="sh">''</span><span class="p">).</span><span class="nf">strip</span><span class="p">()</span>
      <span class="n">topic2_results_list</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">topic2_result</span><span class="p">)</span>

   <span class="c1"># 토픽 2 결과를 통해 토픽 1 결과도 기록하기
</span>   <span class="n">topic1_results_list</span> <span class="o">=</span> <span class="p">[]</span>
   <span class="k">for</span> <span class="n">topic2</span> <span class="ow">in</span> <span class="n">topic2_results_list</span><span class="p">:</span>
      <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">topics_list</span><span class="p">)):</span>
            <span class="k">if</span> <span class="n">topics_list</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">topic2</span><span class="p">:</span>
               <span class="n">topic1_results_list</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">topics_list</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
               <span class="k">break</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="nf">len</span><span class="p">(</span><span class="n">topics_list</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
               <span class="n">topic1_results_list</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="sh">'</span><span class="s">Others</span><span class="sh">'</span><span class="p">)</span>
      
   <span class="c1"># df에 토픽 1, 토픽 2 칼럼을 추가하고, 필요한 칼럼만 뽑아내기
</span>   <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">openai_topic_1</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">topic1_results_list</span>
   <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">openai_topic_2</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">topic2_results_list</span>
   <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span>
      <span class="sh">'</span><span class="s">id</span><span class="sh">'</span><span class="p">,</span>
      <span class="sh">'</span><span class="s">created_datetime</span><span class="sh">'</span><span class="p">,</span>
      <span class="sh">'</span><span class="s">openai_topic_1</span><span class="sh">'</span><span class="p">,</span>
      <span class="sh">'</span><span class="s">openai_topic_2</span><span class="sh">'</span>
   <span class="p">]]</span>
</code></pre></div>    </div>
  </div>
</details>

<p>6) 마지막으로, 주제 분류 결과를 BigQuery 테이블에 적재했습니다.</p>

<details>
<summary>코드 확인하기</summary>
<div>
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   <span class="c1"># 빅쿼리 테이블에 적재하기
</span>   <span class="n">table</span> <span class="o">=</span> <span class="n">bigquery_client</span><span class="p">.</span><span class="nf">get_table</span><span class="p">(</span><span class="n">bigquery_tickets_topics_table_id</span><span class="p">)</span>
   <span class="n">bigquery_client</span><span class="p">.</span><span class="nf">load_table_from_dataframe</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">table</span><span class="p">)</span>
</code></pre></div>    </div>
  </div>
</details>

<h5 id="13-요약하기-openai-api">1.3. 요약하기 <code class="language-plaintext highlighter-rouge">(OpenAI API)</code></h5>

<p><img src="/assets/2024-07-20-voc-dashboard/7-ko.png" alt="" /></p>

<p>1) Python에서 BigQuery 테이블의 데이터를 로드했습니다.</p>

<details>
<summary>코드 확인하기</summary>
<div>
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   <span class="c1"># BigQuery `tickets` 테이블 불러오기 (to `df`)
</span>   <span class="n">query</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">'</span><span class="s">SELECT * FROM </span><span class="si">{</span><span class="n">bigquery_tickets_table_id</span><span class="si">}</span><span class="sh">'</span>
   <span class="n">df</span> <span class="o">=</span> <span class="n">bigquery_client</span><span class="p">.</span><span class="nf">query</span><span class="p">(</span><span class="n">query</span><span class="p">).</span><span class="nf">to_dataframe</span><span class="p">()</span>
</code></pre></div>    </div>
  </div>
</details>

<p>2) 그 중, 신규 항목들만 필터링했습니다.</p>

<details>
<summary>코드 확인하기</summary>
<div>
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   <span class="c1"># 이미 타겟 테이블에 존재하는 행을 제거해주기 (중복 제거)
</span>   <span class="n">query</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">'</span><span class="s">SELECT DISTINCT id FROM `</span><span class="si">{</span><span class="n">bigquery_tickets_summary_table_id</span><span class="si">}</span><span class="s">`</span><span class="sh">'</span>
   <span class="k">try</span><span class="p">:</span>
      <span class="n">existing_ids</span> <span class="o">=</span> <span class="n">bigquery_client</span><span class="p">.</span><span class="nf">query</span><span class="p">(</span><span class="n">query</span><span class="p">).</span><span class="nf">to_dataframe</span><span class="p">()</span>
      <span class="n">existing_ids</span> <span class="o">=</span> <span class="nf">set</span><span class="p">(</span><span class="n">existing_ids</span><span class="p">[</span><span class="sh">'</span><span class="s">id</span><span class="sh">'</span><span class="p">])</span>
      <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span>
         <span class="o">~</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">id</span><span class="sh">'</span><span class="p">].</span><span class="nf">isin</span><span class="p">(</span><span class="n">existing_ids</span><span class="p">)</span>
      <span class="p">].</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
   <span class="k">except</span><span class="p">:</span>
      <span class="n">df</span> <span class="o">=</span> <span class="n">df</span>
</code></pre></div>    </div>
  </div>
</details>

<p>3) OpenAI에 요청할 프롬프트를 작성했습니다.</p>

<details>
<summary>System Prompt</summary>
<div>
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   당신의 작업은 고객 문의 내역을 한국어 한 문장으로 요약하는 것입니다.
   블록체인 하드웨어 및 앱 지갑 서비스 기업의 고객임을 기억하세요.
   요약은 반드시 한국어 한 문장으로 제공되어야 하며, 민감한 개인정보나 링크는 반드시 제거되어야 합니다.
</code></pre></div>    </div>
  </div>
</details>

<details>
<summary>User Prompt</summary>
<div>
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   아래는 고객 문의 내역입니다.
   이 텍스트를 한국어 하나의 문장으로 요약하세요.

   고객 문의 내역:
   {실제 텍스트}

   추출 형식: 한국어 한 문장
   제한 사항:
   1. 블록체인 하드웨어 및 앱 지갑 서비스 기업의 고객임을 기억하세요.
   2. 반드시 한국어로 요약하세요. (단, 번역이 불가능한 고유 단어는 영어 가능)
   3. 오로지 한 문장으로만 응답하세요.
   4. 민감한 개인정보는 반드시 제거하세요.
   
   추출 결과:  
</code></pre></div>    </div>
  </div>
</details>

<p>4) 각 티켓을 순회하며 OpenAI 요약 작업을 진행했습니다.</p>

<details>
<summary>코드 확인하기</summary>
<div>
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   <span class="c1"># OpenAI에 요청할 시스템 프롬프트 정의하기
</span>   <span class="n">prompt_system</span> <span class="o">=</span> <span class="sh">'''</span><span class="s">
   당신의 작업은 고객 문의 내역을 한국어 한 문장으로 요약하는 것입니다.
   블록체인 하드웨어 및 앱 지갑 서비스 기업의 고객임을 기억하세요.
   요약은 반드시 한국어 한 문장으로 제공되어야 하며, 민감한 개인정보나 링크는 반드시 제거되어야 합니다.
   </span><span class="sh">'''</span>

   <span class="c1"># 각 행을 돌아가면서 OpenAI API Request 시작하기
</span>   <span class="n">summaries_list</span> <span class="o">=</span> <span class="p">[]</span>

   <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">df</span><span class="p">)):</span>

      <span class="c1"># 주제 + 본문
</span>      <span class="n">text</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="sh">'</span><span class="s">subject</span><span class="sh">'</span><span class="p">]</span> <span class="o">+</span> <span class="sh">'</span><span class="s"> </span><span class="sh">'</span> <span class="o">+</span> <span class="n">df</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="sh">'</span><span class="s">description</span><span class="sh">'</span><span class="p">]</span>
      <span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="p">[:</span><span class="mi">2000</span><span class="p">]</span> <span class="c1"># 2,000개 길이로 제한 (비용 절약)
</span>
      <span class="c1"># 개별적으로 요청할 프롬프트 정의
</span>      <span class="n">prompt_individual</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">'''</span><span class="s">
      아래는 고객 문의 내역입니다.
      이 텍스트를 한국어 하나의 문장으로 요약하세요.

      고객 문의 내역:
      </span><span class="si">{</span><span class="n">text</span><span class="si">}</span><span class="s">

      추출 형식: 한국어 한 문장
      제한 사항:
      1. 블록체인 하드웨어 및 앱 지갑 서비스 기업의 고객임을 기억하세요.
      2. 반드시 한국어로 요약하세요. (단, 번역이 불가능한 고유 단어는 영어 가능)
      3. 오로지 한 문장으로만 응답하세요.
      4. 민감한 개인정보는 반드시 제거하세요. (예: 인적사항, 지갑주소, 연락처, 비밀번호, 개인키, 니모닉, 이메일 주소, IP 주소, URL, 소셜 미디어 계정 등)
      
      추출 결과: 
      </span><span class="sh">'''</span>

      <span class="c1"># API Request 시작
</span>      <span class="n">result</span> <span class="o">=</span> <span class="n">openai_client</span><span class="p">.</span><span class="n">chat</span><span class="p">.</span><span class="n">completions</span><span class="p">.</span><span class="nf">create</span><span class="p">(</span>
            <span class="n">model</span> <span class="o">=</span> <span class="sh">'</span><span class="s">gpt-4</span><span class="sh">'</span><span class="p">,</span>
            <span class="n">max_tokens</span> <span class="o">=</span> <span class="mi">200</span><span class="p">,</span>
            <span class="n">n</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
            <span class="n">temperature</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
            <span class="n">stop</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span>
            <span class="n">messages</span> <span class="o">=</span> <span class="p">[</span>
               <span class="p">{</span><span class="sh">"</span><span class="s">role</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">system</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">content</span><span class="sh">"</span><span class="p">:</span> <span class="n">prompt_system</span><span class="p">},</span>
               <span class="p">{</span><span class="sh">"</span><span class="s">role</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">user</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">content</span><span class="sh">"</span><span class="p">:</span> <span class="n">prompt_individual</span><span class="p">}</span>
            <span class="p">]</span>
      <span class="p">)</span>

      <span class="c1"># 토픽 결과를 Empty Lists에 기록하기
</span>      <span class="n">summary_result</span> <span class="o">=</span> <span class="n">result</span><span class="p">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">message</span><span class="p">.</span><span class="n">content</span><span class="p">.</span><span class="nf">replace</span><span class="p">(</span><span class="sh">'</span><span class="se">\'</span><span class="sh">'</span><span class="p">,</span> <span class="sh">''</span><span class="p">).</span><span class="nf">replace</span><span class="p">(</span><span class="sh">'</span><span class="se">\"</span><span class="sh">'</span><span class="p">,</span> <span class="sh">''</span><span class="p">).</span><span class="nf">replace</span><span class="p">(</span><span class="sh">'</span><span class="s">[</span><span class="sh">'</span><span class="p">,</span> <span class="sh">''</span><span class="p">).</span><span class="nf">replace</span><span class="p">(</span><span class="sh">'</span><span class="s">]</span><span class="sh">'</span><span class="p">,</span> <span class="sh">''</span><span class="p">).</span><span class="nf">strip</span><span class="p">()</span>
      <span class="n">summaries_list</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">summary_result</span><span class="p">)</span>

   <span class="c1"># df에 요약 칼럼을 추가하고, 필요한 칼럼만 뽑아내기
</span>   <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">openai_summary</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">summaries_list</span>
   <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span>
      <span class="sh">'</span><span class="s">id</span><span class="sh">'</span><span class="p">,</span>
      <span class="sh">'</span><span class="s">created_datetime</span><span class="sh">'</span><span class="p">,</span>
      <span class="sh">'</span><span class="s">openai_summary</span><span class="sh">'</span>
   <span class="p">]]</span>
</code></pre></div>    </div>
  </div>
</details>

<p>5) 마지막으로, 요약 결과를 BigQuery 테이블에 적재했습니다.</p>

<details>
<summary>코드 확인하기</summary>
<div>
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   <span class="c1"># 빅쿼리 테이블에 적재하기
</span>   <span class="n">table</span> <span class="o">=</span> <span class="n">bigquery_client</span><span class="p">.</span><span class="nf">get_table</span><span class="p">(</span><span class="n">bigquery_tickets_summary_table_id</span><span class="p">)</span>
   <span class="n">bigquery_client</span><span class="p">.</span><span class="nf">load_table_from_dataframe</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">table</span><span class="p">)</span>
</code></pre></div>    </div>
  </div>
</details>

<h3 id="2-대시보드와-알림-봇">2. <strong>대시보드와 알림 봇</strong></h3>

<h5 id="21-대시보드-만들기-bigquery--redash">2.1. 대시보드 만들기 <code class="language-plaintext highlighter-rouge">(BigQuery → Redash)</code></h5>

<p>1) 다음 내용을 지닌 Redash 대시보드를 생성했습니다.</p>

<p><img src="/assets/2024-07-20-voc-dashboard/11.png" alt="" /></p>

<details>
<summary>Topic별 비율</summary>
<div>
    <p><img src="/assets/2024-07-20-voc-dashboard/12.png" alt="" /></p>
  </div>
</details>

<details>
<summary>Topic별 트렌드</summary>
<div>
    <p><img src="/assets/2024-07-20-voc-dashboard/13.png" alt="" /></p>
  </div>
</details>

<details>
<summary>Keyword별 트렌드</summary>
<div>
    <p><img src="/assets/2024-07-20-voc-dashboard/14.png" alt="" /></p>
  </div>
</details>

<details>
<summary>Keyword별 문의 요약</summary>
<div>
    <p><img src="/assets/2024-07-20-voc-dashboard/15.png" alt="" /></p>
  </div>
</details>

<details>
<summary>전체 데이터</summary>
<div>
    <p><img src="/assets/2024-07-20-voc-dashboard/16.png" alt="" /></p>
  </div>
</details>

<h5 id="22-알림-봇-구축하기-bigquery--slack-api">2.2. 알림 봇 구축하기 <code class="language-plaintext highlighter-rouge">(BigQuery → Slack API)</code></h5>

<p>1) 우선, BigQuery 쿼리문을 작성했습니다.</p>

<details>
<summary>전주에 고객 문의 수가 가장 많이 증가한 세부 주제(Keyword)를 추출 (전전주 대비)</summary>
<div>
    <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   <span class="k">WITH</span>
   <span class="n">CTE_1w_ago_raw</span> <span class="k">AS</span> <span class="p">(</span>
      <span class="k">SELECT</span>
         <span class="n">openai_topic_2</span><span class="p">,</span>
         <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="n">id</span><span class="p">)</span> <span class="k">AS</span> <span class="n">tickets_cnt</span>
      <span class="k">FROM</span>
         <span class="nv">`bigquery_tickets_topics_table_id`</span>
      <span class="k">WHERE</span>
         <span class="n">DATE_TRUNC</span><span class="p">(</span><span class="n">DATE_ADD</span><span class="p">(</span><span class="k">CURRENT_DATE</span><span class="p">(),</span> <span class="n">INTERVAL</span> <span class="o">-</span><span class="mi">1</span> <span class="n">WEEK</span><span class="p">),</span> <span class="n">WEEK</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="nb">DATE</span><span class="p">(</span><span class="n">created_datetime</span><span class="p">)</span>
         <span class="k">AND</span> <span class="nb">DATE</span><span class="p">(</span><span class="n">created_datetime</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">DATE_TRUNC</span><span class="p">(</span><span class="k">CURRENT_DATE</span><span class="p">(),</span> <span class="n">WEEK</span><span class="p">)</span>
         <span class="k">AND</span> <span class="n">openai_topic_1</span> <span class="o">!=</span> <span class="s1">'Others'</span>
      <span class="k">GROUP</span> <span class="k">BY</span>
         <span class="mi">1</span>
   <span class="p">),</span>
   <span class="n">CTE_2w_ago_raw</span> <span class="k">AS</span> <span class="p">(</span>
      <span class="k">SELECT</span>
         <span class="n">openai_topic_2</span><span class="p">,</span>
         <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="n">id</span><span class="p">)</span> <span class="k">AS</span> <span class="n">tickets_cnt</span>
      <span class="k">FROM</span>
         <span class="nv">`bigquery_tickets_topics_table_id`</span>
      <span class="k">WHERE</span>
         <span class="n">DATE_TRUNC</span><span class="p">(</span><span class="n">DATE_ADD</span><span class="p">(</span><span class="k">CURRENT_DATE</span><span class="p">(),</span> <span class="n">INTERVAL</span> <span class="o">-</span><span class="mi">2</span> <span class="n">WEEK</span><span class="p">),</span> <span class="n">WEEK</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="nb">DATE</span><span class="p">(</span><span class="n">created_datetime</span><span class="p">)</span>
         <span class="k">AND</span> <span class="nb">DATE</span><span class="p">(</span><span class="n">created_datetime</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">DATE_TRUNC</span><span class="p">(</span><span class="n">DATE_ADD</span><span class="p">(</span><span class="k">CURRENT_DATE</span><span class="p">(),</span> <span class="n">INTERVAL</span> <span class="o">-</span><span class="mi">1</span> <span class="n">WEEK</span><span class="p">),</span> <span class="n">WEEK</span><span class="p">)</span>
         <span class="k">AND</span> <span class="n">openai_topic_1</span> <span class="o">!=</span> <span class="s1">'Others'</span>
      <span class="k">GROUP</span> <span class="k">BY</span>
         <span class="mi">1</span>
   <span class="p">),</span>
   <span class="n">CTE_diff</span> <span class="k">AS</span> <span class="p">(</span>
      <span class="k">SELECT</span>
         <span class="n">COALESCE</span><span class="p">(</span><span class="n">MAIN</span><span class="p">.</span><span class="n">openai_topic_2</span><span class="p">,</span> <span class="n">COMP</span><span class="p">.</span><span class="n">openai_topic_2</span><span class="p">)</span> <span class="k">AS</span> <span class="n">openai_topic_2</span><span class="p">,</span>
         <span class="n">MAIN</span><span class="p">.</span><span class="n">tickets_cnt</span> <span class="k">AS</span> <span class="n">tickets_cnt_1w_ago</span><span class="p">,</span>
         <span class="n">COALESCE</span><span class="p">(</span><span class="n">COMP</span><span class="p">.</span><span class="n">tickets_cnt</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="k">AS</span> <span class="n">tickets_cnt_2w_ago</span><span class="p">,</span>
         <span class="n">COALESCE</span><span class="p">(</span><span class="n">MAIN</span><span class="p">.</span><span class="n">tickets_cnt</span> <span class="o">-</span> <span class="n">COMP</span><span class="p">.</span><span class="n">tickets_cnt</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="k">AS</span> <span class="n">tickets_cnt_diff</span>
      <span class="k">FROM</span>
         <span class="n">CTE_1w_ago_raw</span> <span class="n">MAIN</span>
      <span class="k">LEFT</span> <span class="k">JOIN</span>
         <span class="n">CTE_2w_ago_raw</span> <span class="n">COMP</span>
         <span class="k">ON</span> <span class="n">MAIN</span><span class="p">.</span><span class="n">openai_topic_2</span> <span class="o">=</span> <span class="n">COMP</span><span class="p">.</span><span class="n">openai_topic_2</span>
   <span class="p">)</span>
   <span class="k">SELECT</span>
      <span class="n">openai_topic_2</span><span class="p">,</span>
      <span class="n">tickets_cnt_1w_ago</span><span class="p">,</span>
      <span class="n">tickets_cnt_2w_ago</span><span class="p">,</span>
      <span class="n">tickets_cnt_diff</span>
   <span class="k">FROM</span>
      <span class="n">CTE_diff</span>
   <span class="k">WHERE</span>
      <span class="n">tickets_cnt_diff</span> <span class="o">=</span> <span class="p">(</span><span class="k">SELECT</span> <span class="k">MAX</span><span class="p">(</span><span class="n">tickets_cnt_diff</span><span class="p">)</span> <span class="k">FROM</span> <span class="n">CTE_diff</span><span class="p">)</span>
      <span class="k">AND</span> <span class="n">tickets_cnt_diff</span> <span class="o">&gt;</span> <span class="mi">0</span>
   <span class="k">ORDER</span> <span class="k">BY</span>
      <span class="mi">1</span>
</code></pre></div>    </div>
  </div>
</details>

<p>2) 슬랙 메시지 객체를 작성했습니다.</p>

<details>
<summary>코드 확인하기</summary>
<div>
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   <span class="n">df</span> <span class="o">=</span> <span class="n">bigquery_client</span><span class="p">.</span><span class="nf">query</span><span class="p">(</span><span class="n">query</span><span class="p">).</span><span class="nf">to_dataframe</span><span class="p">()</span>

   <span class="c1"># Slack 메시지 제목 만들기
</span>   <span class="n">message</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">'</span><span class="s">:phone: *Weekly Zendesk 요약* </span><span class="se">\n\n</span><span class="sh">'</span>
   <span class="n">message</span> <span class="o">+=</span> <span class="sa">f</span><span class="sh">'</span><span class="s">*지난 1주 가장 많이 증가한 고객 문의 주제들입니다.* </span><span class="se">\n</span><span class="sh">'</span>

   <span class="c1"># 만약 데이터가 존재하는 경우
</span>   <span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
      <span class="n">topics</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">openai_topic_2</span><span class="sh">'</span><span class="p">].</span><span class="nf">tolist</span><span class="p">()</span>
      <span class="n">tickets_cnt_1w_agos</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">tickets_cnt_1w_ago</span><span class="sh">'</span><span class="p">].</span><span class="nf">tolist</span><span class="p">()</span>
      <span class="n">tickets_cnt_diffs</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">tickets_cnt_diff</span><span class="sh">'</span><span class="p">].</span><span class="nf">tolist</span><span class="p">()</span>
      <span class="c1"># Slack 메시지 만들기
</span>      <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">topic</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">topics</span><span class="p">):</span>
         <span class="n">message</span> <span class="o">+=</span> <span class="sa">f</span><span class="sh">'</span><span class="s">- *</span><span class="si">{</span><span class="n">topic</span><span class="si">}</span><span class="s">*: 총 </span><span class="si">{</span><span class="n">tickets_cnt_1w_agos</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s">건 (전주 대비 +</span><span class="si">{</span><span class="n">tickets_cnt_diffs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s">) </span><span class="se">\n</span><span class="sh">'</span>

   <span class="c1"># 만약 데이터가 존재하지 않는 경우
</span>   <span class="k">else</span><span class="p">:</span>
      <span class="n">message</span> <span class="o">+=</span> <span class="sa">f</span><span class="sh">'</span><span class="s">- *증가한 주제가 하나도 없어요.*:smile: </span><span class="se">\n\n</span><span class="sh">'</span>
</code></pre></div>    </div>
  </div>
</details>

<p>3) 매주 월요일 9:00 AM KST에 다음과 같은 슬랙 알림이 발송되었습니다.</p>

<p><img src="/assets/2024-07-20-voc-dashboard/10-ko.png" alt="" /></p>

<hr />

<h1 id="5-results">5. Results</h1>

<blockquote>
  <ol>
    <li><strong>비용 절약</strong>
      <ul>
        <li>월 $300 비용의 외부 서비스를 도입하지 않고도, 내부 개발을 통해 월 $25 비용 만으로 문제를 해소했습니다.</li>
      </ul>
    </li>
    <li><strong>시간 절감</strong>
      <ul>
        <li>사내 구성원 분들의 VOC 팔로업, 이슈 식별과 대응 속도를 향상시켰습니다.</li>
      </ul>
    </li>
  </ol>
</blockquote>

<h3 id="1-비용-절약">1. <strong>비용 절약</strong></h3>

<p>결론) 내부 개발을 통해 매월 약 $275 기회 비용을 제거할 수 있었습니다.</p>

<table>
  <tbody>
    <tr>
      <td> </td>
      <td><strong>외부 VOC 분석 서비스</strong></td>
      <td><strong>내부 개발</strong></td>
    </tr>
    <tr>
      <td>월간 비용</td>
      <td><code class="language-plaintext highlighter-rouge">$300</code></td>
      <td><code class="language-plaintext highlighter-rouge">$25</code></td>
    </tr>
  </tbody>
</table>

<p>1) 외부 VOC 서비스</p>
<ul>
  <li>도입을 고려 중이었던 <a href="https://www.syncly.kr/">syncly</a>의 경우, 최소 월 $299의 비용이 요구되었습니다.</li>
</ul>

<p><img src="/assets/2024-07-20-voc-dashboard/8.png" alt="" /></p>

<p>2) 내부 개발</p>
<ul>
  <li>그러나 직접 내부 개발은 다음과 같은 비용이 요구되었습니다.</li>
</ul>

<table>
  <tbody>
    <tr>
      <td><strong>리소스</strong></td>
      <td><strong>월간 비용</strong></td>
    </tr>
    <tr>
      <td>1. OpenAI API</td>
      <td><code class="language-plaintext highlighter-rouge">$25</code></td>
    </tr>
    <tr>
      <td>2. BigQuery 스토리지</td>
      <td>거의 없음</td>
    </tr>
    <tr>
      <td>3. BigQuery 쿼리 사용</td>
      <td>미미함</td>
    </tr>
    <tr>
      <td>4. VM Instance 운영</td>
      <td>기존 인스턴스를 사용하므로 한계비용 적음</td>
    </tr>
    <tr>
      <td><strong>TOTAL</strong></td>
      <td><code class="language-plaintext highlighter-rouge">$25</code> + e</td>
    </tr>
  </tbody>
</table>

<p><img src="/assets/2024-07-20-voc-dashboard/9.png" alt="ㅇㅇㅇ" /></p>
<blockquote>
  <p>일별 OpenAI API 비용</p>
</blockquote>

<h3 id="2-시간-절감">2. <strong>시간 절감</strong></h3>

<p>1) Redash VOC 대시보드 (주제 분류)</p>
<ul>
  <li>사내 구성원 분들의 VOC 이슈 <u>식별 편의성</u>을 향상시켰습니다.</li>
</ul>

<p>2) Redash VOC 대시보드 (요약)</p>
<ul>
  <li>사내 구성원 분들의 VOC <u>팔로업 속도</u>를 향상시키고 VOC에 대한 <u>접근성</u>을 개선했습니다.</li>
</ul>

<p>3) 슬랙 알림 봇</p>
<ul>
  <li>매주 문의 수가 가장 많이 늘어난 주제를 사내 구성원 분들에게 공유함으로써, 이슈 <u>식별과 대응 속도</u>를 향상시키고 동일한 <u>맥락을 공유</u>하는 데 기여했습니다.</li>
</ul>

<hr />

<h2 id="published-by-joshua-kim"><em>Published by</em> Joshua Kim</h2>
<p><img src="/assets/profile/joshua-profile.png" alt="Joshua Kim" /></p>]]></content><author><name></name></author><category term="Korean" /><category term="Python" /><category term="BigQuery" /><category term="Redash" /><category term="Data Visualization" /><category term="LLM" /><summary type="html"><![CDATA[“사내 구성원 분들이 젠데스크 고객 문의 내역 팔로업에 어려움을 겪고 있다는 사실을 공유 받아, 이를 해결하기 위해 Redash VOC 대시보드를 구축했습니다. 젠데스크 데이터를 자동으로 수집하고 전처리한 후, OpenAI API를 활용해 고객 문의 내역을 주제별로 분류하고 요약했습니다. 추가적으로, 매주 월요일마다 가장 많이 증가한 문의 주제를 슬랙으로 알림을 보내어, 고객 이슈를 효율적으로 식별하고 대응할 수 있도록 기여했습니다. 결과적으로 매월 약 $275 기회 비용을 제거할 수 있었으며, 사내 구성원 분들의 VOC 팔로업 시간을 감소시키는 성과를 얻었습니다.”]]></summary></entry><entry><title type="html">Rolling MAU 쿼리 최적화</title><link href="http://localhost:4000/rolling-mau-ko/" rel="alternate" type="text/html" title="Rolling MAU 쿼리 최적화" /><published>2024-06-30T00:00:00+09:00</published><updated>2024-06-30T00:00:00+09:00</updated><id>http://localhost:4000/rolling-mau-ko</id><content type="html" xml:base="http://localhost:4000/rolling-mau-ko/"><![CDATA[<blockquote>
  <p>“Rolling MAU와 같은 복잡한 Rolling Metrics를 계산하는 데는 대규모 데이터셋에서 막대한 시간과 비용이 소요될 수 있습니다. 기존 쿼리로 6시간 이상 걸리던 작업을 쿼리 최적화와 B-tree Index를 통해 6초로 단축했습니다. 이 과정에서 불필요한 메모리 사용을 줄이고 쿼리 성능을 극대화하여 데이터 처리 효율성을 크게 향상시켰습니다. 이를 통해 기업이 Rolling MAU 지표를 효율적으로 관리하고 인프라 비용을 절감하는 데 기여할 수 있었습니다.”</p>
</blockquote>

<hr />

<h1 id="목차">목차</h1>
<ol>
  <li>STAR Summary</li>
  <li>Situation</li>
  <li>Tasks</li>
  <li>Actions</li>
  <li>Results</li>
</ol>

<hr />

<h1 id="1-star-summary">1. STAR Summary</h1>

<h3 id="situation">Situation</h3>
<ul>
  <li>회사는 Rolling MAU와 같은 복잡한 Rolling Metrics를 계산하고 관리하는 데 <strong>막대한 비용과 시간을 소모</strong>하고 있었습니다. 특히, 사용자가 많아질수록 이 지표를 효율적으로 추출하는 것이 더욱 어려워질 것으로 예상되었으며, 실제로 기존 쿼리로는 Rolling MAU를 계산하는 데 <strong>6시간</strong> 이상 소요되었습니다. Incremental Strategy를 적용하더라도 <strong>2시간</strong>이 걸리는 상황이었습니다.</li>
</ul>

<h3 id="tasks">Tasks</h3>
<ul>
  <li>저는 Rolling MAU 지표를 효율적으로 계산할 수 있는 쿼리를 설계하여 실행 시간을 획기적으로 줄이고 인프라 비용을 절감하는 것을 목표로 삼았습니다. 이를 위해 <strong>쿼리 최적화를 통해 연산 비용을 낮추고 성능을 향상시키는 것</strong>이 필요했습니다.</li>
</ul>

<h3 id="actions">Actions</h3>

<ol>
  <li><strong>B-tree Index 생성</strong>
    <ul>
      <li>Rolling MAU를 계산할 때 가장 많은 시간이 소요되는 <code class="language-plaintext highlighter-rouge">date</code> 칼럼에 B-tree Index를 생성하여 스캔 속도를 향상시키고자 했습니다. 이를 통해 아래 조건에서 <strong>비교 연산의 부담을 줄이고자 한 것</strong>입니다.
        <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">SUB</span><span class="p">.</span><span class="nb">date</span> <span class="k">BETWEEN</span> <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span> <span class="o">-</span> <span class="n">INTERVAL</span> <span class="s1">'29 DAYS'</span> <span class="k">AND</span> <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span>
</code></pre></div>        </div>
      </li>
    </ul>
  </li>
  <li><strong>쿼리 최적화</strong>
    <ul>
      <li>B-tree Index 생성 이후에도 성능 개선이 충분하지 않았습니다. 이에 따라 메모리 사용량을 줄이기 위해 쿼리에서 필요한 컬럼만 불러오는 방식으로 변경했습니다. MAIN 테이블에서 모든 행을 불러오는 대신, 아래와 같이 <strong>필요한 칼럼만 불러와 SELF JOIN 과정에서 기하급수적인 메모리 사용량을 대폭 줄였습니다.</strong>
        <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">SELECT</span> <span class="k">DISTINCT</span> <span class="nb">date</span> <span class="k">FROM</span> <span class="n">daily_activated_users</span>
</code></pre></div>        </div>
      </li>
    </ul>
  </li>
</ol>

<h3 id="results">Results</h3>
<ul>
  <li>이 최적화 전략 덕분에 Rolling MAU 계산 <strong>쿼리의 실행 시간이 6시간에서 6초로 대폭 단축</strong>되었습니다. 이로 인해 데이터 처리 효율성이 극적으로 향상되었고, 쿼리 실행 시간과 인프라 비용 측면에서도 큰 절감 효과를 얻을 수 있었습니다. 이러한 성과는 기업이 Rolling Metrics와 같은 복잡한 지표를 보다 효율적으로 관리할 수 있도록 도왔습니다.</li>
</ul>

<hr />

<h1 id="2-situation">2. Situation</h1>

<blockquote>
  <ul>
    <li>회사는 Rolling MAU와 같은 복잡한 Rolling Metrics를 계산하고 관리하는 데 <strong>막대한 비용과 시간을 소모</strong>하고 있었습니다. 특히, 사용자가 많아질수록 이 지표를 효율적으로 추출하는 것이 더욱 어려워질 것으로 예상되었으며, 실제로 기존 쿼리로는 Rolling MAU를 계산하는 데 <strong>6시간</strong> 이상 소요되었습니다. Incremental Strategy를 적용하더라도 <strong>2시간</strong>이 걸리는 상황이었습니다.</li>
  </ul>
</blockquote>

<h3 id="구체적인-문제-상황">구체적인 문제 상황</h3>
<ul>
  <li>회사가 운영하는 프로덕트는 시간이 지남에 따라 사용자 수가 급증하고 있었으며, 데이터 웨어하우스 관점에서 최적화가 중요한 이슈로 떠오르고 있었습니다. 특히, Rolling MAU는 프로덕트 요금제의 기준으로 필수적인 지표 역할을 했습니다. 그러나 Rolling MAU의 계산 과정은 매우 복잡하고 연산 비용이 높아 큰 고민이 되었습니다.</li>
</ul>

<h3 id="기존-쿼리-분석-및-병목-지점-파악">기존 쿼리 분석 및 병목 지점 파악</h3>

<h5 id="1-기존-쿼리">(1) 기존 쿼리</h5>
<ul>
  <li>초기에 작성된 쿼리는 각 날짜별로 최근 30일 동안의 활성 사용자 수를 계산하기 위해 SELF JOIN을 사용했습니다. 이 방식은 모든 날짜에 대해 연관된 데이터를 반복적으로 조회하고 계산하는 과정에서 O(n²)의 연산 복잡도를 가지며, 사용자가 많아질수록 연산 비용이 기하급수적으로 증가하는 문제점을 지니고 있었습니다. 실제로, 이 쿼리를 Full Scan으로 실행할 때 6시간 이상 소요되었으며, Incremental Strategy로 실행해도 2시간 가까이 걸렸습니다.
    <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="k">SELECT</span>
    <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span><span class="p">,</span>
    <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="n">SUB</span><span class="p">.</span><span class="n">user_id</span><span class="p">)</span> <span class="k">AS</span> <span class="n">rolling_mau</span>
 <span class="k">FROM</span>
    <span class="n">daily_activated_users</span> <span class="n">MAIN</span>
 <span class="k">LEFT</span> <span class="k">JOIN</span>
    <span class="n">daily_activated_users</span> <span class="n">SUB</span>
    <span class="k">ON</span> <span class="n">SUB</span><span class="p">.</span><span class="nb">date</span> <span class="k">BETWEEN</span> <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span> <span class="o">-</span> <span class="n">INTERVAL</span> <span class="s1">'29 DAYS'</span> <span class="k">AND</span> <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span>
 <span class="k">GROUP</span> <span class="k">BY</span>
    <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span>
 <span class="k">ORDER</span> <span class="k">BY</span>
    <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span>
</code></pre></div>    </div>
  </li>
</ul>

<h5 id="2-기존-쿼리-분석-rolling-2-day-active-users-사례">(2) 기존 쿼리 분석 (<code class="language-plaintext highlighter-rouge">Rolling 2-day Active Users 사례</code>)</h5>

<ul>
  <li><strong>A</strong>. 먼저, 아래 과정을 통해 <code class="language-plaintext highlighter-rouge">daily_activated_users</code> 테이블의 데이터를 가져옵니다.
    <details>
 <summary>자세히 보기</summary>
 <div>
        <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="k">FROM</span>
       <span class="n">daily_activated_users</span> <span class="n">MAIN</span>
</code></pre></div>        </div>

        <p><img src="/assets/2024-06-30-rolling-mau/1.webp" alt="Joshua Kim" /></p>
      </div>
 </details>
  </li>
  <li><strong>B</strong>. 그런 후, SELF JOIN을 통해 각 일별 Recent 2-day 활성 사용자 목록을 모두 이어 붙입니다.
    <details>
 <summary>자세히 보기</summary>
 <div>
        <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="k">FROM</span>
       <span class="n">daily_activated_users</span> <span class="n">MAIN</span>
    <span class="k">LEFT</span> <span class="k">JOIN</span>
       <span class="n">daily_activated_users</span> <span class="n">SUB</span>
       <span class="k">ON</span> <span class="n">SUB</span><span class="p">.</span><span class="nb">date</span> <span class="k">BETWEEN</span> <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span> <span class="o">-</span> <span class="n">INTERVAL</span> <span class="s1">'1 DAYS'</span> <span class="k">AND</span> <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span>
</code></pre></div>        </div>

        <p><img src="/assets/2024-06-30-rolling-mau/2.webp" alt="Joshua Kim" /></p>
      </div>
 </details>
  </li>
  <li><strong>C</strong>. 이제 <code class="language-plaintext highlighter-rouge">MAIN.date</code>를 기준으로 그룹화하여 순수 사용자 수를 계산합니다.
    <details>
 <summary>자세히 보기</summary>
 <div>
        <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="k">SELECT</span>
       <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span><span class="p">,</span>
       <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="n">SUB</span><span class="p">.</span><span class="n">user_id</span><span class="p">)</span> <span class="k">AS</span> <span class="n">rolling_mau</span>
    <span class="k">FROM</span>
       <span class="n">daily_activated_users</span> <span class="n">MAIN</span>
    <span class="k">LEFT</span> <span class="k">JOIN</span>
       <span class="n">daily_activated_users</span> <span class="n">SUB</span>
       <span class="k">ON</span> <span class="n">SUB</span><span class="p">.</span><span class="nb">date</span> <span class="k">BETWEEN</span> <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span> <span class="o">-</span> <span class="n">INTERVAL</span> <span class="s1">'29 DAYS'</span> <span class="k">AND</span> <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span>
    <span class="k">GROUP</span> <span class="k">BY</span>
       <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span>
</code></pre></div>        </div>

        <p><img src="/assets/2024-06-30-rolling-mau/3.webp" alt="Joshua Kim" /></p>
      </div>
 </details>
  </li>
  <li>정확한 병목 지점 파악
    <ul>
      <li><strong>연산 시간이 가장 많이 소모되는 지점은 단계 B입니다.</strong> 이 단계에서는 각 행마다 Recent 2-day Window에 해당하는 모든 행을 이어 붙이는 과정이 이루어집니다. 예를 들어, 1월 2일의 행 수가 10개이고, Recent 2-day Window에 해당하는 행이 100개라면, 총 1,000개의 행(10*100)을 이어 붙여야 하므로 메모리 사용량이 급격히 증가합니다. 즉, SELF JOIN을 통해 각 일별 Recent 2-day 활성 사용자 목록을 이어 붙이는 과정이 Scan 시간과 메모리 사용량을 상당히 많이 소모하는 원인이었습니다.</li>
      <li>이러한 상황에서, Rolling MAU 지표를 보다 효율적으로 개선하고 쿼리 실행 시간을 대폭 줄이기 위한 최적화가 시급한 과제로 떠올랐습니다. 또한, 기존 인프라로는 이와 같은 연산 비용을 지속적으로 감당하는 것이 비효율적이었기 때문에, 최적화를 통해 인프라 비용도 절감할 필요가 있었습니다. 즉, 비용과 시간을 절감할 수 있는 솔루션을 찾는 것이 절실한 상황이었습니다.</li>
    </ul>
  </li>
</ul>

<hr />

<h1 id="3-tasks">3. Tasks</h1>
<blockquote>
  <ul>
    <li>저는 Rolling MAU 지표를 효율적으로 계산할 수 있는 쿼리를 설계하여 실행 시간을 획기적으로 줄이고 인프라 비용을 절감하는 것을 목표로 삼았습니다. 이를 위해 <strong>쿼리 최적화를 통해 연산 비용을 낮추고 성능을 향상시키는 것</strong>이 필요했습니다.</li>
  </ul>
</blockquote>

<h3 id="1-쿼리-실행-시간-단축"><strong>1. 쿼리 실행 시간 단축</strong></h3>
<ul>
  <li>Rolling MAU를 계산하는 기존 쿼리는 O(n²)의 연산 복잡도를 가지고 있었기 때문에, 실행 시간이 6시간 이상 걸렸습니다. 이를 크게 단축하여 실시간 분석에 가까운 성능을 구현하는 것이 최우선 과제였습니다. 실행 시간을 초 단위로 줄여야만, 빠르게 변화하는 사용자 활동 데이터를 분석하고 즉각적으로 대응할 수 있는 환경을 마련할 수 있었습니다.</li>
</ul>

<h3 id="2-인프라-비용-절감"><strong>2. 인프라 비용 절감</strong></h3>
<ul>
  <li>쿼리 실행 시 사용되는 메모리와 처리 능력은 비용으로 직결됩니다. 기존 쿼리는 데이터 양이 증가함에 따라 메모리 사용량도 기하급수적으로 늘어나고, 이로 인해 인프라 비용이 급증하는 문제가 있었습니다. 따라서, 메모리 사용량을 줄이고 인프라 자원을 효율적으로 활용할 수 있는 쿼리 구조를 설계하는 것이 필요했습니다.</li>
</ul>

<hr />

<h1 id="4-actions">4. Actions</h1>

<blockquote>
  <ol>
    <li><strong>B-tree Index 생성</strong>
      <ul>
        <li>Rolling MAU를 계산할 때 가장 많은 시간이 소요되는 <code class="language-plaintext highlighter-rouge">date</code> 칼럼에 B-tree Index를 생성하여 스캔 속도를 향상시키고자 했습니다. 이를 통해 아래 조건에서 <strong>비교 연산의 부담을 줄이고자 한 것</strong>입니다.
          <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">SUB</span><span class="p">.</span><span class="nb">date</span> <span class="k">BETWEEN</span> <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span> <span class="o">-</span> <span class="n">INTERVAL</span> <span class="s1">'29 DAYS'</span> <span class="k">AND</span> <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span>
</code></pre></div>          </div>
        </li>
      </ul>
    </li>
    <li><strong>쿼리 최적화</strong>
      <ul>
        <li>B-tree Index 생성 이후에도 성능 개선이 충분하지 않았습니다. 이에 따라 메모리 사용량을 줄이기 위해 쿼리에서 필요한 컬럼만 불러오는 방식으로 변경했습니다. MAIN 테이블에서 모든 행을 불러오는 대신, 아래와 같이 <strong>필요한 칼럼만 불러와 SELF JOIN 과정에서 기하급수적인 메모리 사용량을 대폭 줄였습니다.</strong>
          <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">SELECT</span> <span class="k">DISTINCT</span> <span class="nb">date</span> <span class="k">FROM</span> <span class="n">daily_activated_users</span>
</code></pre></div>          </div>
        </li>
      </ul>
    </li>
  </ol>
</blockquote>

<h3 id="1-b-tree-index-생성"><strong>1. B-tree Index 생성</strong></h3>
<ul>
  <li>병목 지점이었던 <code class="language-plaintext highlighter-rouge">date</code> 칼럼 비교 연산의 성능을 향상시키기 위해, <code class="language-plaintext highlighter-rouge">date</code> 칼럼에 <strong>B-tree Index</strong>를 생성했습니다.
    <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="k">CREATE</span> <span class="k">INDEX</span> <span class="n">idx_dates</span> <span class="k">ON</span> <span class="n">daily_activated_users</span> <span class="k">USING</span> <span class="n">btree</span> <span class="p">(</span><span class="nb">date</span><span class="p">);</span>
</code></pre></div>    </div>
  </li>
  <li>이를 통해, 아래의 <code class="language-plaintext highlighter-rouge">date</code> 검색 속도를 개선하여 쿼리 시간이 소폭 개선되었으나, 여전히 메모리 사용량과 실행 시간이 과도하게 많이 소요되고 있었습니다.
    <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="k">FROM</span>
    <span class="n">daily_activated_users</span> <span class="n">MAIN</span>
 <span class="k">LEFT</span> <span class="k">JOIN</span>
    <span class="n">daily_activated_users</span> <span class="n">SUB</span>
    <span class="k">ON</span> <span class="n">SUB</span><span class="p">.</span><span class="nb">date</span> <span class="k">BETWEEN</span> <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span> <span class="o">-</span> <span class="n">INTERVAL</span> <span class="s1">'29 DAYS'</span> <span class="k">AND</span> <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span>
</code></pre></div>    </div>
  </li>
</ul>

<h3 id="2-쿼리-최적화"><strong>2. 쿼리 최적화</strong></h3>
<ul>
  <li>안타깝게도 <code class="language-plaintext highlighter-rouge">date</code> 칼럼을 Index로 생성했음에도 불구하고 쿼리 실행 시간은 여전히 과도하게 많이 소요되고 있었습니다.</li>
  <li><strong>즉, 핵심 문제는 <code class="language-plaintext highlighter-rouge">date</code> 칼럼 비교 연산 과정이라기보다는, SELF JOIN 과정의 기하급수적인 메모리 사용 과정이었던 것입니다.</strong> 따라서 메모리 사용량을 줄이기 위해 반드시 필요한 칼럼만을 불러오는 방법을 고안했습니다.
    <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="k">SELECT</span>
    <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span><span class="p">,</span>
    <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="n">SUB</span><span class="p">.</span><span class="n">user_id</span><span class="p">)</span> <span class="k">AS</span> <span class="n">rolling_mau</span>
 <span class="k">FROM</span>
    <span class="p">(</span><span class="k">SELECT</span> <span class="k">DISTINCT</span> <span class="nb">date</span> <span class="k">FROM</span> <span class="n">daily_activated_users</span><span class="p">)</span> <span class="n">MAIN</span> <span class="c1">-- 변경한 부분</span>
 <span class="k">LEFT</span> <span class="k">JOIN</span>
    <span class="n">daily_activated_users</span> <span class="n">SUB</span>
    <span class="k">ON</span> <span class="n">SUB</span><span class="p">.</span><span class="nb">date</span> <span class="k">BETWEEN</span> <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span> <span class="o">-</span> <span class="n">INTERVAL</span> <span class="s1">'29 DAYS'</span> <span class="k">AND</span> <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span>
 <span class="k">GROUP</span> <span class="k">BY</span>
    <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span>
</code></pre></div>    </div>
  </li>
  <li>이를 통해 SELF JOIN의 데이터 처리량을 드라마틱하게 줄여 메모리 사용량을 대폭 감소시켰습니다.</li>
</ul>

<hr />

<h1 id="5-results">5. Results</h1>
<blockquote>
  <ul>
    <li>이 최적화 전략 덕분에 Rolling MAU 계산 <strong>쿼리의 실행 시간이 6시간에서 6초로 대폭 단축</strong>되었습니다. 이로 인해 데이터 처리 효율성이 극적으로 향상되었고, 쿼리 실행 시간과 인프라 비용 측면에서도 큰 절감 효과를 얻을 수 있었습니다. 이러한 성과는 기업이 Rolling Metrics와 같은 복잡한 지표를 보다 효율적으로 관리할 수 있도록 도왔습니다.</li>
  </ul>
</blockquote>

<h3 id="쿼리-실행-시간의-극적-단축"><strong>쿼리 실행 시간의 극적 단축</strong></h3>
<ul>
  <li>Rolling MAU는 프로덕트의 요금제 기준으로 기획되었기 때문에, 본 문제는 상당히 중요한 이슈였습니다.
    <ul>
      <li><strong>최적화 이전</strong>: Rolling MAU를 계산하는 쿼리가 약 6시간 소요</li>
      <li><strong>최적화 이후</strong>: 동일한 작업이 단 6초 만에 완료</li>
    </ul>
  </li>
  <li>이렇게 단축된 실행 시간 덕분에 더욱 안정적인 프로덕트 운영이 가능해졌으며 요금제 기준의 대체 방법을 고민할 수도 있었던 기업의 기회비용을 절약할 수 있었습니다.</li>
</ul>

<hr />

<h2 id="published-by-joshua-kim"><em>Published by</em> Joshua Kim</h2>
<p><img src="/assets/profile/joshua-profile.png" alt="Joshua Kim" /></p>]]></content><author><name></name></author><category term="Korean" /><category term="PostgreSQL" /><summary type="html"><![CDATA[“Rolling MAU와 같은 복잡한 Rolling Metrics를 계산하는 데는 대규모 데이터셋에서 막대한 시간과 비용이 소요될 수 있습니다. 기존 쿼리로 6시간 이상 걸리던 작업을 쿼리 최적화와 B-tree Index를 통해 6초로 단축했습니다. 이 과정에서 불필요한 메모리 사용을 줄이고 쿼리 성능을 극대화하여 데이터 처리 효율성을 크게 향상시켰습니다. 이를 통해 기업이 Rolling MAU 지표를 효율적으로 관리하고 인프라 비용을 절감하는 데 기여할 수 있었습니다.”]]></summary></entry><entry><title type="html">Rolling MAU Query Optimization</title><link href="http://localhost:4000/rolling-mau-en/" rel="alternate" type="text/html" title="Rolling MAU Query Optimization" /><published>2024-06-30T00:00:00+09:00</published><updated>2024-06-30T00:00:00+09:00</updated><id>http://localhost:4000/rolling-mau-en</id><content type="html" xml:base="http://localhost:4000/rolling-mau-en/"><![CDATA[<blockquote>
  <p>“Calculating complex Rolling Metrics like Rolling MAU can consume significant time and cost on large datasets. A task that previously took over 6 hours with the original query was reduced to 6 seconds through query optimization and the use of a B-tree Index. This process significantly enhanced data processing efficiency by minimizing unnecessary memory usage and maximizing query performance. As a result, the company was able to manage Rolling MAU metrics more efficiently, contributing to infrastructure cost savings.”</p>
</blockquote>

<hr />

<h1 id="table-of-contents">Table of Contents</h1>
<ol>
  <li>STAR Summary</li>
  <li>Situation</li>
  <li>Tasks</li>
  <li>Actions</li>
  <li>Results</li>
</ol>

<hr />

<h1 id="1-star-summary">1. STAR Summary</h1>

<h3 id="situation">Situation</h3>
<ul>
  <li>The company was consuming <strong>significant time and costs</strong> to calculate and manage complex Rolling Metrics like Rolling MAU. As the number of users increased, it was expected to become even more challenging to extract this metric efficiently, and indeed, the original query took more than <strong>6 hours</strong> to calculate Rolling MAU. Even with an Incremental Strategy applied, it still took <strong>2 hours</strong>.</li>
</ul>

<h3 id="tasks">Tasks</h3>
<ul>
  <li>My goal was to design a query that could calculate the Rolling MAU metric efficiently, drastically reduce execution time, and lower infrastructure costs. This required <strong>query optimization to reduce computational costs and improve performance</strong>.</li>
</ul>

<h3 id="actions">Actions</h3>

<ol>
  <li><strong>Creating a B-tree Index</strong>
    <ul>
      <li>To speed up the most time-consuming process of calculating Rolling MAU, I created a B-tree Index on the <code class="language-plaintext highlighter-rouge">date</code> column to enhance scan speed. This was intended to <strong>reduce the burden of comparison operations</strong> under the following condition:
        <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">SUB</span><span class="p">.</span><span class="nb">date</span> <span class="k">BETWEEN</span> <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span> <span class="o">-</span> <span class="n">INTERVAL</span> <span class="s1">'29 DAYS'</span> <span class="k">AND</span> <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span>
</code></pre></div>        </div>
      </li>
    </ul>
  </li>
  <li><strong>Query Optimization</strong>
    <ul>
      <li>Even after creating the B-tree Index, the performance improvement was not sufficient. Therefore, I changed the query to fetch only the necessary columns to reduce memory usage. Instead of fetching all rows from the MAIN table, I fetched only the necessary columns, <strong>significantly reducing the exponential memory usage during the SELF JOIN process.</strong>
        <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">SELECT</span> <span class="k">DISTINCT</span> <span class="nb">date</span> <span class="k">FROM</span> <span class="n">daily_activated_users</span>
</code></pre></div>        </div>
      </li>
    </ul>
  </li>
</ol>

<h3 id="results">Results</h3>
<ul>
  <li>Thanks to this optimization strategy, the execution time for the Rolling MAU calculation query was <strong>reduced from 6 hours to 6 seconds.</strong> This led to a dramatic improvement in data processing efficiency and significant cost savings in query execution time and infrastructure. These results helped the company manage complex metrics like Rolling Metrics more efficiently.</li>
</ul>

<hr />

<h1 id="2-situation">2. Situation</h1>

<blockquote>
  <ul>
    <li>The company was consuming <strong>significant time and costs</strong> to calculate and manage complex Rolling Metrics like Rolling MAU. As the number of users increased, it was expected to become even more challenging to extract this metric efficiently, and indeed, the original query took more than <strong>6 hours</strong> to calculate Rolling MAU. Even with an Incremental Strategy applied, it still took <strong>2 hours</strong>.</li>
  </ul>
</blockquote>

<h3 id="specific-problem-situation">Specific Problem Situation</h3>
<ul>
  <li>The company’s product saw a rapid increase in users over time, making optimization a critical issue from a data warehouse perspective. The Rolling MAU, a key metric for product pricing, played an essential role. However, the calculation process for Rolling MAU was very complex and computationally expensive, which posed a significant challenge.</li>
</ul>

<h3 id="analysis-of-the-existing-query-and-identification-of-bottlenecks">Analysis of the Existing Query and Identification of Bottlenecks</h3>

<h5 id="1-the-existing-query">(1) The Existing Query</h5>
<ul>
  <li>The initial query used a SELF JOIN to calculate the number of active users over the last 30 days for each date. This approach had a computational complexity of O(n²) because it repeatedly retrieved and calculated related data for each date, causing an exponential increase in computation cost as the number of users grew. In practice, this query took more than 6 hours to execute with a Full Scan, and nearly 2 hours even with an Incremental Strategy.
    <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="k">SELECT</span>
    <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span><span class="p">,</span>
    <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="n">SUB</span><span class="p">.</span><span class="n">user_id</span><span class="p">)</span> <span class="k">AS</span> <span class="n">rolling_mau</span>
 <span class="k">FROM</span>
    <span class="n">daily_activated_users</span> <span class="n">MAIN</span>
 <span class="k">LEFT</span> <span class="k">JOIN</span>
    <span class="n">daily_activated_users</span> <span class="n">SUB</span>
    <span class="k">ON</span> <span class="n">SUB</span><span class="p">.</span><span class="nb">date</span> <span class="k">BETWEEN</span> <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span> <span class="o">-</span> <span class="n">INTERVAL</span> <span class="s1">'29 DAYS'</span> <span class="k">AND</span> <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span>
 <span class="k">GROUP</span> <span class="k">BY</span>
    <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span>
 <span class="k">ORDER</span> <span class="k">BY</span>
    <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span>
</code></pre></div>    </div>
  </li>
</ul>

<h5 id="2-analysis-of-the-existing-query-rolling-2-day-active-users-example">(2) Analysis of the Existing Query (<code class="language-plaintext highlighter-rouge">Rolling 2-day Active Users Example</code>)</h5>

<ul>
  <li><strong>A</strong>. First, the <code class="language-plaintext highlighter-rouge">daily_activated_users</code> table data is retrieved through the following process:
    <details>
 <summary>View code</summary>
 <div>
        <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="k">FROM</span>
       <span class="n">daily_activated_users</span> <span class="n">MAIN</span>
</code></pre></div>        </div>

        <p><img src="/assets/2024-06-30-rolling-mau/1.webp" alt="Joshua Kim" /></p>
      </div>
 </details>
  </li>
  <li><strong>B</strong>. Then, a SELF JOIN is performed to concatenate the list of active users for the recent 2-day period for each day.
    <details>
 <summary>View code</summary>
 <div>
        <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="k">FROM</span>
       <span class="n">daily_activated_users</span> <span class="n">MAIN</span>
    <span class="k">LEFT</span> <span class="k">JOIN</span>
       <span class="n">daily_activated_users</span> <span class="n">SUB</span>
       <span class="k">ON</span> <span class="n">SUB</span><span class="p">.</span><span class="nb">date</span> <span class="k">BETWEEN</span> <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span> <span class="o">-</span> <span class="n">INTERVAL</span> <span class="s1">'1 DAYS'</span> <span class="k">AND</span> <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span>
</code></pre></div>        </div>

        <p><img src="/assets/2024-06-30-rolling-mau/2.webp" alt="Joshua Kim" /></p>
      </div>
 </details>
  </li>
  <li><strong>C</strong>. Now, the users are grouped by <code class="language-plaintext highlighter-rouge">MAIN.date</code> to calculate the unique number of users.
    <details>
 <summary>View code</summary>
 <div>
        <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="k">SELECT</span>
       <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span><span class="p">,</span>
       <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="n">SUB</span><span class="p">.</span><span class="n">user_id</span><span class="p">)</span> <span class="k">AS</span> <span class="n">rolling_mau</span>
    <span class="k">FROM</span>
       <span class="n">daily_activated_users</span> <span class="n">MAIN</span>
    <span class="k">LEFT</span> <span class="k">JOIN</span>
       <span class="n">daily_activated_users</span> <span class="n">SUB</span>
       <span class="k">ON</span> <span class="n">SUB</span><span class="p">.</span><span class="nb">date</span> <span class="k">BETWEEN</span> <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span> <span class="o">-</span> <span class="n">INTERVAL</span> <span class="s1">'29 DAYS'</span> <span class="k">AND</span> <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span>
    <span class="k">GROUP</span> <span class="k">BY</span>
       <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span>
</code></pre></div>        </div>

        <p><img src="/assets/2024-06-30-rolling-mau/3.webp" alt="Joshua Kim" /></p>
      </div>
 </details>
  </li>
  <li>Identifying the Exact Bottleneck
    <ul>
      <li><strong>The most time-consuming part is step B.</strong> In this step, all rows corresponding to the Recent 2-day Window are concatenated for each row. For example, if there are 10 rows on January 2nd, and 100 rows corresponding to the Recent 2-day Window, a total of 1,000 rows (10*100) need to be concatenated, resulting in a rapid increase in memory usage. The process of concatenating the list of active users for each day through SELF JOIN was the primary cause of excessive scan time and memory usage.</li>
      <li>Given this situation, it became urgent to optimize the Rolling MAU metric to improve efficiency and significantly reduce query execution time. Additionally, continuing to bear such computational costs with the existing infrastructure was inefficient, necessitating optimization to reduce infrastructure costs. In other words, finding a solution to save both time and costs was crucial.</li>
    </ul>
  </li>
</ul>

<hr />

<h1 id="3-tasks">3. Tasks</h1>
<blockquote>
  <ul>
    <li>My goal was to design a query that could calculate the Rolling MAU metric efficiently, drastically reduce execution time, and lower infrastructure costs. This required <strong>query optimization to reduce computational costs and improve performance</strong>.</li>
  </ul>
</blockquote>

<h3 id="1-reducing-query-execution-time"><strong>1. Reducing Query Execution Time</strong></h3>
<ul>
  <li>The original query for calculating Rolling MAU had a computational complexity of O(n²), resulting in an execution time of over 6 hours. Drastically reducing this time to achieve near real-time performance was the top priority. Reducing execution time to the second level was essential to quickly analyze changing user activity data and respond immediately.</li>
</ul>

<h3 id="2-reducing-infrastructure-costs"><strong>2. Reducing Infrastructure Costs</strong></h3>
<ul>
  <li>Memory and processing power used during query execution directly translate to costs. The original query had an issue where memory usage increased exponentially as the data volume grew, leading to a sharp rise in infrastructure costs. Therefore, it was necessary to design a query structure that minimized memory usage and efficiently utilized infrastructure resources.</li>
</ul>

<hr />

<h1 id="4-actions">4. Actions</h1>

<blockquote>
  <ol>
    <li><strong>Creating a B-tree Index</strong>
      <ul>
        <li>To speed up the most time-consuming process of calculating Rolling MAU, I created a B-tree Index on the <code class="language-plaintext highlighter-rouge">date</code> column to enhance scan speed. This was intended to <strong>reduce the burden of comparison operations</strong> under the following condition:
          <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">SUB</span><span class="p">.</span><span class="nb">date</span> <span class="k">BETWEEN</span> <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span> <span class="o">-</span> <span class="n">INTERVAL</span> <span class="s1">'29 DAYS'</span> <span class="k">AND</span> <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span>
</code></pre></div>          </div>
        </li>
      </ul>
    </li>
    <li><strong>Query Optimization</strong>
      <ul>
        <li>Even after creating the B-tree Index, the performance improvement was not sufficient. Therefore, I changed the query to fetch only the necessary columns to reduce memory usage. Instead of fetching all rows from the MAIN table, I fetched only the necessary columns, <strong>significantly reducing the exponential memory usage during the SELF JOIN process.</strong>
          <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">SELECT</span> <span class="k">DISTINCT</span> <span class="nb">date</span> <span class="k">FROM</span> <span class="n">daily_activated_users</span>
</code></pre></div>          </div>
        </li>
      </ul>
    </li>
  </ol>
</blockquote>

<h3 id="1-creating-a-b-tree-index"><strong>1. Creating a B-tree Index</strong></h3>
<ul>
  <li>To improve the performance of comparison operations on the <code class="language-plaintext highlighter-rouge">date</code> column, which was the bottleneck, I created a <strong>B-tree Index</strong> on the <code class="language-plaintext highlighter-rouge">date</code> column.
    <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="k">CREATE</span> <span class="k">INDEX</span> <span class="n">idx_dates</span> <span class="k">ON</span> <span class="n">daily_activated_users</span> <span class="k">USING</span> <span class="n">btree</span> <span class="p">(</span><span class="nb">date</span><span class="p">);</span>
</code></pre></div>    </div>
  </li>
  <li>This improved the search speed for <code class="language-plaintext highlighter-rouge">date</code> and slightly reduced query time, but the memory usage and execution time were still excessively high.
    <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="k">FROM</span>
    <span class="n">daily_activated_users</span> <span class="n">MAIN</span>
 <span class="k">LEFT</span> <span class="k">JOIN</span>
    <span class="n">daily_activated_users</span> <span class="n">SUB</span>
    <span class="k">ON</span> <span class="n">SUB</span><span class="p">.</span><span class="nb">date</span> <span class="k">BETWEEN</span> <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span> <span class="o">-</span> <span class="n">INTERVAL</span> <span class="s1">'29 DAYS'</span> <span class="k">AND</span> <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span>
</code></pre></div>    </div>
  </li>
</ul>

<h3 id="2-query-optimization"><strong>2. Query Optimization</strong></h3>
<ul>
  <li>Unfortunately, even after creating an index on the <code class="language-plaintext highlighter-rouge">date</code> column, the query execution time was still excessively high.</li>
  <li><strong>The core issue was not the comparison operations on the <code class="language-plaintext highlighter-rouge">date</code> column, but rather the exponential memory usage during the SELF JOIN process.</strong> To reduce memory usage, I devised a method to retrieve only the necessary columns.
    <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="k">SELECT</span>
    <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span><span class="p">,</span>
    <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="n">SUB</span><span class="p">.</span><span class="n">user_id</span><span class="p">)</span> <span class="k">AS</span> <span class="n">rolling_mau</span>
 <span class="k">FROM</span>
    <span class="p">(</span><span class="k">SELECT</span> <span class="k">DISTINCT</span> <span class="nb">date</span> <span class="k">FROM</span> <span class="n">daily_activated_users</span><span class="p">)</span> <span class="n">MAIN</span> <span class="c1">-- The Modified Part</span>
 <span class="k">LEFT</span> <span class="k">JOIN</span>
    <span class="n">daily_activated_users</span> <span class="n">SUB</span>
    <span class="k">ON</span> <span class="n">SUB</span><span class="p">.</span><span class="nb">date</span> <span class="k">BETWEEN</span> <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span> <span class="o">-</span> <span class="n">INTERVAL</span> <span class="s1">'29 DAYS'</span> <span class="k">AND</span> <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span>
 <span class="k">GROUP</span> <span class="k">BY</span>
    <span class="n">MAIN</span><span class="p">.</span><span class="nb">date</span>
</code></pre></div>    </div>
  </li>
  <li>This drastically reduced the data processing load during SELF JOIN, significantly decreasing memory usage.</li>
</ul>

<hr />

<h1 id="5-results">5. Results</h1>
<blockquote>
  <ul>
    <li>Thanks to this optimization strategy, the execution time for the Rolling MAU calculation query was <strong>reduced from 6 hours to 6 seconds.</strong> This led to a dramatic improvement in data processing efficiency and significant cost savings in query execution time and infrastructure. These results helped the company manage complex metrics like Rolling Metrics more efficiently.</li>
  </ul>
</blockquote>

<h3 id="dramatic-reduction-in-query-execution-time"><strong>Dramatic Reduction in Query Execution Time</strong></h3>
<ul>
  <li>Since Rolling MAU was a key metric for product pricing, this issue was of significant importance.
    <ul>
      <li><strong>Before Optimization</strong>: The query for calculating Rolling MAU took about 6 hours</li>
      <li><strong>After Optimization</strong>: The same task was completed in just 6 seconds</li>
    </ul>
  </li>
  <li>The reduced execution time enabled more stable product operations and saved the company from considering alternative pricing methods, thereby saving opportunity costs.</li>
</ul>

<hr />

<h2 id="published-by-joshua-kim"><em>Published by</em> Joshua Kim</h2>
<p><img src="/assets/profile/joshua-profile.png" alt="Joshua Kim" /></p>]]></content><author><name></name></author><category term="English" /><category term="PostgreSQL" /><summary type="html"><![CDATA[“Calculating complex Rolling Metrics like Rolling MAU can consume significant time and cost on large datasets. A task that previously took over 6 hours with the original query was reduced to 6 seconds through query optimization and the use of a B-tree Index. This process significantly enhanced data processing efficiency by minimizing unnecessary memory usage and maximizing query performance. As a result, the company was able to manage Rolling MAU metrics more efficiently, contributing to infrastructure cost savings.”]]></summary></entry><entry><title type="html">IP 주소-국가 매핑 쿼리 최적화</title><link href="http://localhost:4000/ip-address-to-country-ko/" rel="alternate" type="text/html" title="IP 주소-국가 매핑 쿼리 최적화" /><published>2024-05-19T00:00:00+09:00</published><updated>2024-05-19T00:00:00+09:00</updated><id>http://localhost:4000/ip-address-to-country-ko</id><content type="html" xml:base="http://localhost:4000/ip-address-to-country-ko/"><![CDATA[<blockquote>
  <p>“데이터 웨어하우스에서 IP 주소를 사용해 사용자의 국가 정보를 매핑하는 작업을 최적화하였습니다. 기존 방식은 연산 시간이 길어 비효율적이었으나, 새로운 접근 방식을 통해 쿼리 실행 시간을 90% 감소시켰습니다.”</p>
</blockquote>

<hr />

<h1 id="목차">목차</h1>
<ol>
  <li>STAR Summary</li>
  <li>Situation</li>
  <li>Tasks</li>
  <li>Actions</li>
  <li>Results</li>
</ol>

<hr />

<h1 id="1-star-summary">1. STAR Summary</h1>

<h3 id="situation">Situation</h3>
<ul>
  <li>글로벌 서비스를 운영하는 환경에서 사용자의 접속 IP 주소를 기반으로 국가 정보를 매핑해야 했습니다. PostgreSQL을 사용하여 이 작업을 수행했으나, 기존 접근 방식으로 인해 성능 저하 문제가 발생했습니다. 기존 쿼리로는 너무 많은 시간이 소요되었으며, 이는 데이터 웨어하우스 운영에 큰 부담을 주고 있었습니다.</li>
</ul>

<h3 id="tasks">Tasks</h3>
<ul>
  <li>기존의 IP 주소 매핑 쿼리를 최적화하여 처리 시간을 대폭 줄이는 것이 목표였습니다. 이 작업을 통해 Transformation 과정의 효율성을 높여, 더 나은 데이터 웨어하우스 성능을 달성해야 했습니다. 구체적으로는 IP 주소 매핑 시 연산 과정을 최적화하고, JOIN 조건의 효율성을 높이는 것이 핵심 과제였습니다.</li>
</ul>

<h3 id="actions">Actions</h3>

<ol>
  <li><strong>기존 접근 방식 분석</strong>
    <ul>
      <li>기존 쿼리에서 <code class="language-plaintext highlighter-rouge">&lt;&lt;=</code> 연산자를 사용하여 CIDR 네트워크에 IP 주소를 매핑하는 방법을 사용했습니다. 이는 성능 저하의 주요 원인으로 파악되었습니다.</li>
    </ul>
  </li>
  <li><strong>새로운 테이블 생성</strong>
    <ul>
      <li>기존 테이블을 가공하여 <code class="language-plaintext highlighter-rouge">dim_ips_countries</code> 테이블을 생성했습니다.
        <ul>
          <li>이 테이블은 <code class="language-plaintext highlighter-rouge">start_ip</code>와 <code class="language-plaintext highlighter-rouge">end_ip</code> 칼럼을 가지고 있습니다.</li>
          <li>비교 연산의 효율성을 위해 IP 주소를 BIGINT 타입으로 변환했습니다.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>Index 생성</strong>
    <ul>
      <li><code class="language-plaintext highlighter-rouge">start_ip</code>와 <code class="language-plaintext highlighter-rouge">end_ip</code> 칼럼을 Index로 생성하여 검색 성능을 극대화했습니다.</li>
    </ul>
  </li>
  <li><strong>쿼리 최적화</strong>
    <ul>
      <li>기존의 <code class="language-plaintext highlighter-rouge">&lt;&lt;=</code> 연산자를 <code class="language-plaintext highlighter-rouge">BETWEEN</code> 연산자로 대체하여, IP 주소 비교 작업을 단순화하고 경량화된 연산을 수행하도록 쿼리를 재구성했습니다.</li>
    </ul>
  </li>
</ol>

<h3 id="results">Results</h3>
<ul>
  <li>최적화된 쿼리를 통해 실행 시간이 90% 대폭 감소하여 데이터 웨어하우스 성능 향상을 가져왔습니다.</li>
</ul>

<hr />

<h1 id="2-situation">2. Situation</h1>

<blockquote>
  <ul>
    <li>글로벌 서비스를 운영하는 환경에서 사용자의 접속 IP 주소를 기반으로 국가 정보를 매핑해야 했습니다. PostgreSQL을 사용하여 이 작업을 수행했으나, 기존 접근 방식으로 인해 성능 저하 문제가 발생했습니다. 기존 쿼리로는 너무 많은 시간이 소요되었으며, 이는 데이터 웨어하우스 운영에 큰 부담을 주고 있었습니다.</li>
  </ul>
</blockquote>

<h3 id="문제-요약">문제 요약</h3>
<ul>
  <li>글로벌 서비스를 운영하는 환경에서 사용자들이 접속할 때마다 수집되는 IP 주소를 지리 정보인 국가로 매핑하는 작업이 필요했습니다. 이를 위해 PostgreSQL의 CIDR 연산자를 사용하여 IP 주소를 국가명과 매핑하는 테이블을 구성했지만, 기존 방식은 매우 비효율적이었습니다.</li>
</ul>

<h3 id="구체적인-문제-상황">구체적인 문제 상황</h3>
<ul>
  <li><code class="language-plaintext highlighter-rouge">src_sessions</code> 테이블의 <code class="language-plaintext highlighter-rouge">session_ip</code> 칼럼을 <code class="language-plaintext highlighter-rouge">src_cidrs_countries</code> 테이블의 <code class="language-plaintext highlighter-rouge">cidr</code> 칼럼에 매핑하여 <code class="language-plaintext highlighter-rouge">fct_sessions</code> 테이블을 생성하는 작업이 핵심 문제였습니다.</li>
  <li>기존 쿼리는 <code class="language-plaintext highlighter-rouge">&lt;&lt;=</code> 연산자를 사용하여 IP 주소가 특정 CIDR 네트워크에 포함되는지를 확인하는 방식으로 이루어졌습니다. 그러나 이 방법은 대규모 데이터 처리 시 성능 문제가 발생하여, 쿼리 실행 시간이 지나치게 많이 소요되었습니다. 이는 데이터 웨어하우스의 성능을 저하시키고, 운영에 심각한 지장을 초래했습니다.</li>
</ul>

<hr />

<h1 id="3-tasks">3. Tasks</h1>
<blockquote>
  <ul>
    <li>기존의 IP 주소 매핑 쿼리를 최적화하여 처리 시간을 대폭 줄이는 것이 목표였습니다. 이 작업을 통해 Transformation 과정의 효율성을 높여, 더 나은 데이터 웨어하우스 성능을 달성해야 했습니다. 구체적으로는 IP 주소 매핑 시 연산 과정을 최적화하고, JOIN 조건의 효율성을 높이는 것이 핵심 과제였습니다.</li>
  </ul>
</blockquote>

<h3 id="주어진-과제"><strong>주어진 과제</strong></h3>
<ul>
  <li>기존의 비효율적인 쿼리 실행 시간을 대폭 줄이는 것이었습니다.</li>
</ul>

<h5 id="1-데이터-처리-속도-향상"><strong>1. 데이터 처리 속도 향상</strong></h5>
<ul>
  <li>실행 시간을 줄여 데이터 처리 효율성을 높이고, 서비스 운영에 방해가 되지 않도록 하는 것</li>
</ul>

<h5 id="2-쿼리-최적화"><strong>2. 쿼리 최적화</strong></h5>
<ul>
  <li>IP 주소와 국가 정보의 매핑 작업을 보다 효율적으로 수행할 수 있는 최적화된 쿼리 구조를 설계하고 구현하는 것</li>
</ul>

<h5 id="3-시스템-성능-개선"><strong>3. 시스템 성능 개선</strong></h5>
<ul>
  <li>데이터 웨어하우스의 전반적인 성능을 개선하여 미래의 데이터 확장 및 증가에도 대응할 수 있는 기반을 마련하는 것</li>
</ul>

<hr />

<h1 id="4-actions">4. Actions</h1>

<blockquote>
  <ol>
    <li><strong>기존 접근 방식 분석</strong>
      <ul>
        <li>기존 쿼리에서 <code class="language-plaintext highlighter-rouge">&lt;&lt;=</code> 연산자를 사용하여 CIDR 네트워크에 IP 주소를 매핑하는 방법을 사용했습니다. 이는 성능 저하의 주요 원인으로 파악되었습니다.</li>
      </ul>
    </li>
    <li><strong>새로운 테이블 생성</strong>
      <ul>
        <li>기존 테이블을 가공하여 <code class="language-plaintext highlighter-rouge">dim_ips_countries</code> 테이블을 생성했습니다.</li>
      </ul>
      <ul>
        <li>이 테이블은 <code class="language-plaintext highlighter-rouge">start_ip</code>와 <code class="language-plaintext highlighter-rouge">end_ip</code> 칼럼을 가지고 있습니다.</li>
        <li>비교 연산의 효율성을 위해 IP 주소를 BIGINT 타입으로 변환했습니다.</li>
      </ul>
    </li>
    <li><strong>Index 생성</strong>
      <ul>
        <li><code class="language-plaintext highlighter-rouge">start_ip</code>와 <code class="language-plaintext highlighter-rouge">end_ip</code> 칼럼을 Index로 생성하여 검색 성능을 극대화했습니다.</li>
      </ul>
    </li>
    <li><strong>쿼리 최적화</strong>
      <ul>
        <li>기존의 <code class="language-plaintext highlighter-rouge">&lt;&lt;=</code> 연산자를 <code class="language-plaintext highlighter-rouge">BETWEEN</code> 연산자로 대체하여, IP 주소 비교 작업을 단순화하고 경량화된 연산을 수행하도록 쿼리를 재구성했습니다.</li>
      </ul>
    </li>
  </ol>
</blockquote>

<h3 id="1-기존-접근-방식-분석">1. 기존 접근 방식 분석</h3>
<p><img src="/assets/2024-05-19-ip-address-to-country/1.webp" alt="" /></p>

<p><strong>(STEP 1)</strong> <code class="language-plaintext highlighter-rouge">src_cidrs_countries</code> 테이블에 Index를 생성합니다.</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">src_sessions</code> 테이블과 JOIN시 <code class="language-plaintext highlighter-rouge">cidr</code> 칼럼을 빈번하게 스캔해야 하므로, 이를 Index로 생성했습니다.
    <details>
<summary>View code</summary>
<div>
        <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="k">CREATE</span> <span class="k">INDEX</span> <span class="n">idx_cidr</span> <span class="k">ON</span> <span class="n">src_cidrs_countries</span> <span class="p">(</span><span class="n">cidr</span><span class="p">);</span>
</code></pre></div>        </div>
      </div>
</details>
  </li>
</ul>

<p><strong>(STEP 2)</strong> <code class="language-plaintext highlighter-rouge">src_cidrs_countries</code> 테이블과 <code class="language-plaintext highlighter-rouge">src_sessions</code> 테이블을 JOIN한 <code class="language-plaintext highlighter-rouge">fct_sessions</code> 테이블을 생성했습니다.</p>
<ul>
  <li>JOIN 과정에서 <code class="language-plaintext highlighter-rouge">&lt;&lt;=</code> 연산자를 사용했습니다.</li>
  <li>그러나 이 연산자는 CIDR 타입 간의 비교를 수행하는 데 연산 비용이 높아, 대규모 데이터 처리 시 성능 저하의 원인이 되었습니다.
    <details>
<summary>View code</summary>
<div>
        <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">fct_sessions</span> <span class="k">AS</span>
    <span class="k">SELECT</span>
      <span class="n">S</span><span class="p">.</span><span class="n">session_id</span><span class="p">,</span>
      <span class="n">S</span><span class="p">.</span><span class="n">user_id</span><span class="p">,</span>
      <span class="k">C</span><span class="p">.</span><span class="n">country</span>
    <span class="k">FROM</span>
      <span class="n">src_sessions</span> <span class="n">S</span>
    <span class="k">LEFT</span> <span class="k">JOIN</span>
      <span class="n">src_cidrs_countries</span> <span class="k">C</span>
      <span class="k">ON</span> <span class="n">S</span><span class="p">.</span><span class="n">session_ip</span><span class="p">::</span><span class="n">INET</span> <span class="o">&lt;&lt;=</span> <span class="k">C</span><span class="p">.</span><span class="n">cidr</span><span class="p">;</span>
</code></pre></div>        </div>
      </div>
</details>
  </li>
</ul>

<h3 id="2-새로운-테이블-생성">2. <strong>새로운 테이블 생성</strong></h3>
<p><img src="/assets/2024-05-19-ip-address-to-country/2.webp" alt="" /></p>

<ul>
  <li>기존의 <code class="language-plaintext highlighter-rouge">src_cidrs_countries</code> 테이블을 가공하여 <code class="language-plaintext highlighter-rouge">dim_ips_countries</code> 테이블을 새롭게 설계했습니다. 이 테이블에 CIDR 연산을 최소화하기 위해 각 CIDR 값에 대해 IP 주소 범위를 나타내는 <code class="language-plaintext highlighter-rouge">start_ip</code>와 <code class="language-plaintext highlighter-rouge">end_ip</code> 칼럼을 추가했습니다.</li>
  <li>IP 주소를 BIGINT 타입으로 변환하여 저장함으로써, 연산 속도를 크게 향상시켰습니다. <code class="language-plaintext highlighter-rouge">start_ip</code>와 <code class="language-plaintext highlighter-rouge">end_ip</code>는 CIDR 범위 내에서 가장 낮은 IP와 가장 높은 IP를 나타내며, 이를 통해 CIDR 네트워크 내 IP 주소 확인 작업을 단순화했습니다.</li>
</ul>

<details>
<summary>View code</summary>
<div>
    <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">dim_ips_countries</span> <span class="k">AS</span>
    <span class="k">SELECT</span>
      <span class="n">cidr</span><span class="p">,</span>
      <span class="p">(</span><span class="s1">'x'</span> <span class="o">||</span> 
      <span class="n">LPAD</span><span class="p">(</span><span class="n">TO_HEX</span><span class="p">((</span><span class="n">SPLIT_PART</span><span class="p">(</span><span class="k">HOST</span><span class="p">(</span><span class="n">cidr</span><span class="p">),</span> <span class="s1">'.'</span><span class="p">,</span> <span class="mi">1</span><span class="p">)::</span><span class="nb">INTEGER</span><span class="p">)),</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">'0'</span><span class="p">)</span> <span class="o">||</span>
      <span class="n">LPAD</span><span class="p">(</span><span class="n">TO_HEX</span><span class="p">((</span><span class="n">SPLIT_PART</span><span class="p">(</span><span class="k">HOST</span><span class="p">(</span><span class="n">cidr</span><span class="p">),</span> <span class="s1">'.'</span><span class="p">,</span> <span class="mi">2</span><span class="p">)::</span><span class="nb">INTEGER</span><span class="p">)),</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">'0'</span><span class="p">)</span> <span class="o">||</span>
      <span class="n">LPAD</span><span class="p">(</span><span class="n">TO_HEX</span><span class="p">((</span><span class="n">SPLIT_PART</span><span class="p">(</span><span class="k">HOST</span><span class="p">(</span><span class="n">cidr</span><span class="p">),</span> <span class="s1">'.'</span><span class="p">,</span> <span class="mi">3</span><span class="p">)::</span><span class="nb">INTEGER</span><span class="p">)),</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">'0'</span><span class="p">)</span> <span class="o">||</span>
      <span class="n">LPAD</span><span class="p">(</span><span class="n">TO_HEX</span><span class="p">((</span><span class="n">SPLIT_PART</span><span class="p">(</span><span class="k">HOST</span><span class="p">(</span><span class="n">cidr</span><span class="p">),</span> <span class="s1">'.'</span><span class="p">,</span> <span class="mi">4</span><span class="p">)::</span><span class="nb">INTEGER</span><span class="p">)),</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">'0'</span><span class="p">)</span>
      <span class="p">)::</span><span class="nb">BIT</span><span class="p">(</span><span class="mi">32</span><span class="p">)::</span><span class="nb">BIGINT</span> <span class="k">AS</span> <span class="n">start_ip</span><span class="p">,</span>
      <span class="p">(</span><span class="s1">'x'</span> <span class="o">||</span>
      <span class="n">LPAD</span><span class="p">(</span><span class="n">TO_HEX</span><span class="p">((</span><span class="n">SPLIT_PART</span><span class="p">(</span><span class="k">HOST</span><span class="p">(</span><span class="n">BROADCAST</span><span class="p">(</span><span class="n">cidr</span><span class="p">)),</span> <span class="s1">'.'</span><span class="p">,</span> <span class="mi">1</span><span class="p">)::</span><span class="nb">INTEGER</span><span class="p">)),</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">'0'</span><span class="p">)</span> <span class="o">||</span>
      <span class="n">LPAD</span><span class="p">(</span><span class="n">TO_HEX</span><span class="p">((</span><span class="n">SPLIT_PART</span><span class="p">(</span><span class="k">HOST</span><span class="p">(</span><span class="n">BROADCAST</span><span class="p">(</span><span class="n">cidr</span><span class="p">)),</span> <span class="s1">'.'</span><span class="p">,</span> <span class="mi">2</span><span class="p">)::</span><span class="nb">INTEGER</span><span class="p">)),</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">'0'</span><span class="p">)</span> <span class="o">||</span>
      <span class="n">LPAD</span><span class="p">(</span><span class="n">TO_HEX</span><span class="p">((</span><span class="n">SPLIT_PART</span><span class="p">(</span><span class="k">HOST</span><span class="p">(</span><span class="n">BROADCAST</span><span class="p">(</span><span class="n">cidr</span><span class="p">)),</span> <span class="s1">'.'</span><span class="p">,</span> <span class="mi">3</span><span class="p">)::</span><span class="nb">INTEGER</span><span class="p">)),</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">'0'</span><span class="p">)</span> <span class="o">||</span>
      <span class="n">LPAD</span><span class="p">(</span><span class="n">TO_HEX</span><span class="p">((</span><span class="n">SPLIT_PART</span><span class="p">(</span><span class="k">HOST</span><span class="p">(</span><span class="n">BROADCAST</span><span class="p">(</span><span class="n">cidr</span><span class="p">)),</span> <span class="s1">'.'</span><span class="p">,</span> <span class="mi">4</span><span class="p">)::</span><span class="nb">INTEGER</span><span class="p">)),</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">'0'</span><span class="p">)</span>
      <span class="p">)::</span><span class="nb">BIT</span><span class="p">(</span><span class="mi">32</span><span class="p">)::</span><span class="nb">BIGINT</span> <span class="k">AS</span> <span class="n">end_ip</span><span class="p">,</span>				
      <span class="n">country</span>
    <span class="k">FROM</span>
      <span class="n">src_cidrs_countries</span><span class="p">;</span>
</code></pre></div>    </div>
  </div>
</details>

<h3 id="3-index-생성">3. <strong>Index 생성</strong></h3>

<ul>
  <li><code class="language-plaintext highlighter-rouge">src_sessions</code> 테이블과 JOIN시 <code class="language-plaintext highlighter-rouge">start_ip</code> 및 <code class="language-plaintext highlighter-rouge">end_ip</code> 칼럼을 빈번하게 스캔해야 하므로, 이 2개 칼럼을 Index로 생성했습니다.</li>
  <li>이 Index는 IP 주소 범위 내에서 효율적으로 값을 찾을 수 있도록 설계되었으며, JOIN 연산 시 빠른 검색이 가능하게 되었습니다.
    <details>
<summary>View code</summary>
<div>
        <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="k">CREATE</span> <span class="k">INDEX</span> <span class="n">idx_ip_range</span> <span class="k">ON</span> <span class="n">dim_ips_countries</span> <span class="p">(</span><span class="n">start_ip</span><span class="p">,</span> <span class="n">end_ip</span><span class="p">);</span>
</code></pre></div>        </div>
      </div>
</details>
  </li>
</ul>

<h3 id="4-쿼리-최적화">4. <strong>쿼리 최적화</strong></h3>

<ul>
  <li>기존의 <code class="language-plaintext highlighter-rouge">&lt;&lt;=</code> 연산자를 <code class="language-plaintext highlighter-rouge">BETWEEN</code> 연산자로 대체하여, IP 주소 비교 작업을 단순화하고 경량화된 연산을 수행하도록 쿼리를 재구성했습니다.</li>
  <li><code class="language-plaintext highlighter-rouge">src_sessions</code> 테이블의 <code class="language-plaintext highlighter-rouge">session_ip</code> 칼럼도 CIDR에서 IP 주소를 추출한 후 BIGINT 타입으로 변환하여 <code class="language-plaintext highlighter-rouge">dim_ips_countries</code> 테이블의 <code class="language-plaintext highlighter-rouge">start_ip</code>와 <code class="language-plaintext highlighter-rouge">end_ip</code> 칼럼과 비교했습니다.
    <details>
<summary>View code</summary>
<div>
        <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">fct_sessions</span> <span class="k">AS</span>
    <span class="k">SELECT</span>
    <span class="n">S</span><span class="p">.</span><span class="n">session_id</span><span class="p">,</span>
    <span class="n">S</span><span class="p">.</span><span class="n">user_id</span><span class="p">,</span>
    <span class="k">C</span><span class="p">.</span><span class="n">country</span>
  <span class="k">FROM</span> <span class="p">(</span>
    <span class="k">SELECT</span>
      <span class="n">session_id</span><span class="p">,</span>
      <span class="n">user_id</span><span class="p">,</span>
      <span class="p">(</span><span class="s1">'x'</span> <span class="o">||</span>
      <span class="n">LPAD</span><span class="p">(</span><span class="n">TO_HEX</span><span class="p">((</span><span class="n">SPLIT_PART</span><span class="p">(</span><span class="k">HOST</span><span class="p">(</span><span class="n">session_ip</span><span class="p">::</span><span class="n">INET</span><span class="p">),</span> <span class="s1">'.'</span><span class="p">,</span> <span class="mi">1</span><span class="p">)::</span><span class="nb">INTEGER</span><span class="p">)),</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">'0'</span><span class="p">)</span> <span class="o">||</span>
      <span class="n">LPAD</span><span class="p">(</span><span class="n">TO_HEX</span><span class="p">((</span><span class="n">SPLIT_PART</span><span class="p">(</span><span class="k">HOST</span><span class="p">(</span><span class="n">session_ip</span><span class="p">::</span><span class="n">INET</span><span class="p">),</span> <span class="s1">'.'</span><span class="p">,</span> <span class="mi">2</span><span class="p">)::</span><span class="nb">INTEGER</span><span class="p">)),</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">'0'</span><span class="p">)</span> <span class="o">||</span>
      <span class="n">LPAD</span><span class="p">(</span><span class="n">TO_HEX</span><span class="p">((</span><span class="n">SPLIT_PART</span><span class="p">(</span><span class="k">HOST</span><span class="p">(</span><span class="n">session_ip</span><span class="p">::</span><span class="n">INET</span><span class="p">),</span> <span class="s1">'.'</span><span class="p">,</span> <span class="mi">3</span><span class="p">)::</span><span class="nb">INTEGER</span><span class="p">)),</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">'0'</span><span class="p">)</span> <span class="o">||</span>
      <span class="n">LPAD</span><span class="p">(</span><span class="n">TO_HEX</span><span class="p">((</span><span class="n">SPLIT_PART</span><span class="p">(</span><span class="k">HOST</span><span class="p">(</span><span class="n">session_ip</span><span class="p">::</span><span class="n">INET</span><span class="p">),</span> <span class="s1">'.'</span><span class="p">,</span> <span class="mi">4</span><span class="p">)::</span><span class="nb">INTEGER</span><span class="p">)),</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">'0'</span><span class="p">)</span>                
      <span class="p">)::</span><span class="nb">BIT</span><span class="p">(</span><span class="mi">32</span><span class="p">)::</span><span class="nb">BIGINT</span> <span class="k">AS</span> <span class="n">session_ip</span>
    <span class="k">FROM</span>
      <span class="n">src_sessions</span>
  <span class="p">)</span> <span class="n">S</span>
  <span class="k">LEFT</span> <span class="k">JOIN</span>
    <span class="n">src_cidrs_countries</span> <span class="k">C</span>
    <span class="k">ON</span> <span class="n">S</span><span class="p">.</span><span class="n">session_ip</span> <span class="k">BETWEEN</span> <span class="k">C</span><span class="p">.</span><span class="n">start_ip</span> <span class="k">AND</span> <span class="k">C</span><span class="p">.</span><span class="n">end_ip</span><span class="p">;</span>
</code></pre></div>        </div>
      </div>
</details>
  </li>
</ul>

<hr />

<h1 id="5-results">5. Results</h1>
<blockquote>
  <ul>
    <li>최적화된 쿼리를 통해 실행 시간이 90% 대폭 감소하여 데이터 웨어하우스 성능 향상을 가져왔습니다.</li>
  </ul>
</blockquote>

<h3 id="1-긍정적인-결과">1. 긍정적인 결과</h3>

<ul>
  <li>최적화된 접근 방식을 통해 쿼리 실행 시간이 기존 100x시간에서 약 10x시간으로 감소하였습니다. 이는 실행 시간의 약 90%를 줄인 결과로, 데이터 처리 속도와 시스템 성능이 크게 개선되었습니다. 특히, 신규 접근 방식은 대규모 데이터 처리 시에도 안정적인 성능을 유지할 수 있도록 하였으며, 향후 데이터 증가에도 유연하게 대응할 수 있는 기반을 마련했습니다.</li>
  <li>이 최적화 작업은 데이터 웨어하우스의 효율성을 극대화하여 운영 비용을 절감하고, 더 나은 데이터 분석과 서비스 제공이 가능하도록 했습니다. 결과적으로, 시스템의 전반적인 성능이 크게 향상되었으며, 이로 인해 회사의 데이터 운영 전략에 중요한 기여를 할 수 있었습니다.</li>
</ul>

<h3 id="2-교훈">2. 교훈</h3>

<ul>
  <li>아래 그림과 같이, SQL의 JOIN은 Nested Loop 탐색 과정이 일어나므로 가장 면밀하게 검토해야 할 부분이었습니다.
<img src="/assets/2024-05-19-ip-address-to-country/3.webp" alt="" /></li>
</ul>

<h5 id="tip-1-join의-조건-역할을-하는-칼럼은-최대한-가벼운-타입을-지녀야-한다">(TIP 1) JOIN의 조건 역할을 하는 칼럼은 최대한 가벼운 타입을 지녀야 한다.</h5>
<ul>
  <li>기존 접근 방식에서는 <code class="language-plaintext highlighter-rouge">cidr</code> 칼럼이 CIDR 타입이었으나, 신규 접근 방식에서는 이를 BIGINT로 Parse하여 타입을 경량화시켰습니다.</li>
</ul>

<h5 id="tip-2-join의-조건-역할을-하는-연산자는-최대한-가벼운-과정이-되어야-한다">(TIP 2) JOIN의 조건 역할을 하는 연산자는 최대한 가벼운 과정이 되어야 한다.</h5>
<ul>
  <li>기존 접근 방식에서는 <code class="language-plaintext highlighter-rouge">&gt;&gt;=</code>라는 다소 무거운 연산자를 사용했으나, 신규 접근 방식에서는 이를 <code class="language-plaintext highlighter-rouge">BETWEEN</code> 연산자를 사용하여 부담을 줄였습니다.</li>
</ul>

<hr />

<h2 id="published-by-joshua-kim"><em>Published by</em> Joshua Kim</h2>
<p><img src="/assets/profile/joshua-profile.png" alt="Joshua Kim" /></p>]]></content><author><name></name></author><category term="Korean" /><category term="PostgreSQL" /><summary type="html"><![CDATA[“데이터 웨어하우스에서 IP 주소를 사용해 사용자의 국가 정보를 매핑하는 작업을 최적화하였습니다. 기존 방식은 연산 시간이 길어 비효율적이었으나, 새로운 접근 방식을 통해 쿼리 실행 시간을 90% 감소시켰습니다.”]]></summary></entry><entry><title type="html">IP Address-Country Mapping Query Optimization</title><link href="http://localhost:4000/ip-address-to-country-en/" rel="alternate" type="text/html" title="IP Address-Country Mapping Query Optimization" /><published>2024-05-19T00:00:00+09:00</published><updated>2024-05-19T00:00:00+09:00</updated><id>http://localhost:4000/ip-address-to-country-en</id><content type="html" xml:base="http://localhost:4000/ip-address-to-country-en/"><![CDATA[<blockquote>
  <p>“Optimized the process of mapping user country information using IP addresses in a data warehouse. The previous method was inefficient due to long processing times, but the new approach reduced query execution time by 90%.”</p>
</blockquote>

<hr />

<h1 id="table-of-contents">Table of Contents</h1>
<ol>
  <li>STAR Summary</li>
  <li>Situation</li>
  <li>Tasks</li>
  <li>Actions</li>
  <li>Results</li>
</ol>

<hr />

<h1 id="1-star-summary">1. STAR Summary</h1>

<h3 id="situation">Situation</h3>
<ul>
  <li>In an environment operating a global service, it was necessary to map user country information based on connection IP addresses. This task was performed using PostgreSQL, but the previous approach resulted in performance degradation. The existing query took too long to execute, placing a significant burden on data warehouse operations.</li>
</ul>

<h3 id="tasks">Tasks</h3>
<ul>
  <li>The goal was to optimize the existing IP address mapping query to drastically reduce processing time. This optimization aimed to improve the efficiency of the transformation process, achieving better data warehouse performance. Specifically, the core task was to optimize the computational process for IP address mapping and enhance the efficiency of the JOIN conditions.</li>
</ul>

<h3 id="actions">Actions</h3>

<ol>
  <li><strong>Analysis of the Existing Approach</strong>
    <ul>
      <li>The existing query used the <code class="language-plaintext highlighter-rouge">&lt;&lt;=</code> operator to map IP addresses to CIDR networks, identified as the main cause of performance degradation.</li>
    </ul>
  </li>
  <li><strong>Creation of a New Table</strong>
    <ul>
      <li>Created a new table, <code class="language-plaintext highlighter-rouge">dim_ips_countries</code>, by processing the existing table.
        <ul>
          <li>This table includes <code class="language-plaintext highlighter-rouge">start_ip</code> and <code class="language-plaintext highlighter-rouge">end_ip</code> columns.</li>
          <li>Converted IP addresses to BIGINT type to improve the efficiency of comparison operations.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>Index Creation</strong>
    <ul>
      <li>Created indexes on the <code class="language-plaintext highlighter-rouge">start_ip</code> and <code class="language-plaintext highlighter-rouge">end_ip</code> columns to maximize search performance.</li>
    </ul>
  </li>
  <li><strong>Query Optimization</strong>
    <ul>
      <li>Replaced the existing <code class="language-plaintext highlighter-rouge">&lt;&lt;=</code> operator with the <code class="language-plaintext highlighter-rouge">BETWEEN</code> operator to simplify IP address comparison and restructure the query for lightweight operations.</li>
    </ul>
  </li>
</ol>

<h3 id="results">Results</h3>
<ul>
  <li>The optimized query reduced execution time by 90%, significantly improving data warehouse performance.</li>
</ul>

<hr />

<h1 id="2-situation">2. Situation</h1>

<blockquote>
  <ul>
    <li>In an environment operating a global service, it was necessary to map user country information based on connection IP addresses. This task was performed using PostgreSQL, but the previous approach resulted in performance degradation. The existing query took too long to execute, placing a significant burden on data warehouse operations.</li>
  </ul>
</blockquote>

<h3 id="problem-summary">Problem Summary</h3>
<ul>
  <li>In an environment operating a global service, it was necessary to map IP addresses collected from user connections to geographical information such as the country. For this, a table mapping IP addresses to country names was created using PostgreSQL’s CIDR operator, but the existing method was highly inefficient.</li>
</ul>

<h3 id="specific-problem-context">Specific Problem Context</h3>
<ul>
  <li>The core task was to map the <code class="language-plaintext highlighter-rouge">session_ip</code> column in the <code class="language-plaintext highlighter-rouge">src_sessions</code> table to the <code class="language-plaintext highlighter-rouge">cidr</code> column in the <code class="language-plaintext highlighter-rouge">src_cidrs_countries</code> table to create the <code class="language-plaintext highlighter-rouge">fct_sessions</code> table.</li>
  <li>The existing query used the <code class="language-plaintext highlighter-rouge">&lt;&lt;=</code> operator to determine whether an IP address was included in a specific CIDR network. However, this method caused performance issues during large-scale data processing, with query execution times being excessively long. This degraded data warehouse performance and caused severe operational disruptions.</li>
</ul>

<hr />

<h1 id="3-tasks">3. Tasks</h1>
<blockquote>
  <ul>
    <li>The goal was to optimize the existing IP address mapping query to drastically reduce processing time. This optimization aimed to improve the efficiency of the transformation process, achieving better data warehouse performance. Specifically, the core task was to optimize the computational process for IP address mapping and enhance the efficiency of the JOIN conditions.</li>
  </ul>
</blockquote>

<h3 id="assigned-tasks"><strong>Assigned Tasks</strong></h3>
<ul>
  <li>The main objective was to significantly reduce the inefficient query execution time.</li>
</ul>

<h3 id="1-improve-data-processing-speed"><strong>1. Improve Data Processing Speed</strong></h3>
<ul>
  <li>Reduce execution time to enhance data processing efficiency and prevent disruption to service operations.</li>
</ul>

<h3 id="2-query-optimization"><strong>2. Query Optimization</strong></h3>
<ul>
  <li>Design and implement an optimized query structure that can perform IP address and country information mapping more efficiently.</li>
</ul>

<h3 id="3-system-performance-improvement"><strong>3. System Performance Improvement</strong></h3>
<ul>
  <li>Improve overall data warehouse performance to establish a foundation that can handle future data expansion and growth.</li>
</ul>

<hr />

<h1 id="4-actions">4. Actions</h1>

<blockquote>
  <ol>
    <li><strong>Analysis of the Existing Approach</strong>
      <ul>
        <li>The existing query used the <code class="language-plaintext highlighter-rouge">&lt;&lt;=</code> operator to map IP addresses to CIDR networks, identified as the main cause of performance degradation.</li>
      </ul>
    </li>
    <li><strong>Creation of a New Table</strong>
      <ul>
        <li>Created a new table, <code class="language-plaintext highlighter-rouge">dim_ips_countries</code>, by processing the existing table.
          <ul>
            <li>This table includes <code class="language-plaintext highlighter-rouge">start_ip</code> and <code class="language-plaintext highlighter-rouge">end_ip</code> columns.</li>
            <li>Converted IP addresses to BIGINT type to improve the efficiency of comparison operations.</li>
          </ul>
        </li>
      </ul>
    </li>
    <li><strong>Index Creation</strong>
      <ul>
        <li>Created indexes on the <code class="language-plaintext highlighter-rouge">start_ip</code> and <code class="language-plaintext highlighter-rouge">end_ip</code> columns to maximize search performance.</li>
      </ul>
    </li>
    <li><strong>Query Optimization</strong>
      <ul>
        <li>Replaced the existing <code class="language-plaintext highlighter-rouge">&lt;&lt;=</code> operator with the <code class="language-plaintext highlighter-rouge">BETWEEN</code> operator to simplify IP address comparison and restructure the query for lightweight operations.</li>
      </ul>
    </li>
  </ol>
</blockquote>

<h3 id="1-analysis-of-the-existing-approach">1. Analysis of the Existing Approach</h3>
<p><img src="/assets/2024-05-19-ip-address-to-country/1.webp" alt="" /></p>

<p><strong>(STEP 1)</strong> Create an index on the <code class="language-plaintext highlighter-rouge">src_cidrs_countries</code> table.</p>
<ul>
  <li>Since the <code class="language-plaintext highlighter-rouge">cidr</code> column needs to be frequently scanned during the JOIN operation with the <code class="language-plaintext highlighter-rouge">src_sessions</code> table, an index was created on this column.
    <details>
<summary>View code</summary>
<div>
        <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="k">CREATE</span> <span class="k">INDEX</span> <span class="n">idx_cidr</span> <span class="k">ON</span> <span class="n">src_cidrs_countries</span> <span class="p">(</span><span class="n">cidr</span><span class="p">);</span>
</code></pre></div>        </div>
      </div>
</details>
  </li>
</ul>

<p><strong>(STEP 2)</strong> Created the <code class="language-plaintext highlighter-rouge">fct_sessions</code> table by joining the <code class="language-plaintext highlighter-rouge">src_cidrs_countries</code> table with the <code class="language-plaintext highlighter-rouge">src_sessions</code> table.</p>
<ul>
  <li>The <code class="language-plaintext highlighter-rouge">&lt;&lt;=</code> operator was used in the JOIN process.</li>
  <li>However, this operator, which compares CIDR types, had a high computational cost, causing performance degradation during large-scale data processing.
    <details>
<summary>View code</summary>
<div>
        <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">fct_sessions</span> <span class="k">AS</span>
    <span class="k">SELECT</span>
      <span class="n">S</span><span class="p">.</span><span class="n">session_id</span><span class="p">,</span>
      <span class="n">S</span><span class="p">.</span><span class="n">user_id</span><span class="p">,</span>
      <span class="k">C</span><span class="p">.</span><span class="n">country</span>
    <span class="k">FROM</span>
      <span class="n">src_sessions</span> <span class="n">S</span>
    <span class="k">LEFT</span> <span class="k">JOIN</span>
      <span class="n">src_cidrs_countries</span> <span class="k">C</span>
      <span class="k">ON</span> <span class="n">S</span><span class="p">.</span><span class="n">session_ip</span><span class="p">::</span><span class="n">INET</span> <span class="o">&lt;&lt;=</span> <span class="k">C</span><span class="p">.</span><span class="n">cidr</span><span class="p">;</span>
</code></pre></div>        </div>
      </div>
</details>
  </li>
</ul>

<h3 id="2-creation-of-a-new-table">2. <strong>Creation of a New Table</strong></h3>
<p><img src="/assets/2024-05-19-ip-address-to-country/2.webp" alt="" /></p>

<ul>
  <li>A new table, <code class="language-plaintext highlighter-rouge">dim_ips_countries</code>, was created by processing the existing <code class="language-plaintext highlighter-rouge">src_cidrs_countries</code> table. This table was newly designed to minimize CIDR operations, adding <code class="language-plaintext highlighter-rouge">start_ip</code> and <code class="language-plaintext highlighter-rouge">end_ip</code> columns representing the IP address range for each CIDR value.</li>
  <li>By converting IP addresses to BIGINT type for storage, computation speed was greatly improved. <code class="language-plaintext highlighter-rouge">start_ip</code> and <code class="language-plaintext highlighter-rouge">end_ip</code> represent the lowest and highest IPs within the CIDR range, simplifying the process of verifying IP addresses within a CIDR network.</li>
</ul>
<details>
<summary>View code</summary>
<div>
    <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">dim_ips_countries</span> <span class="k">AS</span>
    <span class="k">SELECT</span>
      <span class="n">cidr</span><span class="p">,</span>
      <span class="p">(</span><span class="s1">'x'</span> <span class="o">||</span> 
      <span class="n">LPAD</span><span class="p">(</span><span class="n">TO_HEX</span><span class="p">((</span><span class="n">SPLIT_PART</span><span class="p">(</span><span class="k">HOST</span><span class="p">(</span><span class="n">cidr</span><span class="p">),</span> <span class="s1">'.'</span><span class="p">,</span> <span class="mi">1</span><span class="p">)::</span><span class="nb">INTEGER</span><span class="p">)),</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">'0'</span><span class="p">)</span> <span class="o">||</span>
      <span class="n">LPAD</span><span class="p">(</span><span class="n">TO_HEX</span><span class="p">((</span><span class="n">SPLIT_PART</span><span class="p">(</span><span class="k">HOST</span><span class="p">(</span><span class="n">cidr</span><span class="p">),</span> <span class="s1">'.'</span><span class="p">,</span> <span class="mi">2</span><span class="p">)::</span><span class="nb">INTEGER</span><span class="p">)),</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">'0'</span><span class="p">)</span> <span class="o">||</span>
      <span class="n">LPAD</span><span class="p">(</span><span class="n">TO_HEX</span><span class="p">((</span><span class="n">SPLIT_PART</span><span class="p">(</span><span class="k">HOST</span><span class="p">(</span><span class="n">cidr</span><span class="p">),</span> <span class="s1">'.'</span><span class="p">,</span> <span class="mi">3</span><span class="p">)::</span><span class="nb">INTEGER</span><span class="p">)),</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">'0'</span><span class="p">)</span> <span class="o">||</span>
      <span class="n">LPAD</span><span class="p">(</span><span class="n">TO_HEX</span><span class="p">((</span><span class="n">SPLIT_PART</span><span class="p">(</span><span class="k">HOST</span><span class="p">(</span><span class="n">cidr</span><span class="p">),</span> <span class="s1">'.'</span><span class="p">,</span> <span class="mi">4</span><span class="p">)::</span><span class="nb">INTEGER</span><span class="p">)),</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">'0'</span><span class="p">)</span>
      <span class="p">)::</span><span class="nb">BIT</span><span class="p">(</span><span class="mi">32</span><span class="p">)::</span><span class="nb">BIGINT</span> <span class="k">AS</span> <span class="n">start_ip</span><span class="p">,</span>
      <span class="p">(</span><span class="s1">'x'</span> <span class="o">||</span>
      <span class="n">LPAD</span><span class="p">(</span><span class="n">TO_HEX</span><span class="p">((</span><span class="n">SPLIT_PART</span><span class="p">(</span><span class="k">HOST</span><span class="p">(</span><span class="n">BROADCAST</span><span class="p">(</span><span class="n">cidr</span><span class="p">)),</span> <span class="s1">'.'</span><span class="p">,</span> <span class="mi">1</span><span class="p">)::</span><span class="nb">INTEGER</span><span class="p">)),</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">'0'</span><span class="p">)</span> <span class="o">||</span>
      <span class="n">LPAD</span><span class="p">(</span><span class="n">TO_HEX</span><span class="p">((</span><span class="n">SPLIT_PART</span><span class="p">(</span><span class="k">HOST</span><span class="p">(</span><span class="n">BROADCAST</span><span class="p">(</span><span class="n">cidr</span><span class="p">)),</span> <span class="s1">'.'</span><span class="p">,</span> <span class="mi">2</span><span class="p">)::</span><span class="nb">INTEGER</span><span class="p">)),</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">'0'</span><span class="p">)</span> <span class="o">||</span>
      <span class="n">LPAD</span><span class="p">(</span><span class="n">TO_HEX</span><span class="p">((</span><span class="n">SPLIT_PART</span><span class="p">(</span><span class="k">HOST</span><span class="p">(</span><span class="n">BROADCAST</span><span class="p">(</span><span class="n">cidr</span><span class="p">)),</span> <span class="s1">'.'</span><span class="p">,</span> <span class="mi">3</span><span class="p">)::</span><span class="nb">INTEGER</span><span class="p">)),</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">'0'</span><span class="p">)</span> <span class="o">||</span>
      <span class="n">LPAD</span><span class="p">(</span><span class="n">TO_HEX</span><span class="p">((</span><span class="n">SPLIT_PART</span><span class="p">(</span><span class="k">HOST</span><span class="p">(</span><span class="n">BROADCAST</span><span class="p">(</span><span class="n">cidr</span><span class="p">)),</span> <span class="s1">'.'</span><span class="p">,</span> <span class="mi">4</span><span class="p">)::</span><span class="nb">INTEGER</span><span class="p">)),</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">'0'</span><span class="p">)</span>
      <span class="p">)::</span><span class="nb">BIT</span><span class="p">(</span><span class="mi">32</span><span class="p">)::</span><span class="nb">BIGINT</span> <span class="k">AS</span> <span class="n">end_ip</span><span class="p">,</span>				
      <span class="n">country</span>
    <span class="k">FROM</span>
      <span class="n">src_cidrs_countries</span><span class="p">;</span>
</code></pre></div>    </div>
  </div>
</details>

<h3 id="3-index-creation">3. <strong>Index Creation</strong></h3>

<ul>
  <li>Since the <code class="language-plaintext highlighter-rouge">start_ip</code> and <code class="language-plaintext highlighter-rouge">end_ip</code> columns need to be frequently scanned during the JOIN operation with the <code class="language-plaintext highlighter-rouge">src_sessions</code> table, an index was created on these two columns.</li>
  <li>This index was designed to efficiently find values within an IP address range, enabling quick searches during JOIN operations.
    <details>
<summary>View code</summary>
<div>
        <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="k">CREATE</span> <span class="k">INDEX</span> <span class="n">idx_ip_range</span> <span class="k">ON</span> <span class="n">dim_ips_countries</span> <span class="p">(</span><span class="n">start_ip</span><span class="p">,</span> <span class="n">end_ip</span><span class="p">);</span>
</code></pre></div>        </div>
      </div>
</details>
  </li>
</ul>

<h3 id="4-query-optimization">4. <strong>Query Optimization</strong></h3>

<ul>
  <li>The existing <code class="language-plaintext highlighter-rouge">&lt;&lt;=</code> operator was replaced with the <code class="language-plaintext highlighter-rouge">BETWEEN</code> operator to simplify IP address comparison and restructure the query for lightweight operations.</li>
  <li>The <code class="language-plaintext highlighter-rouge">session_ip</code> column in the <code class="language-plaintext highlighter-rouge">src_sessions</code> table was also converted from CIDR to IP address, then to BIGINT type, to be compared with the <code class="language-plaintext highlighter-rouge">start_ip</code> and <code class="language-plaintext highlighter-rouge">end_ip</code> columns in the <code class="language-plaintext highlighter-rouge">dim_ips_countries</code> table.
    <details>
<summary>View code</summary>
<div>
        <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">fct_sessions</span> <span class="k">AS</span>
    <span class="k">SELECT</span>
    <span class="n">S</span><span class="p">.</span><span class="n">session_id</span><span class="p">,</span>
    <span class="n">S</span><span class="p">.</span><span class="n">user_id</span><span class="p">,</span>
    <span class="k">C</span><span class="p">.</span><span class="n">country</span>
  <span class="k">FROM</span> <span class="p">(</span>
    <span class="k">SELECT</span>
      <span class="n">session_id</span><span class="p">,</span>
      <span class="n">user_id</span><span class="p">,</span>
      <span class="p">(</span><span class="s1">'x'</span> <span class="o">||</span>
      <span class="n">LPAD</span><span class="p">(</span><span class="n">TO_HEX</span><span class="p">((</span><span class="n">SPLIT_PART</span><span class="p">(</span><span class="k">HOST</span><span class="p">(</span><span class="n">session_ip</span><span class="p">::</span><span class="n">INET</span><span class="p">),</span> <span class="s1">'.'</span><span class="p">,</span> <span class="mi">1</span><span class="p">)::</span><span class="nb">INTEGER</span><span class="p">)),</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">'0'</span><span class="p">)</span> <span class="o">||</span>
      <span class="n">LPAD</span><span class="p">(</span><span class="n">TO_HEX</span><span class="p">((</span><span class="n">SPLIT_PART</span><span class="p">(</span><span class="k">HOST</span><span class="p">(</span><span class="n">session_ip</span><span class="p">::</span><span class="n">INET</span><span class="p">),</span> <span class="s1">'.'</span><span class="p">,</span> <span class="mi">2</span><span class="p">)::</span><span class="nb">INTEGER</span><span class="p">)),</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">'0'</span><span class="p">)</span> <span class="o">||</span>
      <span class="n">LPAD</span><span class="p">(</span><span class="n">TO_HEX</span><span class="p">((</span><span class="n">SPLIT_PART</span><span class="p">(</span><span class="k">HOST</span><span class="p">(</span><span class="n">session_ip</span><span class="p">::</span><span class="n">INET</span><span class="p">),</span> <span class="s1">'.'</span><span class="p">,</span> <span class="mi">3</span><span class="p">)::</span><span class="nb">INTEGER</span><span class="p">)),</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">'0'</span><span class="p">)</span> <span class="o">||</span>
      <span class="n">LPAD</span><span class="p">(</span><span class="n">TO_HEX</span><span class="p">((</span><span class="n">SPLIT_PART</span><span class="p">(</span><span class="k">HOST</span><span class="p">(</span><span class="n">session_ip</span><span class="p">::</span><span class="n">INET</span><span class="p">),</span> <span class="s1">'.'</span><span class="p">,</span> <span class="mi">4</span><span class="p">)::</span><span class="nb">INTEGER</span><span class="p">)),</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">'0'</span><span class="p">)</span>                
      <span class="p">)::</span><span class="nb">BIT</span><span class="p">(</span><span class="mi">32</span><span class="p">)::</span><span class="nb">BIGINT</span> <span class="k">AS</span> <span class="n">session_ip</span>
    <span class="k">FROM</span>
      <span class="n">src_sessions</span>
  <span class="p">)</span> <span class="n">S</span>
  <span class="k">LEFT</span> <span class="k">JOIN</span>
    <span class="n">src_cidrs_countries</span> <span class="k">C</span>
    <span class="k">ON</span> <span class="n">S</span><span class="p">.</span><span class="n">session_ip</span> <span class="k">BETWEEN</span> <span class="k">C</span><span class="p">.</span><span class="n">start_ip</span> <span class="k">AND</span> <span class="k">C</span><span class="p">.</span><span class="n">end_ip</span><span class="p">;</span>
</code></pre></div>        </div>
      </div>
</details>
  </li>
</ul>

<hr />

<h1 id="5-results">5. Results</h1>
<blockquote>
  <ul>
    <li>The optimized query reduced execution time by 90%, significantly improving data warehouse performance.</li>
  </ul>
</blockquote>

<h3 id="1-positive-results">1. Positive Results</h3>

<ul>
  <li>The optimized approach reduced query execution time from approximately 100x to 10x, effectively cutting execution time by around 90%. This significantly improved data processing speed and system performance. The new approach also maintained stable performance during large-scale data processing and established a foundation that could flexibly respond to future data growth.</li>
  <li>This optimization effort maximized the efficiency of the data warehouse, reducing operational costs and enabling better data analysis and service delivery. As a result, the overall system performance was greatly enhanced, making a significant contribution to the company’s data operation strategy.</li>
</ul>

<h3 id="2-lessons-learned">2. Lessons Learned</h3>

<ul>
  <li>As shown in the figure below, SQL JOINs involve a nested loop search process, which needs to be carefully considered.
<img src="/assets/2024-05-19-ip-address-to-country/3.webp" alt="" /></li>
</ul>

<h5 id="tip-1-columns-used-in-join-conditions-should-have-lightweight-data-types">(TIP 1) Columns used in JOIN conditions should have lightweight data types.</h5>
<ul>
  <li>In the existing approach, the <code class="language-plaintext highlighter-rouge">cidr</code> column was of the CIDR type, but in the new approach, it was parsed into BIGINT to make the data type lighter.</li>
</ul>

<h5 id="tip-2-operators-used-in-join-conditions-should-have-lightweight-processes">(TIP 2) Operators used in JOIN conditions should have lightweight processes.</h5>
<ul>
  <li>In the existing approach, the heavier <code class="language-plaintext highlighter-rouge">&lt;&lt;=</code> operator was used, but in the new approach, the <code class="language-plaintext highlighter-rouge">BETWEEN</code> operator was used to reduce the burden.</li>
</ul>

<hr />

<h2 id="published-by-joshua-kim"><em>Published by</em> Joshua Kim</h2>
<p><img src="/assets/profile/joshua-profile.png" alt="Joshua Kim" /></p>]]></content><author><name></name></author><category term="English" /><category term="PostgreSQL" /><summary type="html"><![CDATA[“Optimized the process of mapping user country information using IP addresses in a data warehouse. The previous method was inefficient due to long processing times, but the new approach reduced query execution time by 90%.”]]></summary></entry><entry><title type="html">데이터 분석가의 SQL 최적화 일기: 코호트 리텐션 Batch Query 만들기</title><link href="http://localhost:4000/retention-batch-query/" rel="alternate" type="text/html" title="데이터 분석가의 SQL 최적화 일기: 코호트 리텐션 Batch Query 만들기" /><published>2024-01-01T00:00:00+09:00</published><updated>2024-01-01T00:00:00+09:00</updated><id>http://localhost:4000/retention-batch-query</id><content type="html" xml:base="http://localhost:4000/retention-batch-query/"><![CDATA[<blockquote>
  <p>코호트 리텐션의 의미와 중요성에 대해 말씀드리고, Batch Query를 사용하여 회원가입 월 코호트 별로 Monthly Range Retention을 계산하는 방법을 제시해드릴게요.</p>
</blockquote>

<h3 id="contents">CONTENTS</h3>
<ol>
  <li>코호트 리텐션의 의미와 중요성
    <ul>
      <li>1.1. 리텐션</li>
      <li>1.2. 코호트</li>
      <li>1.3. 코호트 리텐션</li>
      <li>1.4. 코호트 리텐션의 중요성</li>
    </ul>
  </li>
  <li>쿼리 작업 목표</li>
  <li>일회성 쿼리문
    <ul>
      <li>3.1. 쿼리문 보기</li>
      <li>3.2. 문제점</li>
    </ul>
  </li>
  <li>해결 아이디어</li>
  <li>Batch Query를 통해 접근하기</li>
  <li>결론</li>
</ol>

<hr />

<h3 id="disclaimer">DISCLAIMER</h3>
<p>본 아티클은 필자의 전/현 재직 기업의 데이터 분석 현황과 관련이 없으며, 단지 평소에 문제 의식을 지녔던 점에 대한 해결 방법을 스스로 도출해본 내용입니다. 쿼리문 작성에 다른 외부 레퍼런스를 참고하지 않았으며, 분석 환경에 따라 본 내용이 적합하지 않을 수 있으므로 반드시 비판적 고찰을 해주시면 감사드리겠습니다.</p>

<h1 id="1-코호트-리텐션의-의미와-중요성">1. 코호트 리텐션의 의미와 중요성</h1>

<h3 id="11-리텐션">1.1. 리텐션</h3>

<p>먼저, 리텐션은 “시간이 흐름에 따라 얼마나 많은 사용자들이 우리 프로덕트에 재참여하는지”를 나타내는 지표입니다. 이미 많은 분들이 아시듯 리텐션은 PMF를 달성하기 위해 분석해야 할 중요한 지표입니다. 이 정의가 꽤나 간단해보이지만, 측정하는 과정에서 실상은 그렇지 않습니다. “재참여”를 “재”와 “참여”로 나누어 각각의 사전 정의가 이루어져야 하기 때문입니다.</p>

<p><strong>“참여” 개념 정의하기</strong></p>

<p>사용자가 우리 프로덕트에 “참여”한다는 것이 정확히 어떤 순간인지 정의해야 합니다. 예를 들어, 접속, 30초 이상 세션 유지, 특정 퍼널 단계 도달 등 여러 이벤트 중 하나가 “참여”로 간주될 수 있습니다. 저는 개인적으로 아래 3가지 측면 정의를 모두 사전에 준비하여 Target Metric에 따라 적시적소에 모니터링하는 것이 필요하다고 느꼈습니다.</p>

<p>(1) “접속”을 하는 것만으로 참여한 것으로 간주하자!</p>
<ul>
  <li>DAU, WAU, MAU, Stickiness 등의 지표와 직접적으로 연관된 정의 방법이며, 광고 노출 효과를 극대화하는 경우 유용합니다.</li>
</ul>

<p>(2) “구매”까지 해야 참여한 것으로 간주하자!</p>
<ul>
  <li>재구매율 등의 지표와 직접적으로 연관된 정의 방법이며, Recurring Revenue가 중요한 프로덕트에서 중요합니다.</li>
</ul>

<p>(3) “아하 모먼트”에 도달해야 참여한 것으로 간주하자!</p>
<ul>
  <li><a href="https://www.youtube.com/watch?v=0KgOCKJ1PG4">토스의 이승건 대표님에 따르면</a>, 아하 모먼트란 프로덕트의 핵심 가치의 경험하는 순간을 의미합니다.</li>
  <li>X, Y, Z의 조합으로 이루어진 여러 가지 “X 이벤트를 Y 기간 내에 Z번 수행한다” 중 리텐션이 극명하게 높은(가령, 95%) 항목을 사전에 발견하여, 빠르게 PMF를 달성해야 할 때 유용합니다.</li>
</ul>

<p><strong>“재” 개념 정의하기</strong></p>

<p>사용자가 복귀했다는 것을 어떻게 계산할 것인가에 대한 정의가 필요합니다. <a href="https://product.kyobobook.co.kr/detail/S000001766457">양승화님의 그로스해킹에 따르면</a>, Classic Retention, Range Retention, Rolling Retention 중 프로덕트의 특성에 따라 적절한 방법을 선택할 수 있습니다.</p>

<p>(1) Classic Retention: 사용자가 최초로 “참여”한 Day 0 이후, 각 Day N 별로 한 번 더 “참여”했는지 계산합니다.</p>

<p>(2) Range Retention: Day N이 아니라 Week N, Bi-week N, Month N 별로 한 번 더 “참여”했는지 계산합니다.</p>

<p>(3) Rolling Retention: Day N 이후에 한 번이라도 “참여”한 경우를 계산합니다. (이탈률의 반대 개념)</p>

<p><strong>이러한 정의와 측정 방법을 통해 효과적인 리텐션 지표 측정이 가능해질 것입니다.</strong></p>

<h3 id="12-코호트">1.2. 코호트</h3>

<p>코호트의 개념을 두 가지로 혼용하는 경향이 있습니다.</p>
<ol>
  <li><em>“코호트는 세그먼트다. 즉, 사용자가 지닌 여러 가지 Feature 조합을 통해 그룹화된 클러스터다.”</em></li>
  <li><em>“코호트는 세그먼트의 일부로서, 특정 이벤트의 최초 수행일시를 기준으로 그룹화된 클러스터다.” (최초 프로덕트 방문일, 회원가입일, 최초 결제일 등)</em></li>
</ol>

<p>개인적으로는 세그먼트와의 혼동을 줄이기 위해 2번의 개념을 선호하지만, 코호트를 융통성 있게 설정하기 위해 1번 개념에서 언급한 다른 Feature 조합도 선택적으로 추가할 수 있는 “열린 개념”으로 받아들이고 있습니다.</p>

<ul>
  <li>예시 1) 사용자를 최초 프로덕트 방문일 기준으로 그룹화한다. → 코호트 O</li>
  <li>예시 2) 사용자를 최초 접속 국가 기준으로 그룹화한다. → 코호트 X</li>
  <li>예시 3) 사용자를 최초 프로덕트 방문일 및 접속 국가 기준으로 그룹화한다. → 코호트 O</li>
</ul>

<p>이렇게 하면 특정 이벤트의 최초 수행일시를 중심으로 하면서도 다양한 특성을 고려할 수 있어서 코호트를 보다 유연하게 활용할 수 있을 것입니다.</p>

<h3 id="13-코호트-리텐션">1.3. 코호트 리텐션</h3>

<p>코호트 리텐션이란, 기존의 리텐션 개념을 코호트에 따라 시리즈를 달리하여 계산한 지표를 의미합니다. 예를 들면, 최초 프로덕트 방문일을 기준으로 사용자들의 리텐션이 상승 추세인지, 혹은 하락 추세인지를 알 수 있는 것이죠.</p>

<h3 id="14-코호트-리텐션의-중요성">1.4. 코호트 리텐션의 중요성</h3>

<p>아래의 리텐션 지표를 통해 PMF 달성 여부를 확인할 수 있지만, 문제를 파악하거나 액션 포인트를 도출하는 데는 그다지 도움이 되지 않습니다.</p>

<p><img src="/assets/2024-01-01-retention-batch-query/retention.webp" alt="" /></p>
<blockquote>
  <p><a href="https://mermaid.js.org/syntax/xyChart.html">mermaid</a>를 통해 필자가 직접 작성</p>
</blockquote>

<p>그러나 코호트 리텐션 값을 확인할 수 있다면, 프로덕트의 기능 업데이트나 캠페인 론칭 등에 따른 사후 효과를 확인하고, 리텐션 향상을 위해 우리가 어떤 액션에 좀 더 집중해야 하는지 확인하는 데 도움을 줄 수 있습니다.</p>

<p><img src="/assets/2024-01-01-retention-batch-query/cohort-retention.webp" alt="" /></p>
<blockquote>
  <p><a href="https://mermaid.js.org/syntax/xyChart.html">mermaid</a>를 통해 필자가 직접 작성</p>
</blockquote>

<h1 id="2-쿼리-작업-목표">2. 쿼리 작업 목표</h1>

<p>쿼리 작업 목표는 다음과 같습니다. 아래와 같은 테이블을 대시보드에 반영해보고자 합니다. 즉, 회원가입 연월(YYYY-MM) 코호트별 리텐션(Monthly Range)테이블을 배포하여 다양한 이해당사자 분들이 리텐션 지표의 시계열 추이를 확인하시는 데 도움을 드리려는 것입니다.</p>

<p><img src="/assets/2024-01-01-retention-batch-query/task-goal.webp" alt="" /></p>
<blockquote>
  <p>제가 직접 샘플로 만들어본 위 테이블에서는 시간이 흐를수록 리텐션이 향상되는 추이를 보여주고 있군요.</p>
</blockquote>

<p>그런데, 위와 같은 테이블을 만들기 위해서는 SQL의 최후 출력 상태가 다음과 같은 Unpivoted한 형태가 되어야 합니다. 물론 Pivoted한 형태로 직접 출력하는 방법도 있지만, 오늘의 토픽인 “Batch Query 만들기”를 위해서는 Unpivoted한 형태가 되어야 합니다. Table을 Update를 방지하고, 오로지 Insert 작업만 수행함으로써 연산 부하를 방지하기 위함인데요. 지금부터 차차 읽어가시면 이해가 되실 겁니다.</p>

<p><img src="/assets/2024-01-01-retention-batch-query/last-query-results.webp" alt="" /></p>
<blockquote>
  <p>필자가 직접 작성</p>
</blockquote>

<h1 id="3-일회성-쿼리문">3. 일회성 쿼리문</h1>

<h3 id="31-쿼리문-보기">3.1. 쿼리문 보기</h3>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">WITH</span>

<span class="c1">-- 1. 사용자들의 "참여" (회원가입 및 로그인 이벤트) 소스 테이블을 불러온다.</span>
<span class="n">CTE_engagements</span> <span class="k">AS</span> <span class="p">(</span>
    <span class="k">SELECT</span>
        <span class="n">user_id</span><span class="p">,</span>
        <span class="n">DATE_TRUNC</span><span class="p">(</span><span class="s1">'DAY'</span><span class="p">,</span> <span class="nb">datetime</span><span class="p">)</span> <span class="k">AS</span> <span class="nb">date</span>
    <span class="k">FROM</span>
        <span class="n">signups_logins</span>
    <span class="k">GROUP</span> <span class="k">BY</span>
        <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span>
<span class="p">),</span>

<span class="c1">-- 2. 사용자들을 회원가입일 기준의 코호트로 Labeling해준다.</span>
<span class="n">CTE_cohorts</span> <span class="k">AS</span> <span class="p">(</span>
    <span class="k">SELECT</span>
        <span class="n">user_id</span><span class="p">,</span>
        <span class="k">MIN</span><span class="p">(</span><span class="nb">date</span><span class="p">)</span> <span class="k">AS</span> <span class="n">cohort_date</span>
    <span class="k">FROM</span>
        <span class="n">CTE_engagements</span>
    <span class="k">GROUP</span> <span class="k">BY</span>
        <span class="mi">1</span>
<span class="p">),</span>

<span class="c1">-- 3. 사용자들의 "참여" 테이블과 "코호트 Labeling" 테이블을 조인하여 "Day N"도 함께 표시해준다.</span>
<span class="n">CTE_engagements_with_cohorts_daily</span> <span class="k">AS</span> <span class="p">(</span>
    <span class="k">SELECT</span>
        <span class="n">ENG</span><span class="p">.</span><span class="n">user_id</span><span class="p">,</span>
        <span class="n">ENG</span><span class="p">.</span><span class="nb">date</span><span class="p">,</span>
        <span class="n">COH</span><span class="p">.</span><span class="n">cohort_date</span><span class="p">,</span>
        <span class="n">DATE_DIFF</span><span class="p">(</span>
            <span class="n">ENG</span><span class="p">.</span><span class="nb">date</span><span class="p">,</span>
            <span class="n">COH</span><span class="p">.</span><span class="n">cohort_date</span><span class="p">,</span>
            <span class="k">DAY</span>
        <span class="p">)</span> <span class="k">AS</span> <span class="n">day_n</span>
    <span class="k">FROM</span>
        <span class="n">CTE_engagements</span> <span class="n">ENG</span>
    <span class="k">LEFT</span> <span class="k">JOIN</span>
        <span class="n">CTE_cohorts</span> <span class="n">COH</span>
        <span class="k">USING</span> <span class="p">(</span><span class="n">user_id</span><span class="p">)</span>
<span class="p">),</span>

<span class="c1">-- 4. "Day N"을 "Month N"으로 변환해준다.</span>
<span class="n">CTE_engagements_with_cohorts_monthly</span> <span class="k">AS</span> <span class="p">(</span>
    <span class="k">SELECT</span>
        <span class="n">user_id</span><span class="p">,</span>
        <span class="n">DATE_TRUNC</span><span class="p">(</span><span class="s1">'MONTH'</span><span class="p">,</span> <span class="nb">date</span><span class="p">)</span> <span class="k">AS</span> <span class="n">yyyymm</span><span class="p">,</span>
        <span class="n">DATE_TRUNC</span><span class="p">(</span><span class="s1">'MONTH'</span><span class="p">,</span> <span class="n">cohort_date</span><span class="p">)</span> <span class="k">AS</span> <span class="n">cohort_yyyymm</span><span class="p">,</span>
        <span class="n">DATE_DIFF</span><span class="p">(</span>
            <span class="nb">date</span><span class="p">,</span>
            <span class="n">cohort_date</span><span class="p">,</span>
            <span class="k">MONTH</span>
        <span class="p">)</span> <span class="k">AS</span> <span class="n">month_n</span>
    <span class="k">FROM</span>
        <span class="n">CTE_engagements_with_cohorts_daily</span>
<span class="p">),</span>

<span class="c1">-- 5. 코호트 및 "Month N" 기준으로 사용자 수를 집계한다.</span>
<span class="n">CTE_month_n_cnt</span> <span class="k">AS</span> <span class="p">(</span>
    <span class="k">SELECT</span>
        <span class="n">cohort_yyyymm</span><span class="p">,</span>
        <span class="n">month_n</span><span class="p">,</span>
        <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="n">user_id</span><span class="p">)</span> <span class="k">AS</span> <span class="n">users_cnt</span>
    <span class="k">FROM</span>
        <span class="n">CTE_engagements_with_cohorts_monthly</span>
    <span class="k">GROUP</span> <span class="k">BY</span>
        <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span>
<span class="p">),</span>

<span class="c1">-- 6. 최종 리텐션을 계산한다.</span>
<span class="n">CTE_monthly_retention</span> <span class="k">AS</span> <span class="p">(</span>
    <span class="k">SELECT</span>
        <span class="n">cohort_yyyymm</span><span class="p">,</span>
        <span class="n">month_n</span><span class="p">,</span>
        <span class="k">CAST</span><span class="p">(</span><span class="n">users_cnt</span> <span class="k">AS</span> <span class="nb">DOUBLE</span><span class="p">)</span>
        <span class="o">/</span>
        <span class="k">CAST</span><span class="p">(</span><span class="n">FIRST_VALUE</span><span class="p">(</span><span class="n">users_cnt</span><span class="p">)</span> <span class="n">OVER</span> <span class="p">(</span>
            <span class="k">PARTITION</span> <span class="k">BY</span> <span class="n">cohort_yyyymm</span>
            <span class="k">ORDER</span> <span class="k">BY</span> <span class="n">month_n</span>
            <span class="k">ROWS</span> <span class="k">BETWEEN</span> <span class="n">UNBOUNDED</span> <span class="k">PRECEDING</span> <span class="k">AND</span> <span class="n">UNBOUNDED</span> <span class="k">FOLLOWING</span>
            <span class="p">)</span> <span class="k">AS</span> <span class="nb">DOUBLE</span>
        <span class="p">)</span> <span class="k">AS</span> <span class="n">monthly_retention</span>
    <span class="k">FROM</span>
        <span class="n">CTE_month_n_cnt</span>
    <span class="k">ORDER</span> <span class="k">BY</span>
        <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span>
<span class="p">)</span>
<span class="k">SELECT</span>
    <span class="o">*</span>
<span class="k">FROM</span>
    <span class="n">CTE_monthly_retention</span>
<span class="p">;</span>
</code></pre></div></div>

<h3 id="32-문제점">3.2. 문제점</h3>

<p>위 쿼리문의 출력 결과는 앞서 잠깐 보여드린 아래와 같은 형태의 테이블을 출력합니다. 그런데, 매번 전체 소스 테이블을 메모리에 올려 리텐션을 계산하려면 연산량이 과도하게 많이 들어 리소스 낭비로 이어지게 됩니다.</p>

<p><img src="/assets/2024-01-01-retention-batch-query/last-query-results.webp" alt="" /></p>
<blockquote>
  <p>필자가 직접 작성</p>
</blockquote>

<h1 id="4-해결-아이디어">4. 해결 아이디어</h1>

<p>마침, Cohort 칼럼과 Month 칼럼이 시계열 형식을 지니고 있으므로 미래의 데이터가 과거의 데이터에 영향을 끼칠 수 없습니다. 또한, 출력된 테이블은  <a href="https://www.kimballgroup.com/data-warehouse-business-intelligence-resources/kimball-techniques/dimensional-modeling-techniques/periodic-snapshot-fact-table/">Periodic Snapshot Fact Table</a>의 유형에 해당합니다. 바로 이 점으로부터 우리는 Batch Query를 활용할 수 있는 여지를 발견할 수 있습니다. 즉, 아래와 같이 매월 1일 00:01 UTC마다 새롭게 획득한 리텐션 값들을 Insert할 수 있는 Batch Query를 작성할 수 있는 것입니다. 특히 이벤트 로그 데이터의 크기가 매우 큰 프로덕트를 운영하고 있다면, 굳이 매번 일회성 쿼리문을 실행할 필요가 없는 셈이죠.</p>

<p><img src="/assets/2024-01-01-retention-batch-query/idea.webp" alt="" /></p>
<blockquote>
  <p>즉, 매월 초마다 좌측 테이블의 빨간색 영역들을 순차적으로 신규 계산하여 테이블 Insert 스케줄링을 구현할 수 있는 것이죠. (필자가 직접 작성)</p>
</blockquote>

<h1 id="5-batch-query를-통해-접근하기">5. Batch Query를 통해 접근하기</h1>

<p><strong>STEP 1) 사용자들의 “참여” 소스 테이블을 불러온다. (단, 현재 시점 기준으로 7개월 전의 월초부터 1개월 전의 월말까지 항목만)</strong></p>

<p><img src="/assets/2024-01-01-retention-batch-query/step1.webp" alt="" /></p>
<blockquote>
  <p>필자가 직접 작성</p>
</blockquote>

<ul>
  <li>로그인했을 때 사용자가 “참여”했다고 가정 하에, 로그인 이벤트를 불러온다.</li>
  <li>코호트는 “회원가입” 기준으로 정의할 것이므로, 회원가입 이벤트도 함께 불러온다.</li>
  <li>Monthly Range Retention은 Month 0부터 Month 6까지만 계산한다.</li>
</ul>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">WITH</span>  
  
<span class="c1">-- 1. 사용자들의 "참여" (회원가입 및 로그인 이벤트) 소스 테이블을 불러온다.  </span>
<span class="c1">-- (단, 현재 시점 기준으로 7개월 전의 월초부터 1개월 전의 월말까지 항목만)  </span>
<span class="n">CTE_engagements</span> <span class="k">AS</span> <span class="p">(</span>  
    <span class="k">SELECT</span>  
        <span class="n">user_id</span><span class="p">,</span>  
        <span class="n">DATE_TRUNC</span><span class="p">(</span><span class="s1">'DAY'</span><span class="p">,</span> <span class="nb">datetime</span><span class="p">)</span> <span class="k">AS</span>  <span class="nb">date</span>  
    <span class="k">FROM</span>
        <span class="k">source</span><span class="p">.</span><span class="n">signups_logins</span>
    <span class="nv">"if is_incremental()"</span>
    <span class="k">WHERE</span>  
        <span class="c1">-- 현재 시점 기준으로 7개월 전의 월초부터 ~  </span>
        <span class="n">DATE_TRUNC</span><span class="p">(</span><span class="s1">'MONTH'</span><span class="p">,</span> <span class="k">CURRENT_DATE</span><span class="p">)</span> <span class="o">-</span> <span class="n">INTERVAL</span> <span class="s1">'7'</span> <span class="k">MONTH</span>  
        <span class="o">&lt;=</span> <span class="n">DATE_TRUNC</span><span class="p">(</span><span class="s1">'DAY'</span><span class="p">,</span> <span class="nb">datetime</span><span class="p">)</span>  
        <span class="c1">-- ~ 현재 시점 기준으로 1개월 전의 월말까지  </span>
        <span class="k">AND</span> <span class="n">DATE_TRUNC</span><span class="p">(</span><span class="s1">'DAY'</span><span class="p">,</span> <span class="nb">datetime</span><span class="p">)</span>  
        <span class="o">&lt;=</span> <span class="n">DATE_TRUNC</span><span class="p">(</span><span class="s1">'MONTH'</span><span class="p">,</span> <span class="k">CURRENT_DATE</span><span class="p">)</span> <span class="o">-</span> <span class="n">INTERVAL</span> <span class="s1">'1'</span> <span class="k">DAY</span>  
    <span class="nv">"endif"</span>
    <span class="k">GROUP</span> <span class="k">BY</span>  
        <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span>  
<span class="p">),</span>
</code></pre></div></div>

<p><strong>STEP 2) 사용자들을 회원가입일 기준의 코호트로 Labeling해준다.</strong></p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">-- 2. 사용자들을 회원가입일 기준의 코호트로 Labeling해준다.  </span>
<span class="n">CTE_cohorts</span> <span class="k">AS</span> <span class="p">(</span>  
    <span class="k">SELECT</span>  
        <span class="n">user_id</span><span class="p">,</span>  
        <span class="k">MIN</span><span class="p">(</span><span class="nb">date</span><span class="p">)</span> <span class="k">AS</span> <span class="n">cohort_date</span>  
    <span class="k">FROM</span>  
        <span class="n">CTE_engagements</span>  
    <span class="k">GROUP</span> <span class="k">BY</span>  
        <span class="mi">1</span>  
<span class="p">),</span>
</code></pre></div></div>

<p><strong>STEP 3) 사용자들의 “참여” 테이블과 “코호트 Labeling” 테이블을 조인하여 “Day N”도 함께 표시해준다.</strong></p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">-- 3. 사용자들의 "참여" 테이블과 "코호트 Labeling" 테이블을 조인하여 "Day N"도 함께 표시해준다.  </span>
<span class="n">CTE_engagements_with_cohorts_daily</span> <span class="k">AS</span> <span class="p">(</span>  
    <span class="k">SELECT</span>  
        <span class="n">ENG</span><span class="p">.</span><span class="n">user_id</span><span class="p">,</span>  
        <span class="n">ENG</span><span class="p">.</span><span class="nb">date</span><span class="p">,</span>  
        <span class="n">COH</span><span class="p">.</span><span class="n">cohort_date</span><span class="p">,</span>  
        <span class="n">DATE_DIFF</span><span class="p">(</span>  
            <span class="n">ENG</span><span class="p">.</span><span class="nb">date</span><span class="p">,</span>  
            <span class="n">COH</span><span class="p">.</span><span class="n">cohort_date</span><span class="p">,</span>  
            <span class="k">DAY</span>  
        <span class="p">)</span> <span class="k">AS</span> <span class="n">day_n</span>  
    <span class="k">FROM</span>  
        <span class="n">CTE_engagements</span> <span class="n">ENG</span>  
    <span class="k">LEFT</span> <span class="k">JOIN</span>  
        <span class="n">CTE_cohorts</span> <span class="n">COH</span>  
        <span class="k">USING</span> <span class="p">(</span><span class="n">user_id</span><span class="p">)</span>  
<span class="p">),</span>
</code></pre></div></div>

<p><strong>STEP 4) “Day N”을 “Month N”으로 변환해준다.</strong></p>
<ul>
  <li>Monthly Range Retention을 계산해야 하기 때문이다.</li>
</ul>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">-- 4. "Day N"을 "Month N"으로 변환해준다.  </span>
<span class="n">CTE_engagements_with_cohorts_monthly</span> <span class="k">AS</span> <span class="p">(</span>  
    <span class="k">SELECT</span>  
        <span class="n">user_id</span><span class="p">,</span>  
        <span class="n">DATE_TRUNC</span><span class="p">(</span><span class="s1">'MONTH'</span><span class="p">,</span> <span class="nb">date</span><span class="p">)</span> <span class="k">AS</span> <span class="n">yyyymm</span><span class="p">,</span>  
        <span class="n">DATE_TRUNC</span><span class="p">(</span><span class="s1">'MONTH'</span><span class="p">,</span> <span class="n">cohort_date</span><span class="p">)</span> <span class="k">AS</span> <span class="n">cohort_yyyymm</span><span class="p">,</span>  
        <span class="n">DATE_DIFF</span><span class="p">(</span>  
            <span class="nb">date</span><span class="p">,</span>  
            <span class="n">cohort_date</span><span class="p">,</span>  
            <span class="k">MONTH</span>  
        <span class="p">)</span> <span class="k">AS</span> <span class="n">month_n</span>  
    <span class="k">FROM</span>  
        <span class="n">CTE_engagements_with_cohorts_daily</span>  
<span class="p">),</span>
</code></pre></div></div>

<p><strong>STEP 5) 코호트 및 “Month N” 기준으로 사용자 수를 집계한다.</strong></p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">-- 5. 코호트 및 "Month N" 기준으로 사용자 수를 집계한다.  </span>
<span class="n">CTE_month_n_cnt</span> <span class="k">AS</span> <span class="p">(</span>  
    <span class="k">SELECT</span>  
        <span class="n">cohort_yyyymm</span><span class="p">,</span>  
        <span class="n">month_n</span><span class="p">,</span>  
        <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="n">user_id</span><span class="p">)</span> <span class="k">AS</span> <span class="n">users_cnt</span>  
    <span class="k">FROM</span>  
        <span class="n">CTE_engagements_with_cohorts_monthly</span>  
    <span class="k">GROUP</span> <span class="k">BY</span>  
        <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span>  
<span class="p">),</span>
</code></pre></div></div>

<p><strong>STEP 6) 최종 리텐션을 계산한다.</strong></p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">-- 6. 최종 리텐션을 계산한다.  </span>
<span class="n">CTE_monthly_retention</span> <span class="k">AS</span> <span class="p">(</span>  
    <span class="k">SELECT</span>  
        <span class="n">cohort_yyyymm</span><span class="p">,</span>  
        <span class="n">month_n</span><span class="p">,</span>  
        <span class="k">CAST</span><span class="p">(</span><span class="n">users_cnt</span> <span class="k">AS</span> <span class="nb">DOUBLE</span><span class="p">)</span>  
        <span class="o">/</span>  
        <span class="k">CAST</span><span class="p">(</span><span class="n">FIRST_VALUE</span><span class="p">(</span><span class="n">users_cnt</span><span class="p">)</span> <span class="n">OVER</span> <span class="p">(</span>  
            <span class="k">PARTITION</span> <span class="k">BY</span> <span class="n">cohort_yyyymm</span>  
            <span class="k">ORDER</span> <span class="k">BY</span> <span class="n">month_n</span>  
            <span class="k">ROWS</span> <span class="k">BETWEEN</span> <span class="n">UNBOUNDED</span> <span class="k">PRECEDING</span> <span class="k">AND</span> <span class="n">UNBOUNDED</span> <span class="k">FOLLOWING</span>  
        <span class="p">)</span>  
        <span class="k">AS</span> <span class="n">monthly_retention</span>  
    <span class="k">FROM</span>  
        <span class="n">CTE_month_n_cnt</span>  
    <span class="k">ORDER</span> <span class="k">BY</span>  
        <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span>  
<span class="p">)</span>
</code></pre></div></div>

<p><strong>STEP 7) 중복되지 않은 신규 항목들만 Insert할 수 있도록 조건화한다.</strong></p>

<p><img src="/assets/2024-01-01-retention-batch-query/step7.webp" alt="" /></p>
<blockquote>
  <p>필자가 직접 작성</p>
</blockquote>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">-- 7. 중복되지 않은 신규 항목들만 Insert할 수 있도록 조건화한다.  </span>
<span class="n">CTE_monthly_retention_inserted</span> <span class="k">AS</span> <span class="p">(</span>  
    <span class="k">SELECT</span>  
        <span class="o">*</span>  
    <span class="k">FROM</span>  
        <span class="n">CTE_monthly_retention</span>  
    <span class="nv">"if is_incremental()"</span>
    <span class="k">WHERE</span>  
        <span class="c1">-- 현재 시점 기준으로 1개월 전의 코호트: Month 0 리텐션 값만 Insert한다.  </span>
        <span class="p">(</span><span class="n">cohort_yyyymm</span> <span class="o">=</span> <span class="n">DATE_TRUNC</span><span class="p">(</span><span class="s1">'MONTH'</span><span class="p">,</span> <span class="k">CURRENT_DATE</span><span class="p">)</span> <span class="o">-</span> <span class="n">INTERVAL</span> <span class="s1">'1'</span> <span class="k">MONTH</span> <span class="k">AND</span> <span class="n">month_n</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>  
        <span class="c1">-- 현재 시점 기준으로 2개월 전의 코호트: Month 1 리텐션 값만 Insert한다.  </span>
        <span class="k">OR</span> <span class="p">(</span><span class="n">cohort_yyyymm</span> <span class="o">=</span> <span class="n">DATE_TRUNC</span><span class="p">(</span><span class="s1">'MONTH'</span><span class="p">,</span> <span class="k">CURRENT_DATE</span><span class="p">)</span> <span class="o">-</span> <span class="n">INTERVAL</span> <span class="s1">'2'</span> <span class="k">MONTH</span> <span class="k">AND</span> <span class="n">month_n</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>  
        <span class="c1">-- 현재 시점 기준으로 3개월 전의 코호트: Month 2 리텐션 값만 Insert한다.  </span>
        <span class="k">OR</span> <span class="p">(</span><span class="n">cohort_yyyymm</span> <span class="o">=</span> <span class="n">DATE_TRUNC</span><span class="p">(</span><span class="s1">'MONTH'</span><span class="p">,</span> <span class="k">CURRENT_DATE</span><span class="p">)</span> <span class="o">-</span> <span class="n">INTERVAL</span> <span class="s1">'3'</span> <span class="k">MONTH</span> <span class="k">AND</span> <span class="n">month_n</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span>  
        <span class="c1">-- 현재 시점 기준으로 4개월 전의 코호트: Month 3 리텐션 값만 Insert한다.  </span>
        <span class="k">OR</span> <span class="p">(</span><span class="n">cohort_yyyymm</span> <span class="o">=</span> <span class="n">DATE_TRUNC</span><span class="p">(</span><span class="s1">'MONTH'</span><span class="p">,</span> <span class="k">CURRENT_DATE</span><span class="p">)</span> <span class="o">-</span> <span class="n">INTERVAL</span> <span class="s1">'4'</span> <span class="k">MONTH</span> <span class="k">AND</span> <span class="n">month_n</span> <span class="o">=</span> <span class="mi">3</span><span class="p">)</span>  
        <span class="c1">-- 현재 시점 기준으로 5개월 전의 코호트: Month 4 리텐션 값만 Insert한다.  </span>
        <span class="k">OR</span> <span class="p">(</span><span class="n">cohort_yyyymm</span> <span class="o">=</span> <span class="n">DATE_TRUNC</span><span class="p">(</span><span class="s1">'MONTH'</span><span class="p">,</span> <span class="k">CURRENT_DATE</span><span class="p">)</span> <span class="o">-</span> <span class="n">INTERVAL</span> <span class="s1">'5'</span> <span class="k">MONTH</span> <span class="k">AND</span> <span class="n">month_n</span> <span class="o">=</span> <span class="mi">4</span><span class="p">)</span>  
        <span class="c1">-- 현재 시점 기준으로 6개월 전의 코호트: Month 5 리텐션 값만 Insert한다.  </span>
        <span class="k">OR</span> <span class="p">(</span><span class="n">cohort_yyyymm</span> <span class="o">=</span> <span class="n">DATE_TRUNC</span><span class="p">(</span><span class="s1">'MONTH'</span><span class="p">,</span> <span class="k">CURRENT_DATE</span><span class="p">)</span> <span class="o">-</span> <span class="n">INTERVAL</span> <span class="s1">'6'</span> <span class="k">MONTH</span> <span class="k">AND</span> <span class="n">month_n</span> <span class="o">=</span> <span class="mi">5</span><span class="p">)</span>  
        <span class="c1">-- 현재 시점 기준으로 7개월 전의 코호트: Month 6 리텐션 값만 Insert한다.  </span>
        <span class="k">OR</span> <span class="p">(</span><span class="n">cohort_yyyymm</span> <span class="o">=</span> <span class="n">DATE_TRUNC</span><span class="p">(</span><span class="s1">'MONTH'</span><span class="p">,</span> <span class="k">CURRENT_DATE</span><span class="p">)</span> <span class="o">-</span> <span class="n">INTERVAL</span> <span class="s1">'7'</span> <span class="k">MONTH</span> <span class="k">AND</span> <span class="n">month_n</span> <span class="o">=</span> <span class="mi">6</span><span class="p">)</span>  
    <span class="nv">"endif"</span>
    <span class="k">ORDER</span> <span class="k">BY</span>  
        <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span>  
<span class="p">)</span>
</code></pre></div></div>

<p><strong>STEP 8) 출력한다.</strong></p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">SELECT</span>  
    <span class="o">*</span>  
<span class="k">FROM</span>  
    <span class="n">CTE_monthly_retention_inserted</span>  
<span class="p">;</span>
</code></pre></div></div>

<h1 id="6-결론">6. 결론</h1>

<p>Data Mart나 Batch Query에 대한 이론은 누구나 쉽게 온라인에서 공부할 수 있지만, 실제 Metrics 별로 모범이 될 만한 레퍼런스를 찾기가 어려운 것 같습니다. 특히, 리텐션의 경우 분명히 일회성 쿼리의 문제점을 해결해야 할 필요성이 클 것임에도 불구하고 저는 개인적으로 구글링을 통해서 적절한 레퍼런스를 전혀 찾지 못했습니다. 그래서 이참에 퍼블릭 레퍼런스를 제가 한 번 만들어보자는 결심이 들어 이렇게 글을 적어봤습니다.</p>

<p>그러나 저의 레퍼런스가 절대로 정답은 아닐 것입니다. Batch Query 모범 사례를 찾기 어렵다는 점은 그만큼 각 프로덕트의 도메인 특수성과 데이터의 형태가 극명하게 달라 절대불변의 정답이 없다는 의미일지도 모르겠습니다.</p>

<p>그러므로, 저의 사례는 가볍게 참고만 해주시고, 독자 분들께서 처한 다양한 특수성에 따라 가장 효율적인 리텐션 측정 환경을 구축하시길 바라겠습니다. 물론, 저의 논리적 오류나 개선 방향에 대한 피드백도 언제나 감사히 받겠습니다. 읽어주셔서 감사합니다.</p>

<hr />

<h2 id="published-by-joshua-kim"><em>Published by</em> Joshua Kim</h2>
<p><img src="/assets/profile/joshua-profile.png" alt="Joshua Kim" /></p>]]></content><author><name></name></author><category term="Korean" /><category term="Data Analysis" /><category term="SQL" /><category term="Data Warehouse" /><summary type="html"><![CDATA[코호트 리텐션의 의미와 중요성에 대해 말씀드리고, Batch Query를 사용하여 회원가입 월 코호트 별로 Monthly Range Retention을 계산하는 방법을 제시해드릴게요.]]></summary></entry><entry><title type="html">데이터 분석가의 SQL 최적화 일기: SELF JOIN을 피하는 방법</title><link href="http://localhost:4000/how-to-avoid-self-joins/" rel="alternate" type="text/html" title="데이터 분석가의 SQL 최적화 일기: SELF JOIN을 피하는 방법" /><published>2023-11-30T00:00:00+09:00</published><updated>2023-11-30T00:00:00+09:00</updated><id>http://localhost:4000/how-to-avoid-self-joins</id><content type="html" xml:base="http://localhost:4000/how-to-avoid-self-joins/"><![CDATA[<blockquote>
  <p>대고객 서빙을 위해 엄청나게 큰 사이즈의 소스 테이블로부터 최적화된 데이터 마트 설계 고민을 많이 하고 있는 만큼, 이번에는 SELF JOIN 사례를 중심으로 SQL 성능에 대한 이야기를 들려드리겠습니다.</p>
</blockquote>

<h3 id="contents">CONTENTS</h3>
<ol>
  <li>들어가는 글</li>
  <li>Python과 달리 거칠게 사고해야 하는 SQL</li>
  <li>SELF JOIN을 하면 연산량이 제곱으로 늘어난다.</li>
  <li>Subquery와 EXISTS 사용하기</li>
  <li>결론: 무조건적 우월성은 없다.</li>
</ol>

<hr />

<h3 id="disclaimer">DISCLAIMER</h3>

<p>본 자료는 작성자 본인의 견해일 뿐이며, 실제 데이터베이스의 환경에 따라 적합하지 않을 수 있습니다. 이미지 출처를 제외한 모든 쿼리문과 내용은 본인의 경험에 의해 작성되었습니다. 작성된 쿼리문은 샘플로 작성한 것이며, 본인의 과거 및 현재 재직 회사의 업무 현황과 무관합니다.</p>

<h1 id="1-들어가는-글">1. 들어가는 글</h1>

<p><img src="/assets/2023-11-30-how-to-avoid-self-joins/join-meme.webp" alt="" /></p>
<blockquote>
  <p><a href="https://miro.medium.com/v2/resize:fit:800/1*DTET9ngrx2Gzu6ZJk0G9BQ.jpeg">Source</a></p>
</blockquote>

<p>안녕하세요. 저는 친구들 얼굴을 보면 위와 같은 이상한 생각을 하는 데이터 분석가 Joshua라고 합니다.</p>

<p>저는 일반적인 B2C 기업에서 데이터 분석가로 근무하며, GA4, Amplitude, BigQuery, Redash 등을 활용하여 A/B 테스트, 지표 모니터링 등을 수행하며 회사의 등대 역할을 하며 지냈습니다. 다른 분들과 비슷한 역할을 수행했던 것이죠.</p>

<p>또한 GA4, Amplitude 등과 같은 B2B 데이터 분석 플랫폼 서비스를 만드는 경험도 살짝 했는데요. 그러다보니 저의 R&amp;R은 서비스 자체의 데이터 분석 업무 외에도, 고객들에게 데이터를 서빙하기 위한 데이터 마트 설계와 최적화 업무에 집중되기도 했습니다. 제 타이틀을 멋있게 가공하면 최근에 떠오르는 포지션인 Analytics Engineer, 반쪽 짜리 데이터 엔지니어, 아니면 대충 쿼리 머신 혹은 분지니어(?)인 것 같기도 합니다. 😅</p>

<p>대고객 서빙을 위해 엄청나게 큰 사이즈의 소스 테이블로부터 최적화된 데이터 마트 설계 고민을 많이 하고 있는 만큼, 이번에는 SELF JOIN 사례를 중심으로 SQL 성능에 대한 이야기를 들려드리겠습니다.
(SQL 전문가 분들이 많이 계시는 만큼, 제 글을 비판적으로 고찰해주시면 감사하겠습니다! 😄)</p>

<p>쿼리로 고통 받으며 눈동자에 비가 내렸던 경험 이야기, 시작합니다! (울지마~ 울지마~ 울지마~)</p>

<p><img src="/assets/2023-11-30-how-to-avoid-self-joins/crying-cat-meme.avif" alt="" /></p>
<blockquote>
  <p><a href="https://www.google.com/url?sa=i&amp;url=https%3A%2F%2Fwww.dailydot.com%2Fnews%2Fcat-crying-memes-explainer%2F&amp;psig=AOvVaw1JpDJ5k_6Tx93h2YT8in_Y&amp;ust=1702536707113000&amp;source=images&amp;cd=vfe&amp;opi=89978449&amp;ved=0CBMQjRxqFwoTCMC01dLpi4MDFQAAAAAdAAAAABAD">Source</a></p>
</blockquote>

<h1 id="2-python과-달리-거칠게-사고해야-하는-sql">2. Python과 달리 거칠게 사고해야 하는 SQL</h1>

<p>SQL을 통해 OLAP(Online Analytical Processing)에 해당하는 데이터 웨어하우스를 구축하다보면, 종종  <strong>SELF JOIN</strong>이 필요합니다. 가령, 소스 테이블의 복사본인 Staging Table을 Pivoting 해야 하거나, 칼럼 A와 칼럼 B 간의 관계 규칙을 찾아 Data Cleaning을 해야 하는 경우에 특히 발생하는 것 같았어요.</p>

<p>가령, Python의 Pandas Dataframe 환경에서는 메소드를 통해 너무나도 쉽게 Pivoting을 하거나, 반복문과 조건문을 통해 칼럼 사이의 관계 규칙을 고작 몇 줄 코드 만으로 Data Cleaning을 할 수 있을 것입니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pandas</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">.</span><span class="n">pivot</span>
<span class="n">pandas</span><span class="p">.</span><span class="nf">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">value</span> <span class="k">if</span> <span class="n">condition</span> <span class="ow">is</span> <span class="n">true</span> <span class="k">if</span> <span class="n">x</span> <span class="n">condition</span> <span class="k">else</span> <span class="n">value</span> <span class="n">of</span> <span class="n">condition</span> <span class="ow">is</span> <span class="n">false</span><span class="p">)</span>
</code></pre></div></div>

<p>하지만 안타깝게도 SQL에서는 다소 거친 방법으로 쿼리문을 작성해야 하므로 좀 더 테이블 자체를 기반의 Logical Thinking을 하는 것이 중요합니다.</p>

<p>가령 다음 기본적인 사례와 같이, 국가 별로 MAU를 집계할 경우에 SQL은 훨씬 거칠게 표현합니다.</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">SELECT</span>  
   <span class="n">DATE_TRUNC</span><span class="p">(</span><span class="s1">'MONTH'</span><span class="p">,</span> <span class="nb">datetime</span><span class="p">)</span> <span class="k">AS</span> <span class="n">yyyymm</span><span class="p">,</span>  
   <span class="n">country</span><span class="p">,</span>  
   <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="n">user_id</span><span class="p">)</span> <span class="k">AS</span> <span class="n">mau</span>  
<span class="k">FROM</span>  
   <span class="n">source_events</span>  
<span class="k">GROUP</span> <span class="k">BY</span>  
   <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span>  
<span class="k">ORDER</span> <span class="k">BY</span>  
   <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span>  
<span class="p">;</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">source_events</span><span class="p">[</span><span class="sh">'</span><span class="s">yyyymm</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">to_datetime</span><span class="p">(</span><span class="n">source_events</span><span class="p">[</span><span class="sh">'</span><span class="s">datetime</span><span class="sh">'</span><span class="p">]).</span><span class="n">dt</span><span class="p">.</span><span class="nf">to_period</span><span class="p">(</span><span class="sh">'</span><span class="s">M</span><span class="sh">'</span><span class="p">)</span>  
<span class="n">result_df</span> <span class="o">=</span> <span class="n">source_events</span><span class="p">.</span><span class="nf">groupby</span><span class="p">([</span><span class="sh">'</span><span class="s">yyyymm</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">country</span><span class="sh">'</span><span class="p">]).</span><span class="nf">agg</span><span class="p">(</span><span class="n">mau</span><span class="o">=</span><span class="p">(</span><span class="sh">'</span><span class="s">user_id</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">nunique</span><span class="sh">'</span><span class="p">)).</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>  
<span class="n">result_df</span> <span class="o">=</span> <span class="n">result_df</span><span class="p">.</span><span class="nf">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">yyyymm</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">country</span><span class="sh">'</span><span class="p">]).</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>  
<span class="nf">print</span><span class="p">(</span><span class="n">result_df</span><span class="p">)</span>
</code></pre></div></div>

<p>즉, 파이썬의  <code class="language-plaintext highlighter-rouge">to_period</code>,  <code class="language-plaintext highlighter-rouge">groupby</code>,  <code class="language-plaintext highlighter-rouge">nunique</code>  등과 같은 내장 메소드의 연산 원리를 이해하여 이를  <code class="language-plaintext highlighter-rouge">DATE_TRUNC</code>,  <code class="language-plaintext highlighter-rouge">COUNT(DISTINCT …)</code>,  <code class="language-plaintext highlighter-rouge">GROUP BY</code>  등의 SQL 함수와 Statement로 표현해야 하는 것이죠.</p>

<h1 id="3-self-join을-하면-연산량이-제곱으로-늘어난다">3. SELF JOIN을 하면 연산량이 제곱으로 늘어난다.</h1>

<p>먼저 다음과 같은 쿼리문 사례를 살펴보도록 하죠.</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">SELECT</span>  
   <span class="n">MAIN</span><span class="p">.</span><span class="nb">datetime</span><span class="p">,</span>  
   <span class="n">MAIN</span><span class="p">.</span><span class="n">user_id</span><span class="p">,</span>  
   <span class="n">MAIN</span><span class="p">.</span><span class="n">session_id</span><span class="p">,</span>  
   <span class="n">MAIN</span><span class="p">.</span><span class="n">event_index</span><span class="p">,</span>  
   <span class="n">MAIN</span><span class="p">.</span><span class="n">event_param_index</span><span class="p">,</span>  
   <span class="n">MAIN</span><span class="p">.</span><span class="n">event_param_key</span><span class="p">,</span>  
   <span class="n">MAIN</span><span class="p">.</span><span class="n">event_param_value</span>  
<span class="k">FROM</span>  
   <span class="n">source_events</span> <span class="n">MAIN</span>  
<span class="k">LEFT</span> <span class="k">JOIN</span>  
   <span class="n">source_events</span> <span class="n">SUB</span>  
   <span class="k">ON</span> <span class="n">MAIN</span><span class="p">.</span><span class="n">user_id</span> <span class="o">=</span> <span class="n">SUB</span><span class="p">.</span><span class="n">user_id</span>  
      <span class="k">AND</span> <span class="n">MAIN</span><span class="p">.</span><span class="n">session_id</span> <span class="o">=</span> <span class="n">SUB</span><span class="p">.</span><span class="n">session_id</span>  
      <span class="k">AND</span> <span class="n">MAIN</span><span class="p">.</span><span class="n">event_index</span> <span class="o">=</span> <span class="n">SUB</span><span class="p">.</span><span class="n">event_index</span>  
<span class="k">WHERE</span>  
   <span class="n">MAIN</span><span class="p">.</span><span class="n">event_param_index</span> <span class="o">=</span> <span class="n">SUB</span><span class="p">.</span><span class="n">event_param_index</span> <span class="o">+</span> <span class="mi">0</span>  
   <span class="k">OR</span> <span class="n">MAIN</span><span class="p">.</span><span class="n">event_param_index</span> <span class="o">=</span> <span class="n">SUB</span><span class="p">.</span><span class="n">event_param_index</span> <span class="o">+</span> <span class="mi">1</span>  
   <span class="k">OR</span> <span class="n">MAIN</span><span class="p">.</span><span class="n">event_param_index</span> <span class="o">=</span> <span class="n">SUB</span><span class="p">.</span><span class="n">event_param_index</span> <span class="o">+</span> <span class="mi">2</span>  
   <span class="k">OR</span> <span class="n">MAIN</span><span class="p">.</span><span class="n">event_param_index</span> <span class="o">=</span> <span class="n">SUB</span><span class="p">.</span><span class="n">event_param_index</span> <span class="o">+</span> <span class="mi">3</span>
</code></pre></div></div>

<p>위 사례는 가령 이런 상황으로 이해하시면 될 것 같습니다. 사용자의 이벤트 로그 소스 테이블에서 각 이벤트의 파라미터 key-value가 unnested된 상태로 존재하거나, 혹은 특정 파라미터의 index를 기준으로 인접한 파라미터 정보들만 추출해야 하는 상황에서 위와 같은 쿼리문 작성이 필요할 것입니다.</p>

<p>SQL의 연산 과정은  <strong>FROM → XXX JOIN → WHERE → GROUP BY → SELECT → HAVING → ORDER BY</strong>  등의 순으로 진행되는데요. 위 쿼리문을 연산하는 과정에서 WHERE Statement에 진입하기 전에, 먼저 FROM과 LEFT JOIN을 통해 모든 Row를 메모리에 로드하게 됩니다.</p>

<p><img src="/assets/2023-11-30-how-to-avoid-self-joins/sql-processing.webp" alt="" /></p>
<blockquote>
  <p><a href="https://blog.kakaocdn.net/dn/ckOt66/btrjP1TVZsq/Ta9JdTTiEd9tddkKkFk2n1/img.png">Source</a></p>
</blockquote>

<p>가령,  <code class="language-plaintext highlighter-rouge">source_events</code>  테이블이 1,000,000개의 Row로 구성되어 있다면, 최대 1,000,000 * 1,000,000개의 Row가 메모리에 올라오게 되는 것이죠. 이는 쿼리 엔진의 메모리 및 트래픽 DevOps 환경이 중요한 경우 분명히 문제가 됩니다. 혹은 Usage Limit이 걸려 있을 경우에는 쿼리 실행이 몇 시간 동안 진행되다가 아침에 눈을 떠보면 트래픽 제한으로 인해 실행이 실패되었다는 매우 슬프고 참담한 상황에 마주하게 될 것입니다.</p>

<p><img src="/assets/2023-11-30-how-to-avoid-self-joins/crying-meme.webp" alt="" /></p>
<blockquote>
  <p><a href="https://res.heraldm.com/content/image/2021/07/16/20210716000671_0.jpg">Source</a></p>
</blockquote>

<p>그렇다면, 이런 상황에서 어떻게 쿼리를 최적화할 수 있을까요?</p>

<h1 id="4-subquery와-exists-사용하기">4. Subquery와 EXISTS 사용하기</h1>

<p>위에서 보셨던 쿼리문을 아래와 같이 수정해봤습니다.</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">SELECT</span>  
   <span class="nb">datetime</span><span class="p">,</span>  
   <span class="n">user_id</span><span class="p">,</span>  
   <span class="n">session_id</span><span class="p">,</span>  
   <span class="n">event_index</span><span class="p">,</span>  
   <span class="n">event_param_index</span><span class="p">,</span>  
   <span class="n">event_param_key</span><span class="p">,</span>  
   <span class="n">event_param_value</span>  
<span class="k">FROM</span>  
   <span class="n">source_events</span> <span class="n">MAIN</span>  
<span class="k">WHERE</span>  
   <span class="k">EXISTS</span> <span class="p">(</span>  
      <span class="k">SELECT</span> <span class="mi">1</span>  
      <span class="k">FROM</span> <span class="n">source_events</span> <span class="n">SUB</span>  
      <span class="k">WHERE</span>  
         <span class="n">event_type</span> <span class="o">=</span> <span class="s1">'click_button'</span>  
         <span class="k">AND</span> <span class="n">MAIN</span><span class="p">.</span><span class="n">user_id</span> <span class="o">=</span> <span class="n">SUB</span><span class="p">.</span><span class="n">user_id</span>  
         <span class="k">AND</span> <span class="n">MAIN</span><span class="p">.</span><span class="n">session_id</span> <span class="o">=</span> <span class="n">SUB</span><span class="p">.</span><span class="n">session_id</span>  
         <span class="k">AND</span> <span class="n">MAIN</span><span class="p">.</span><span class="n">event_index</span> <span class="o">=</span> <span class="n">SUB</span><span class="p">.</span><span class="n">event_index</span>  
         <span class="k">AND</span> <span class="p">(</span>  
            <span class="n">MAIN</span><span class="p">.</span><span class="n">event_param_index</span> <span class="o">=</span> <span class="n">SUB</span><span class="p">.</span><span class="n">event_param_index</span> <span class="o">+</span> <span class="mi">0</span>  
            <span class="k">OR</span> <span class="n">MAIN</span><span class="p">.</span><span class="n">event_param_index</span> <span class="o">=</span> <span class="n">SUB</span><span class="p">.</span><span class="n">event_param_index</span> <span class="o">+</span> <span class="mi">1</span>  
            <span class="k">OR</span> <span class="n">MAIN</span><span class="p">.</span><span class="n">event_param_index</span> <span class="o">=</span> <span class="n">SUB</span><span class="p">.</span><span class="n">event_param_index</span> <span class="o">+</span> <span class="mi">2</span>  
            <span class="k">OR</span> <span class="n">MAIN</span><span class="p">.</span><span class="n">event_param_index</span> <span class="o">=</span> <span class="n">SUB</span><span class="p">.</span><span class="n">event_param_index</span> <span class="o">+</span> <span class="mi">3</span>  
         <span class="p">)</span>  
   <span class="p">)</span>
</code></pre></div></div>

<p>자, 어떻게 달라졌는지 차근차근 살펴보도록 하죠.</p>

<h3 id="1-먼저-left-join이-사라지고-where-statement의-subquery가-추가되었습니다">1. 먼저, LEFT JOIN이 사라지고, WHERE Statement의 Subquery가 추가되었습니다.</h3>

<p>JOIN보다 Subquery가 반드시 모든 상황에서 성능이 우월하지는 않지만, 이 상황에서는 메모리 데이터의 사이즈는 상당 부분 해소되었습니다. 앞서 말씀 드린 것처럼, SQL은 WHERE Statement를 고려하기 전에 먼저 FROM과 LEFT JOIN을 먼저 실행하게 되는데, WHERE Statement의 Subquery로 옮김으로써 LEFT JOIN에서 실행되어야 하는 작업을 WHERE에서 동시에 연산하여 메모리에 올릴 수 있게 되었습니다.</p>

<p>가령,  <code class="language-plaintext highlighter-rouge">source_events</code>  테이블의 Row 수가 1,000,000개 이고, WHERE를 통해 Filter out된 Row 수가 10,000개라면, 메모리에 올라가게 되는 Row 수는 이전의 최대 1,000,000 * 1,000,000개에서 1,000,000 * 10,000개로 1% 수준으로 급감하였습니다.</p>

<h3 id="2-in보다-exists가-연산-속도가-더-빠릅니다">2. IN보다 EXISTS가 연산 속도가 더 빠릅니다.</h3>

<p>IN과 EXISTS 모두 “<strong>XXX한 경우가 존재하니?</strong>”를 질문하는 과정으로 추상화할 수 있을 것 같은데요.</p>

<p>만약 IN을 통해 Filter out하려고 하면 가령 아래와 같은 쿼리문을 작성해야 합니다.</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">WHERE</span>  
   <span class="n">MAIN</span><span class="p">.</span><span class="n">event_param_index</span> <span class="k">IN</span> <span class="p">(</span><span class="k">SELECT</span> <span class="n">SUB</span><span class="p">.</span><span class="n">event_param_index</span> <span class="o">+</span> <span class="mi">0</span> <span class="k">FROM</span> <span class="p">...)</span>  
   <span class="k">AND</span> <span class="n">MAIN</span><span class="p">.</span><span class="n">event_param_index</span> <span class="k">IN</span> <span class="p">(</span><span class="k">SELECT</span> <span class="n">SUB</span><span class="p">.</span><span class="n">event_param_index</span> <span class="o">+</span> <span class="mi">1</span> <span class="k">FROM</span> <span class="p">...)</span>  
   <span class="k">AND</span> <span class="n">MAIN</span><span class="p">.</span><span class="n">event_param_index</span> <span class="k">IN</span> <span class="p">(</span><span class="k">SELECT</span> <span class="n">SUB</span><span class="p">.</span><span class="n">event_param_index</span> <span class="o">+</span> <span class="mi">2</span> <span class="k">FROM</span> <span class="p">...)</span>  
   <span class="k">AND</span> <span class="n">MAIN</span><span class="p">.</span><span class="n">event_param_index</span> <span class="k">IN</span> <span class="p">(</span><span class="k">SELECT</span> <span class="n">SUB</span><span class="p">.</span><span class="n">event_param_index</span> <span class="o">+</span> <span class="mi">3</span> <span class="k">FROM</span> <span class="p">...)</span>  
<span class="p">...</span>
</code></pre></div></div>

<p>위 과정은 한 가지 단점이 있습니다.  <code class="language-plaintext highlighter-rouge">SUB.event_param_index</code>  칼럼의 값들을 일일이 출력해야 하는데요. 즉, 다양한 값들로 구성된 칼럼을 메모리에 로드해야 한다는 것이죠.</p>

<p>그러나 EXISTS를 통해 Filter out하려고 하면 아래와 같은 쿼리문으로 수정될 수 있습니다.</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">WHERE</span>  
   <span class="k">EXISTS</span> <span class="p">(</span>  
      <span class="k">SELECT</span> <span class="mi">1</span>  
      <span class="k">FROM</span> <span class="p">...</span>  
      <span class="k">WHERE</span>  
         <span class="p">...</span>  
         <span class="k">AND</span> <span class="p">(</span>  
         <span class="n">MAIN</span><span class="p">.</span><span class="n">event_param_index</span> <span class="o">=</span> <span class="n">SUB</span><span class="p">.</span><span class="n">event_param_index</span> <span class="o">+</span> <span class="mi">0</span>  
         <span class="k">OR</span> <span class="n">MAIN</span><span class="p">.</span><span class="n">event_param_index</span> <span class="o">=</span> <span class="n">SUB</span><span class="p">.</span><span class="n">event_param_index</span> <span class="o">+</span> <span class="mi">1</span>  
         <span class="k">OR</span> <span class="n">MAIN</span><span class="p">.</span><span class="n">event_param_index</span> <span class="o">=</span> <span class="n">SUB</span><span class="p">.</span><span class="n">event_param_index</span> <span class="o">+</span> <span class="mi">2</span>  
         <span class="k">OR</span> <span class="n">MAIN</span><span class="p">.</span><span class="n">event_param_index</span> <span class="o">=</span> <span class="n">SUB</span><span class="p">.</span><span class="n">event_param_index</span> <span class="o">+</span> <span class="mi">3</span>  
   <span class="p">)</span>
</code></pre></div></div>

<p>이 과정은 위에서 말씀 드린 IN의 단점을 상당 부분 해소합니다.  <code class="language-plaintext highlighter-rouge">SUB.event_param_index</code>  칼럼의 값들을 일일이 출력했던 것과 달리, 이번에는 조건을 만족하기만 하면 단순히 일괄적으로  <code class="language-plaintext highlighter-rouge">1</code>로만 구성된 칼럼을 메모리에 로드하게 됩니다. Data Type 측면에서 훨씬 메모리의 부담을 경감시킬 수 있습니다. (혹은 <code class="language-plaintext highlighter-rouge">1</code>이 아니라,  <code class="language-plaintext highlighter-rouge">True</code>나  <code class="language-plaintext highlighter-rouge">False</code>와 같은 Boolean 타입으로 출력하면 더 확실하게 경감시킬 수 있을 것 같네요.)</p>

<h1 id="5-결론-무조건적-우월성은-없다">5. 결론: 무조건적 우월성은 없다.</h1>

<p>자 이제 다시 최적화된 쿼리문 전체를 보시죠.</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">SELECT</span>  
   <span class="nb">datetime</span><span class="p">,</span>  
   <span class="n">user_id</span><span class="p">,</span>  
   <span class="n">session_id</span><span class="p">,</span>  
   <span class="n">event_index</span><span class="p">,</span>  
   <span class="n">event_param_index</span><span class="p">,</span>  
   <span class="n">event_param_key</span><span class="p">,</span>  
   <span class="n">event_param_value</span>  
<span class="k">FROM</span>  
   <span class="n">source_events</span> <span class="n">MAIN</span>  
<span class="k">WHERE</span>  
   <span class="k">EXISTS</span> <span class="p">(</span>  
      <span class="k">SELECT</span> <span class="mi">1</span>  
      <span class="k">FROM</span> <span class="n">source_events</span> <span class="n">SUB</span>  
      <span class="k">WHERE</span>  
         <span class="n">event_type</span> <span class="o">=</span> <span class="s1">'click_button'</span>  
         <span class="k">AND</span> <span class="n">MAIN</span><span class="p">.</span><span class="n">user_id</span> <span class="o">=</span> <span class="n">SUB</span><span class="p">.</span><span class="n">user_id</span>  
         <span class="k">AND</span> <span class="n">MAIN</span><span class="p">.</span><span class="n">session_id</span> <span class="o">=</span> <span class="n">SUB</span><span class="p">.</span><span class="n">session_id</span>  
         <span class="k">AND</span> <span class="n">MAIN</span><span class="p">.</span><span class="n">event_index</span> <span class="o">=</span> <span class="n">SUB</span><span class="p">.</span><span class="n">event_index</span>  
         <span class="k">AND</span> <span class="p">(</span>  
            <span class="n">MAIN</span><span class="p">.</span><span class="n">event_param_index</span> <span class="o">=</span> <span class="n">SUB</span><span class="p">.</span><span class="n">event_param_index</span> <span class="o">+</span> <span class="mi">0</span>  
            <span class="k">OR</span> <span class="n">MAIN</span><span class="p">.</span><span class="n">event_param_index</span> <span class="o">=</span> <span class="n">SUB</span><span class="p">.</span><span class="n">event_param_index</span> <span class="o">+</span> <span class="mi">1</span>  
            <span class="k">OR</span> <span class="n">MAIN</span><span class="p">.</span><span class="n">event_param_index</span> <span class="o">=</span> <span class="n">SUB</span><span class="p">.</span><span class="n">event_param_index</span> <span class="o">+</span> <span class="mi">2</span>  
            <span class="k">OR</span> <span class="n">MAIN</span><span class="p">.</span><span class="n">event_param_index</span> <span class="o">=</span> <span class="n">SUB</span><span class="p">.</span><span class="n">event_param_index</span> <span class="o">+</span> <span class="mi">3</span>  
         <span class="p">)</span>  
   <span class="p">)</span>
</code></pre></div></div>

<p>프로그래밍에는 반드시 “<strong>방법 A가 방법 B보다 우월하다.</strong>”라는 것은 존재하지 않은 것처럼, 각자의 환경에 따라 취사선택하며 최적화를 하는 것이 중요할 것입니다.</p>

<p>WHERE Statement의 Subquery가 JOIN보다 반드시 우월한 것도 아니고, 경우에 따라 EXISTS가 IN보다 반드시 뛰어난 성능을 보이지 않을 수도 있습니다.</p>

<p>또한, 일반적으로 Subquery와 EXISTS 문법은 SQL 초급 사용자 분들께는 살짝 팔로업하기 어려울 수 있으므로, 가독성 측면에서 추후 유지보수의 장애로 작용할 수도 있을 것입니다.</p>

<p><img src="/assets/2023-11-30-how-to-avoid-self-joins/infinite-challenge.webp" alt="" /></p>
<blockquote>
  <p><a href="https://i.pinimg.com/736x/cd/c3/57/cdc35735e9efc721d26a0f3f780178a4.jpg">Source</a></p>
</blockquote>

<p>앞으로, 대용량의 데이터 소스를 다루시다가 SELF JOIN 때문에 트래픽 문제가 발생하신다면 위와 같은 사례로도 접근 가능하다는 점을 참고하시고, 각자 처한 환경에 따라 최적화하여 가성비 좋은 데이터 분석을 하시길 바랄게요. 부족한 글을 읽어주셔서 감사합니다!</p>

<p><img src="/assets/2023-11-30-how-to-avoid-self-joins/bye-guys.webp" alt="" /></p>
<blockquote>
  <p>퇴사하겠다는 의미가 아니라, 계속 쿼리 작성하러 가겠다는 의미</p>
</blockquote>

<hr />

<h2 id="published-by-joshua-kim"><em>Published by</em> Joshua Kim</h2>
<p><img src="/assets/profile/joshua-profile.png" alt="Joshua Kim" /></p>]]></content><author><name></name></author><category term="Korean" /><category term="Data Analysis" /><category term="SQL" /><summary type="html"><![CDATA[대고객 서빙을 위해 엄청나게 큰 사이즈의 소스 테이블로부터 최적화된 데이터 마트 설계 고민을 많이 하고 있는 만큼, 이번에는 SELF JOIN 사례를 중심으로 SQL 성능에 대한 이야기를 들려드리겠습니다.]]></summary></entry></feed>